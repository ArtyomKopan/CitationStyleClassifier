{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21lsmc6gBFw-"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FgnYLa9hnPuO"
   },
   "outputs": [],
   "source": [
    "import joblib # для сериализации и сохранения обученной модели в файл\n",
    "# (см. https://machinelearningmastery.ru/save-load-machine-learning-models-python-scikit-learn/)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, log_loss, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLmR8NBToJbh"
   },
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('drive/MyDrive/bib_data_union_v2.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLvVXkKApEVi",
    "outputId": "11677993-ad98-4236-873e-67e343ab4829"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6007277, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "2kOs2bhQpJmq",
    "outputId": "71969604-d668-4d32-93df-f4e90ea7c9ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-09c93130-e0ec-48b7-bb7f-fd40ed54183a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>square_brackets</th>\n",
       "      <th>round_brackets</th>\n",
       "      <th>slashes</th>\n",
       "      <th>inverse_slashes</th>\n",
       "      <th>quotes</th>\n",
       "      <th>dots</th>\n",
       "      <th>commas</th>\n",
       "      <th>semicolons</th>\n",
       "      <th>colons</th>\n",
       "      <th>abstract</th>\n",
       "      <th>...</th>\n",
       "      <th>begin_ref</th>\n",
       "      <th>tirets</th>\n",
       "      <th>key</th>\n",
       "      <th>annotation</th>\n",
       "      <th>capital_letters</th>\n",
       "      <th>years</th>\n",
       "      <th>sine</th>\n",
       "      <th>et_al</th>\n",
       "      <th>etc</th>\n",
       "      <th>style_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>iaea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09c93130-e0ec-48b7-bb7f-fd40ed54183a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-09c93130-e0ec-48b7-bb7f-fd40ed54183a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-09c93130-e0ec-48b7-bb7f-fd40ed54183a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   square_brackets  round_brackets  slashes  inverse_slashes  quotes  dots  \\\n",
       "0                1               1        1                0       0     5   \n",
       "1                1               1        5                0       0    11   \n",
       "2                1               2        5                0       0    18   \n",
       "3                1               2        5                0       0    18   \n",
       "4                1               2        5                0       0    17   \n",
       "\n",
       "   commas  semicolons  colons  abstract  ...  begin_ref  tirets  key  \\\n",
       "0      10           0       0         0  ...          1       0    0   \n",
       "1       3           0       2         0  ...          3       0    0   \n",
       "2       2           0       3         0  ...          3       0    0   \n",
       "3       2           0       4         0  ...          3       0    0   \n",
       "4       2           0       3         0  ...          3       0    0   \n",
       "\n",
       "   annotation  capital_letters  years  sine  et_al  etc  style_name  \n",
       "0           0         0.552632      2     0      1    0        iaea  \n",
       "1           0         0.647059      9     0      0    0  bestpapers  \n",
       "2           0         0.647059      2     0      0    0  bestpapers  \n",
       "3           0         0.454545      2     0      0    0  bestpapers  \n",
       "4           0         0.588235      3     0      0    0  bestpapers  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EScLI_TofdC"
   },
   "outputs": [],
   "source": [
    "X = data_frame.drop(['style_name'], axis=1)\n",
    "y = data_frame.style_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVHw4Zp9mkcE"
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=['begin_ref', 'abstract', 'key', 'annotation', 'sine', 'et_al', 'etc', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJsUcCfYp7jB"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(classifier, test_data, test_answers, _average=None):\n",
    "    print(f\"accuracy = {classifier.score(test_data, test_answers)}\")\n",
    "    precisions = precision_score(test_answers, classifier.predict(test_data), average=_average, zero_division=0)\n",
    "    recalls = recall_score(test_answers, classifier.predict(test_data), average=_average, zero_division=0)\n",
    "    f1_scores = f1_score(test_answers, classifier.predict(test_data), average=_average, zero_division=0)\n",
    "    print(\"precision: \", \"min = \", precisions.min(), \"max = \", precisions.max(), \"mean = \", np.mean(precisions), \"median = \", np.median(precisions))\n",
    "    print(\"recall: \", \"min = \", recalls.min(), \"max = \", recalls.max(), \"mean = \", np.mean(recalls), \"median = \", np.median(recalls))\n",
    "    print(\"f1_score: \", \"min = \", f1_scores.min(), \"max = \", f1_scores.max(), \"mean = \", np.mean(f1_scores), \"median = \", np.median(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZNTh2EcWf_4"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rgRjUelDF7N",
    "outputId": "412e7a5c-b9c9-4d8a-f0f9-bc153bbc29d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5389785393722284"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion='entropy', n_estimators=40, max_depth=11, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvNtElX-dtFW",
    "outputId": "3f952e2f-1ac4-4c14-fb57-ddea2dbcad40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   IEEEannot       0.30      0.01      0.03     13829\n",
      "    IEEEtran       0.34      0.58      0.42     14633\n",
      "   IEEEtranN       0.49      0.52      0.51     14815\n",
      "   IEEEtranS       0.35      0.12      0.18     14399\n",
      "  IEEEtranSA       0.76      0.87      0.81     14944\n",
      "  IEEEtranSN       0.48      0.33      0.39     14934\n",
      "      JHEP-2       0.28      0.01      0.03     14299\n",
      "  aaai-named       0.98      0.79      0.88     13986\n",
      "    abstract       0.76      0.94      0.84     14027\n",
      "    acmtrans       0.57      0.54      0.56     14271\n",
      "      aichej       0.65      0.68      0.66     13692\n",
      "         aip       0.28      0.01      0.02     14315\n",
      "    alphanum       0.62      0.88      0.73     13942\n",
      "         ama       0.66      0.47      0.55     13918\n",
      "    amsalpha       0.86      0.88      0.87     10774\n",
      "    amsplain       0.34      0.62      0.44     10792\n",
      "    annotate       0.79      0.80      0.79     14295\n",
      "  annotation       1.00      1.00      1.00     12997\n",
      "         apa       0.50      0.43      0.47     14180\n",
      "apalike-ejor       0.98      0.86      0.92     13228\n",
      "     apasoft       0.88      0.89      0.89     14177\n",
      "      astron       0.60      0.79      0.68     13968\n",
      "         bbs       0.82      0.70      0.76     14346\n",
      " besjournals       0.58      0.78      0.67     14155\n",
      "  bestpapers       1.00      0.03      0.06       185\n",
      "     biolett       0.70      0.64      0.67     13722\n",
      "      bookdb       0.80      0.83      0.81     10884\n",
      "         cbe       0.56      0.44      0.49     14536\n",
      "     chicago       0.36      0.52      0.43     14260\n",
      "    chicagoa       0.32      0.15      0.20     14338\n",
      "          cj       0.39      0.51      0.44     14280\n",
      "         cpc       0.33      0.16      0.21     14246\n",
      "      decsci       0.62      0.54      0.58     14064\n",
      " development       0.72      0.87      0.79     14091\n",
      "         fbs       0.34      0.83      0.48     14321\n",
      "    finplain       0.15      0.40      0.22     14119\n",
      "    generate       0.19      0.00      0.01      3453\n",
      " h-elsevier3       0.46      0.22      0.30     14435\n",
      "  h-physrev3       0.47      0.00      0.01     14027\n",
      "  h-physrev4       0.32      0.06      0.10     13830\n",
      "  h-physrev5       0.33      0.02      0.03     13847\n",
      "        hum2       0.51      0.69      0.59     14387\n",
      "    humanbio       0.46      0.46      0.46     14321\n",
      "    humannat       0.57      0.43      0.49     14422\n",
      "        iaea       0.54      0.76      0.63     14326\n",
      "       jbact       0.33      0.53      0.41     14291\n",
      "         jcc       0.63      0.57      0.60     14214\n",
      "         jcp       0.32      0.06      0.11     14016\n",
      "         jmb       0.91      0.76      0.83     14134\n",
      "   jneurosci       0.53      0.86      0.66     14394\n",
      "         jpc       0.71      0.60      0.65     14031\n",
      "    jphysiol       0.89      0.73      0.80     14259\n",
      "     jqt1999       0.99      0.71      0.83     14134\n",
      "         jtb       0.55      0.59      0.57     14208\n",
      "      jtbnew       0.70      0.49      0.58     14055\n",
      "         mla       0.46      0.34      0.39     14345\n",
      "        mlaa       0.45      0.42      0.43     14409\n",
      "    namunsrt       0.99      1.00      0.99     14083\n",
      "         nar       0.44      0.61      0.51     14067\n",
      "      natbib       0.72      0.86      0.79     14036\n",
      "      neuron       0.67      0.72      0.70     14119\n",
      "   newcastle       0.89      0.84      0.86     12972\n",
      "          nf       0.58      0.11      0.19     14102\n",
      "       nflet       0.63      0.19      0.29     14261\n",
      "        pccp       0.38      0.36      0.37     14027\n",
      "  perception       0.96      0.95      0.96     13939\n",
      "          pf       0.14      0.24      0.18     14022\n",
      "       phjcp       0.15      0.08      0.10     14217\n",
      "     plainyr       0.12      0.55      0.19     14667\n",
      "        pnas       0.42      0.79      0.55     14326\n",
      "    pnas2009       0.42      0.15      0.22     13908\n",
      "        ppcf       0.62      0.90      0.73     14303\n",
      "      report       0.19      0.25      0.22     14044\n",
      " revcompchem       0.63      0.32      0.43     14446\n",
      "         rmp       0.93      0.72      0.81     13350\n",
      "       these       0.80      0.96      0.87     14262\n",
      "   ugost2003       0.48      0.36      0.41     10994\n",
      "  ugost2003s       0.48      0.60      0.53     10764\n",
      "   ugost2008       0.20      0.43      0.27     11132\n",
      "  ugost2008l       0.25      0.25      0.25     10899\n",
      " ugost2008ls       0.19      0.05      0.08     10954\n",
      "ugost2008mod       0.98      0.38      0.54     11049\n",
      "  ugost2008n       0.31      0.15      0.21        65\n",
      " ugost2008ns       0.31      0.25      0.28        61\n",
      "  ugost2008s       0.22      0.13      0.16     11023\n",
      "      utcaps       0.52      0.55      0.54     14049\n",
      "      utphys       0.42      0.44      0.43     13764\n",
      "         vak       0.95      0.98      0.96     14008\n",
      "   vancouver       0.74      0.84      0.79     13498\n",
      "     wmaainf       0.98      0.90      0.94     14207\n",
      "     zootaxa       0.79      0.72      0.75     14338\n",
      "\n",
      "    accuracy                           0.54   1201456\n",
      "   macro avg       0.56      0.52      0.51   1201456\n",
      "weighted avg       0.56      0.54      0.52   1201456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJBGn5UfXXQc"
   },
   "outputs": [],
   "source": [
    "precision_score(y_test, clf.predict(X_test), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YgYhr9irOczi",
    "outputId": "687d4667-be6c-402f-e71d-3b40572b9671"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.57334071e-02, 1.40270769e-01, 8.54970224e-02, 3.52857883e-06,\n",
       "       6.35333558e-02, 4.53995573e-02, 2.30159064e-02, 3.46565340e-02,\n",
       "       5.66727065e-02, 2.92628458e-03, 1.62570014e-02, 6.35904016e-02,\n",
       "       2.84581430e-02, 3.16135388e-01, 1.95883331e-02, 9.04565353e-03,\n",
       "       2.84745424e-06, 2.29252288e-02, 6.97758733e-03, 1.41364037e-03,\n",
       "       3.78955668e-02, 1.13740366e-06])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeWNN19xbLPe"
   },
   "outputs": [],
   "source": [
    "y_list = list(y)\n",
    "y_set = set(y_list)\n",
    "for style in y_set:\n",
    "  print(style, y_list.count(style))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBTajIBBYPcZ"
   },
   "outputs": [],
   "source": [
    "precisions = precision_score(y_test, clf.predict(X_test), average=None)\n",
    "recalls = recall_score(y_test, clf.predict(X_test), average=None)\n",
    "f1_scores = f1_score(y_test, clf.predict(X_test), average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSmuzGlMdb12",
    "outputId": "79fe1932-cf4d-4349-9d97-1dfcbd9f655f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  min =  0.11790302527973477 max =  1.0 mean =  0.5440775699164183 median =  0.49117680116893336\n",
      "recall:  min =  0.007471980074719801 max =  0.9984328395935493 mean =  0.5150078729198585 median =  0.5418823529411765\n",
      "f1_score:  min =  0.014519731943410276 max =  0.9793527321617209 mean =  0.49919371625718445 median =  0.4951682969354887\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", \"min = \", precisions.min(), \"max = \", precisions.max(), \"mean = \", np.mean(precisions), \"median = \", np.median(precisions))\n",
    "print(\"recall: \", \"min = \", recalls.min(), \"max = \", recalls.max(), \"mean = \", np.mean(recalls), \"median = \", np.median(recalls))\n",
    "print(\"f1_score: \", \"min = \", f1_scores.min(), \"max = \", f1_scores.max(), \"mean = \", np.mean(f1_scores), \"median = \", np.median(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRmnX-HBcKD0"
   },
   "source": [
    "clf1 = RandomForestClassifier(criterion='gini', max_depth=8, n_estimators=50) ==> 46%\n",
    "\n",
    "clf2 = RandomForestClassifier(criterion='gini', n_estimators=20, max_depth=10, n_jobs=-1) ==> 50%\n",
    "\n",
    "clf3 = RandomForestClassifier(criterion='entropy', n_estimators=20, max_depth=10, n_jobs=-1) ==> 51.6%\n",
    "\n",
    "clf4 = RandomForestClassifier(criterion='entropy', n_estimators=30, max_depth=10, n_jobs=-1) ==> 52%\n",
    "\n",
    "clf5 = RandomForestClassifier(criterion='entropy', n_estimators=20, max_depth=11, n_jobs=-1) ==> 52.8%\n",
    "\n",
    "clf6 = RandomForestClassifier(criterion='entropy', n_estimators=30, max_depth=11, n_jobs=-1) ==> 53.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WonGA5W4chJa"
   },
   "source": [
    "# Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFWNaOf0qgPK"
   },
   "outputs": [],
   "source": [
    "X = X.drop(['abstract', 'annotation', 'inverse_slashes', 'etc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0fxHpl8L9Eg"
   },
   "outputs": [],
   "source": [
    "y_list = list(y)\n",
    "for style in y_list:\n",
    "  if 'ugost2003' in style:\n",
    "    style = 'ugost2003'\n",
    "  elif 'ugost2008' in style:\n",
    "    style = 'ugost2008'\n",
    "  elif 'IEEE' in style:\n",
    "    style = 'IEEE'\n",
    "  elif 'h-physrev' in style:\n",
    "    style = 'h-physrev'\n",
    "y = pd.Series(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "gyd-mUyIAwOj"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "k-89m_iJcfsd"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'begin_ref_1' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-8c2c2c665f0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_dataset = catboost.Pool(data=X_train, label=y_train, cat_features=[ 'begin_ref_1',\n\u001b[0m\u001b[1;32m      2\u001b[0m  \u001b[0;34m'begin_ref_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m  \u001b[0;34m'begin_ref_3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0;34m'begin_ref_4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m  \u001b[0;34m'begin_ref_5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    790\u001b[0m                     )\n\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m                 self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0m\u001b[1;32m    793\u001b[0m                            group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m    794\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcat_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mcat_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_features_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_string_feature_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cat_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_string_feature_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cat_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_get_features_indices\u001b[0;34m(features, feature_names)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature names should be a sequence, but got \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         return [\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0mfeature_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         return [\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mfeature_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         ]\n",
      "\u001b[0;31mValueError\u001b[0m: 'begin_ref_1' is not in list"
     ]
    }
   ],
   "source": [
    "train_dataset = catboost.Pool(data=X_train, label=y_train, cat_features=[ 'begin_ref_1',\n",
    " 'begin_ref_2',\n",
    " 'begin_ref_3',\n",
    " 'begin_ref_4',\n",
    " 'begin_ref_5',\n",
    " 'begin_ref_6',\n",
    " 'begin_ref_7',\n",
    " 'begin_ref_8',\n",
    " 'begin_ref_9',\n",
    " 'begin_ref_10',\n",
    " 'begin_ref_11',\n",
    " 'begin_ref_12',\n",
    " 'abstract_0',\n",
    " 'abstract_1',\n",
    " 'key_0',\n",
    " 'key_1',\n",
    " 'annotation_0',\n",
    " 'annotation_1',\n",
    " 'sine_0',\n",
    " 'sine_1',\n",
    " 'sine_2',\n",
    " 'et_al_0',\n",
    " 'et_al_1',\n",
    " 'et_al_2',\n",
    " 'et_al_3',\n",
    " 'etc_0',\n",
    " 'etc_1'])\n",
    "test_dataset = catboost.Pool(data=X_test, label=y_test, cat_features=[ 'begin_ref_1',\n",
    " 'begin_ref_2',\n",
    " 'begin_ref_3',\n",
    " 'begin_ref_4',\n",
    " 'begin_ref_5',\n",
    " 'begin_ref_6',\n",
    " 'begin_ref_7',\n",
    " 'begin_ref_8',\n",
    " 'begin_ref_9',\n",
    " 'begin_ref_10',\n",
    " 'begin_ref_11',\n",
    " 'begin_ref_12',\n",
    " 'abstract_0',\n",
    " 'abstract_1',\n",
    " 'key_0',\n",
    " 'key_1',\n",
    " 'annotation_0',\n",
    " 'annotation_1',\n",
    " 'sine_0',\n",
    " 'sine_1',\n",
    " 'sine_2',\n",
    " 'et_al_0',\n",
    " 'et_al_1',\n",
    " 'et_al_2',\n",
    " 'et_al_3',\n",
    " 'etc_0',\n",
    " 'etc_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCDqe6Z0Cedn"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vju2YNZ0wZ9U",
    "outputId": "1ad22b7d-071f-43e7-bdbe-69bcae888a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3080077\ttest: 0.3075002\tbest: 0.3075002 (0)\ttotal: 3.6s\tremaining: 14m 57s\n",
      "1:\tlearn: 0.3493131\ttest: 0.3488401\tbest: 0.3488401 (1)\ttotal: 7.2s\tremaining: 14m 52s\n",
      "2:\tlearn: 0.3974112\ttest: 0.3965921\tbest: 0.3965921 (2)\ttotal: 10.9s\tremaining: 14m 58s\n",
      "3:\tlearn: 0.4142674\ttest: 0.4132910\tbest: 0.4132910 (3)\ttotal: 14.5s\tremaining: 14m 52s\n",
      "4:\tlearn: 0.4298913\ttest: 0.4288663\tbest: 0.4288663 (4)\ttotal: 18.1s\tremaining: 14m 46s\n",
      "5:\tlearn: 0.4329104\ttest: 0.4317653\tbest: 0.4317653 (5)\ttotal: 21.6s\tremaining: 14m 40s\n",
      "6:\tlearn: 0.4393770\ttest: 0.4383831\tbest: 0.4383831 (6)\ttotal: 25.2s\tremaining: 14m 34s\n",
      "7:\tlearn: 0.4436465\ttest: 0.4426504\tbest: 0.4426504 (7)\ttotal: 28.7s\tremaining: 14m 28s\n",
      "8:\tlearn: 0.4436998\ttest: 0.4426962\tbest: 0.4426962 (8)\ttotal: 32.3s\tremaining: 14m 25s\n",
      "9:\tlearn: 0.4533373\ttest: 0.4521023\tbest: 0.4521023 (9)\ttotal: 35.9s\tremaining: 14m 22s\n",
      "10:\tlearn: 0.4557785\ttest: 0.4544628\tbest: 0.4544628 (10)\ttotal: 39.6s\tremaining: 14m 19s\n",
      "11:\tlearn: 0.4588930\ttest: 0.4575590\tbest: 0.4575590 (11)\ttotal: 43.2s\tremaining: 14m 17s\n",
      "12:\tlearn: 0.4598533\ttest: 0.4585886\tbest: 0.4585886 (12)\ttotal: 46.9s\tremaining: 14m 15s\n",
      "13:\tlearn: 0.4660363\ttest: 0.4646479\tbest: 0.4646479 (13)\ttotal: 50.5s\tremaining: 14m 11s\n",
      "14:\tlearn: 0.4665482\ttest: 0.4651298\tbest: 0.4651298 (14)\ttotal: 54s\tremaining: 14m 5s\n",
      "15:\tlearn: 0.4691456\ttest: 0.4677733\tbest: 0.4677733 (15)\ttotal: 57.7s\tremaining: 14m 3s\n",
      "16:\tlearn: 0.4719419\ttest: 0.4704783\tbest: 0.4704783 (16)\ttotal: 1m 1s\tremaining: 14m 1s\n",
      "17:\tlearn: 0.4729552\ttest: 0.4714854\tbest: 0.4714854 (17)\ttotal: 1m 4s\tremaining: 13m 56s\n",
      "18:\tlearn: 0.4758272\ttest: 0.4743844\tbest: 0.4743844 (18)\ttotal: 1m 8s\tremaining: 13m 53s\n",
      "19:\tlearn: 0.4785603\ttest: 0.4769763\tbest: 0.4769763 (19)\ttotal: 1m 12s\tremaining: 13m 48s\n",
      "20:\tlearn: 0.4817098\ttest: 0.4801699\tbest: 0.4801699 (20)\ttotal: 1m 15s\tremaining: 13m 46s\n",
      "21:\tlearn: 0.4830729\ttest: 0.4815516\tbest: 0.4815516 (21)\ttotal: 1m 19s\tremaining: 13m 40s\n",
      "22:\tlearn: 0.4879819\ttest: 0.4862775\tbest: 0.4862775 (22)\ttotal: 1m 22s\tremaining: 13m 38s\n",
      "23:\tlearn: 0.4967233\ttest: 0.4950061\tbest: 0.4950061 (23)\ttotal: 1m 26s\tremaining: 13m 34s\n",
      "24:\tlearn: 0.5009923\ttest: 0.4992218\tbest: 0.4992218 (24)\ttotal: 1m 30s\tremaining: 13m 32s\n",
      "25:\tlearn: 0.5041196\ttest: 0.5023014\tbest: 0.5023014 (25)\ttotal: 1m 33s\tremaining: 13m 27s\n",
      "26:\tlearn: 0.5065583\ttest: 0.5048175\tbest: 0.5048175 (26)\ttotal: 1m 37s\tremaining: 13m 24s\n",
      "27:\tlearn: 0.5099228\ttest: 0.5081618\tbest: 0.5081618 (27)\ttotal: 1m 40s\tremaining: 13m 19s\n",
      "28:\tlearn: 0.5107166\ttest: 0.5089891\tbest: 0.5089891 (28)\ttotal: 1m 44s\tremaining: 13m 15s\n",
      "29:\tlearn: 0.5113186\ttest: 0.5096583\tbest: 0.5096583 (29)\ttotal: 1m 47s\tremaining: 13m 10s\n",
      "30:\tlearn: 0.5133986\ttest: 0.5117649\tbest: 0.5117649 (30)\ttotal: 1m 51s\tremaining: 13m 7s\n",
      "31:\tlearn: 0.5186883\ttest: 0.5170094\tbest: 0.5170094 (31)\ttotal: 1m 55s\tremaining: 13m 4s\n",
      "32:\tlearn: 0.5195686\ttest: 0.5178167\tbest: 0.5178167 (32)\ttotal: 1m 58s\tremaining: 13m\n",
      "33:\tlearn: 0.5238681\ttest: 0.5218385\tbest: 0.5218385 (33)\ttotal: 2m 2s\tremaining: 12m 58s\n",
      "34:\tlearn: 0.5252753\ttest: 0.5232759\tbest: 0.5232759 (34)\ttotal: 2m 6s\tremaining: 12m 54s\n",
      "35:\tlearn: 0.5275817\ttest: 0.5253467\tbest: 0.5253467 (35)\ttotal: 2m 9s\tremaining: 12m 50s\n",
      "36:\tlearn: 0.5281521\ttest: 0.5258178\tbest: 0.5258178 (36)\ttotal: 2m 13s\tremaining: 12m 46s\n",
      "37:\tlearn: 0.5283852\ttest: 0.5260933\tbest: 0.5260933 (37)\ttotal: 2m 16s\tremaining: 12m 40s\n",
      "38:\tlearn: 0.5301441\ttest: 0.5277763\tbest: 0.5277763 (38)\ttotal: 2m 20s\tremaining: 12m 38s\n",
      "39:\tlearn: 0.5305556\ttest: 0.5281225\tbest: 0.5281225 (39)\ttotal: 2m 23s\tremaining: 12m 34s\n",
      "40:\tlearn: 0.5335597\ttest: 0.5311381\tbest: 0.5311381 (40)\ttotal: 2m 27s\tremaining: 12m 31s\n",
      "41:\tlearn: 0.5353573\ttest: 0.5328551\tbest: 0.5328551 (41)\ttotal: 2m 31s\tremaining: 12m 30s\n",
      "42:\tlearn: 0.5359990\ttest: 0.5334677\tbest: 0.5334677 (42)\ttotal: 2m 35s\tremaining: 12m 28s\n",
      "43:\tlearn: 0.5374600\ttest: 0.5348685\tbest: 0.5348685 (43)\ttotal: 2m 39s\tremaining: 12m 24s\n",
      "44:\tlearn: 0.5376315\ttest: 0.5350092\tbest: 0.5350092 (44)\ttotal: 2m 42s\tremaining: 12m 20s\n",
      "45:\tlearn: 0.5404705\ttest: 0.5377001\tbest: 0.5377001 (45)\ttotal: 2m 46s\tremaining: 12m 17s\n",
      "46:\tlearn: 0.5414821\ttest: 0.5385516\tbest: 0.5385516 (46)\ttotal: 2m 49s\tremaining: 12m 14s\n",
      "47:\tlearn: 0.5437402\ttest: 0.5406931\tbest: 0.5406931 (47)\ttotal: 2m 53s\tremaining: 12m 11s\n",
      "48:\tlearn: 0.5449160\ttest: 0.5419433\tbest: 0.5419433 (48)\ttotal: 2m 57s\tremaining: 12m 8s\n",
      "49:\tlearn: 0.5457019\ttest: 0.5426982\tbest: 0.5426982 (49)\ttotal: 3m 1s\tremaining: 12m 5s\n",
      "50:\tlearn: 0.5473369\ttest: 0.5442397\tbest: 0.5442397 (50)\ttotal: 3m 5s\tremaining: 12m 1s\n",
      "51:\tlearn: 0.5483030\ttest: 0.5452293\tbest: 0.5452293 (51)\ttotal: 3m 8s\tremaining: 11m 57s\n",
      "52:\tlearn: 0.5499729\ttest: 0.5467658\tbest: 0.5467658 (52)\ttotal: 3m 12s\tremaining: 11m 54s\n",
      "53:\tlearn: 0.5507031\ttest: 0.5474699\tbest: 0.5474699 (53)\ttotal: 3m 15s\tremaining: 11m 50s\n",
      "54:\tlearn: 0.5509331\ttest: 0.5476264\tbest: 0.5476264 (54)\ttotal: 3m 19s\tremaining: 11m 46s\n",
      "55:\tlearn: 0.5523009\ttest: 0.5490130\tbest: 0.5490130 (55)\ttotal: 3m 23s\tremaining: 11m 43s\n",
      "56:\tlearn: 0.5532977\ttest: 0.5498895\tbest: 0.5498895 (56)\ttotal: 3m 26s\tremaining: 11m 39s\n",
      "57:\tlearn: 0.5546725\ttest: 0.5511912\tbest: 0.5511912 (57)\ttotal: 3m 30s\tremaining: 11m 35s\n",
      "58:\tlearn: 0.5560871\ttest: 0.5525404\tbest: 0.5525404 (58)\ttotal: 3m 33s\tremaining: 11m 32s\n",
      "59:\tlearn: 0.5567594\ttest: 0.5531896\tbest: 0.5531896 (59)\ttotal: 3m 37s\tremaining: 11m 28s\n",
      "60:\tlearn: 0.5575620\ttest: 0.5538979\tbest: 0.5538979 (60)\ttotal: 3m 41s\tremaining: 11m 25s\n",
      "61:\tlearn: 0.5592469\ttest: 0.5555268\tbest: 0.5555268 (61)\ttotal: 3m 45s\tremaining: 11m 22s\n",
      "62:\tlearn: 0.5601353\ttest: 0.5564940\tbest: 0.5564940 (62)\ttotal: 3m 48s\tremaining: 11m 18s\n",
      "63:\tlearn: 0.5611535\ttest: 0.5573088\tbest: 0.5573088 (63)\ttotal: 3m 52s\tremaining: 11m 15s\n",
      "64:\tlearn: 0.5624281\ttest: 0.5585306\tbest: 0.5585306 (64)\ttotal: 3m 56s\tremaining: 11m 12s\n",
      "65:\tlearn: 0.5633003\ttest: 0.5594495\tbest: 0.5594495 (65)\ttotal: 3m 59s\tremaining: 11m 9s\n",
      "66:\tlearn: 0.5643238\ttest: 0.5605216\tbest: 0.5605216 (66)\ttotal: 4m 3s\tremaining: 11m 5s\n",
      "67:\tlearn: 0.5650837\ttest: 0.5611292\tbest: 0.5611292 (67)\ttotal: 4m 7s\tremaining: 11m 2s\n",
      "68:\tlearn: 0.5660520\ttest: 0.5620880\tbest: 0.5620880 (68)\ttotal: 4m 11s\tremaining: 10m 58s\n",
      "69:\tlearn: 0.5665952\ttest: 0.5627389\tbest: 0.5627389 (69)\ttotal: 4m 14s\tremaining: 10m 54s\n",
      "70:\tlearn: 0.5676034\ttest: 0.5636661\tbest: 0.5636661 (70)\ttotal: 4m 18s\tremaining: 10m 50s\n",
      "71:\tlearn: 0.5695611\ttest: 0.5654256\tbest: 0.5654256 (71)\ttotal: 4m 21s\tremaining: 10m 47s\n",
      "72:\tlearn: 0.5697520\ttest: 0.5655172\tbest: 0.5655172 (72)\ttotal: 4m 25s\tremaining: 10m 44s\n",
      "73:\tlearn: 0.5705737\ttest: 0.5663229\tbest: 0.5663229 (73)\ttotal: 4m 29s\tremaining: 10m 40s\n",
      "74:\tlearn: 0.5712296\ttest: 0.5668963\tbest: 0.5668963 (74)\ttotal: 4m 33s\tremaining: 10m 37s\n",
      "75:\tlearn: 0.5723047\ttest: 0.5678710\tbest: 0.5678710 (75)\ttotal: 4m 37s\tremaining: 10m 34s\n",
      "76:\tlearn: 0.5727863\ttest: 0.5682738\tbest: 0.5682738 (76)\ttotal: 4m 40s\tremaining: 10m 31s\n",
      "77:\tlearn: 0.5733862\ttest: 0.5688465\tbest: 0.5688465 (77)\ttotal: 4m 44s\tremaining: 10m 27s\n",
      "78:\tlearn: 0.5734766\ttest: 0.5689721\tbest: 0.5689721 (78)\ttotal: 4m 47s\tremaining: 10m 23s\n",
      "79:\tlearn: 0.5741169\ttest: 0.5693991\tbest: 0.5693991 (79)\ttotal: 4m 51s\tremaining: 10m 19s\n",
      "80:\tlearn: 0.5745395\ttest: 0.5697196\tbest: 0.5697196 (80)\ttotal: 4m 55s\tremaining: 10m 16s\n",
      "81:\tlearn: 0.5751249\ttest: 0.5701940\tbest: 0.5701940 (81)\ttotal: 4m 59s\tremaining: 10m 13s\n",
      "82:\tlearn: 0.5756662\ttest: 0.5707641\tbest: 0.5707641 (82)\ttotal: 5m 2s\tremaining: 10m 9s\n",
      "83:\tlearn: 0.5762668\ttest: 0.5713551\tbest: 0.5713551 (83)\ttotal: 5m 6s\tremaining: 10m 5s\n",
      "84:\tlearn: 0.5769077\ttest: 0.5719560\tbest: 0.5719560 (84)\ttotal: 5m 10s\tremaining: 10m 2s\n",
      "85:\tlearn: 0.5773494\ttest: 0.5723580\tbest: 0.5723580 (85)\ttotal: 5m 13s\tremaining: 9m 58s\n",
      "86:\tlearn: 0.5779437\ttest: 0.5729939\tbest: 0.5729939 (86)\ttotal: 5m 17s\tremaining: 9m 54s\n",
      "87:\tlearn: 0.5787275\ttest: 0.5737871\tbest: 0.5737871 (87)\ttotal: 5m 20s\tremaining: 9m 50s\n",
      "88:\tlearn: 0.5791009\ttest: 0.5741509\tbest: 0.5741509 (88)\ttotal: 5m 24s\tremaining: 9m 47s\n",
      "89:\tlearn: 0.5795343\ttest: 0.5745520\tbest: 0.5745520 (89)\ttotal: 5m 28s\tremaining: 9m 43s\n",
      "90:\tlearn: 0.5799940\ttest: 0.5750298\tbest: 0.5750298 (90)\ttotal: 5m 31s\tremaining: 9m 39s\n",
      "91:\tlearn: 0.5807916\ttest: 0.5757464\tbest: 0.5757464 (91)\ttotal: 5m 35s\tremaining: 9m 35s\n",
      "92:\tlearn: 0.5815182\ttest: 0.5763540\tbest: 0.5763540 (92)\ttotal: 5m 39s\tremaining: 9m 32s\n",
      "93:\tlearn: 0.5819075\ttest: 0.5767760\tbest: 0.5767760 (93)\ttotal: 5m 42s\tremaining: 9m 28s\n",
      "94:\tlearn: 0.5822196\ttest: 0.5770532\tbest: 0.5770532 (94)\ttotal: 5m 46s\tremaining: 9m 24s\n",
      "95:\tlearn: 0.5824812\ttest: 0.5772979\tbest: 0.5772979 (95)\ttotal: 5m 49s\tremaining: 9m 21s\n",
      "96:\tlearn: 0.5830309\ttest: 0.5778131\tbest: 0.5778131 (96)\ttotal: 5m 53s\tremaining: 9m 18s\n",
      "97:\tlearn: 0.5835069\ttest: 0.5783524\tbest: 0.5783524 (97)\ttotal: 5m 57s\tremaining: 9m 14s\n",
      "98:\tlearn: 0.5838318\ttest: 0.5786346\tbest: 0.5786346 (98)\ttotal: 6m 1s\tremaining: 9m 11s\n",
      "99:\tlearn: 0.5840413\ttest: 0.5788510\tbest: 0.5788510 (99)\ttotal: 6m 4s\tremaining: 9m 7s\n",
      "100:\tlearn: 0.5843068\ttest: 0.5791057\tbest: 0.5791057 (100)\ttotal: 6m 8s\tremaining: 9m 3s\n",
      "101:\tlearn: 0.5850881\ttest: 0.5797283\tbest: 0.5797283 (101)\ttotal: 6m 12s\tremaining: 9m\n",
      "102:\tlearn: 0.5854135\ttest: 0.5799971\tbest: 0.5799971 (102)\ttotal: 6m 15s\tremaining: 8m 56s\n",
      "103:\tlearn: 0.5859229\ttest: 0.5805847\tbest: 0.5805847 (103)\ttotal: 6m 19s\tremaining: 8m 52s\n",
      "104:\tlearn: 0.5863760\ttest: 0.5809551\tbest: 0.5809551 (104)\ttotal: 6m 22s\tremaining: 8m 48s\n",
      "105:\tlearn: 0.5866684\ttest: 0.5812331\tbest: 0.5812331 (105)\ttotal: 6m 26s\tremaining: 8m 45s\n",
      "106:\tlearn: 0.5871761\ttest: 0.5816318\tbest: 0.5816318 (106)\ttotal: 6m 30s\tremaining: 8m 41s\n",
      "107:\tlearn: 0.5878589\ttest: 0.5821328\tbest: 0.5821328 (107)\ttotal: 6m 34s\tremaining: 8m 38s\n",
      "108:\tlearn: 0.5880417\ttest: 0.5822460\tbest: 0.5822460 (108)\ttotal: 6m 37s\tremaining: 8m 34s\n",
      "109:\tlearn: 0.5886551\ttest: 0.5827929\tbest: 0.5827929 (109)\ttotal: 6m 41s\tremaining: 8m 31s\n",
      "110:\tlearn: 0.5888896\ttest: 0.5830001\tbest: 0.5830001 (110)\ttotal: 6m 45s\tremaining: 8m 27s\n",
      "111:\tlearn: 0.5893399\ttest: 0.5834088\tbest: 0.5834088 (111)\ttotal: 6m 48s\tremaining: 8m 23s\n",
      "112:\tlearn: 0.5895946\ttest: 0.5836910\tbest: 0.5836910 (112)\ttotal: 6m 52s\tremaining: 8m 20s\n",
      "113:\tlearn: 0.5899860\ttest: 0.5840231\tbest: 0.5840231 (113)\ttotal: 6m 56s\tremaining: 8m 16s\n",
      "114:\tlearn: 0.5905279\ttest: 0.5844991\tbest: 0.5844991 (114)\ttotal: 7m\tremaining: 8m 13s\n",
      "115:\tlearn: 0.5908267\ttest: 0.5847821\tbest: 0.5847821 (115)\ttotal: 7m 4s\tremaining: 8m 9s\n",
      "116:\tlearn: 0.5911252\ttest: 0.5850793\tbest: 0.5850793 (116)\ttotal: 7m 8s\tremaining: 8m 6s\n",
      "117:\tlearn: 0.5914803\ttest: 0.5854829\tbest: 0.5854829 (117)\ttotal: 7m 12s\tremaining: 8m 3s\n",
      "118:\tlearn: 0.5917347\ttest: 0.5858492\tbest: 0.5858492 (118)\ttotal: 7m 15s\tremaining: 7m 59s\n",
      "119:\tlearn: 0.5920496\ttest: 0.5859424\tbest: 0.5859424 (119)\ttotal: 7m 19s\tremaining: 7m 56s\n",
      "120:\tlearn: 0.5924922\ttest: 0.5862803\tbest: 0.5862803 (120)\ttotal: 7m 23s\tremaining: 7m 52s\n",
      "121:\tlearn: 0.5927180\ttest: 0.5864584\tbest: 0.5864584 (121)\ttotal: 7m 27s\tremaining: 7m 49s\n",
      "122:\tlearn: 0.5931281\ttest: 0.5869037\tbest: 0.5869037 (122)\ttotal: 7m 30s\tremaining: 7m 45s\n",
      "123:\tlearn: 0.5935886\ttest: 0.5872982\tbest: 0.5872982 (123)\ttotal: 7m 34s\tremaining: 7m 41s\n",
      "124:\tlearn: 0.5939185\ttest: 0.5875579\tbest: 0.5875579 (124)\ttotal: 7m 38s\tremaining: 7m 38s\n",
      "125:\tlearn: 0.5941884\ttest: 0.5877810\tbest: 0.5877810 (125)\ttotal: 7m 41s\tremaining: 7m 34s\n",
      "126:\tlearn: 0.5943610\ttest: 0.5879325\tbest: 0.5879325 (126)\ttotal: 7m 45s\tremaining: 7m 30s\n",
      "127:\tlearn: 0.5947749\ttest: 0.5882696\tbest: 0.5882696 (127)\ttotal: 7m 49s\tremaining: 7m 27s\n",
      "128:\tlearn: 0.5950271\ttest: 0.5884660\tbest: 0.5884660 (128)\ttotal: 7m 52s\tremaining: 7m 23s\n",
      "129:\tlearn: 0.5951789\ttest: 0.5886724\tbest: 0.5886724 (129)\ttotal: 7m 56s\tremaining: 7m 19s\n",
      "130:\tlearn: 0.5954089\ttest: 0.5888281\tbest: 0.5888281 (130)\ttotal: 7m 59s\tremaining: 7m 16s\n",
      "131:\tlearn: 0.5958206\ttest: 0.5891801\tbest: 0.5891801 (131)\ttotal: 8m 3s\tremaining: 7m 12s\n",
      "132:\tlearn: 0.5963899\ttest: 0.5897503\tbest: 0.5897503 (132)\ttotal: 8m 7s\tremaining: 7m 9s\n",
      "133:\tlearn: 0.5965631\ttest: 0.5899459\tbest: 0.5899459 (133)\ttotal: 8m 11s\tremaining: 7m 5s\n",
      "134:\tlearn: 0.5969287\ttest: 0.5902355\tbest: 0.5902355 (134)\ttotal: 8m 15s\tremaining: 7m 1s\n",
      "135:\tlearn: 0.5971804\ttest: 0.5904128\tbest: 0.5904128 (135)\ttotal: 8m 18s\tremaining: 6m 58s\n",
      "136:\tlearn: 0.5976226\ttest: 0.5907657\tbest: 0.5907657 (136)\ttotal: 8m 22s\tremaining: 6m 54s\n",
      "137:\tlearn: 0.5981253\ttest: 0.5911502\tbest: 0.5911502 (137)\ttotal: 8m 26s\tremaining: 6m 51s\n",
      "138:\tlearn: 0.5983420\ttest: 0.5913575\tbest: 0.5913575 (138)\ttotal: 8m 30s\tremaining: 6m 47s\n",
      "139:\tlearn: 0.5985715\ttest: 0.5915614\tbest: 0.5915614 (139)\ttotal: 8m 33s\tremaining: 6m 43s\n",
      "140:\tlearn: 0.5986883\ttest: 0.5917245\tbest: 0.5917245 (140)\ttotal: 8m 37s\tremaining: 6m 39s\n",
      "141:\tlearn: 0.5990783\ttest: 0.5919826\tbest: 0.5919826 (141)\ttotal: 8m 40s\tremaining: 6m 36s\n",
      "142:\tlearn: 0.5994265\ttest: 0.5923147\tbest: 0.5923147 (142)\ttotal: 8m 44s\tremaining: 6m 32s\n",
      "143:\tlearn: 0.5997190\ttest: 0.5926318\tbest: 0.5926318 (143)\ttotal: 8m 48s\tremaining: 6m 28s\n",
      "144:\tlearn: 0.5998616\ttest: 0.5927766\tbest: 0.5927766 (144)\ttotal: 8m 51s\tremaining: 6m 25s\n",
      "145:\tlearn: 0.6000660\ttest: 0.5929031\tbest: 0.5929031 (145)\ttotal: 8m 55s\tremaining: 6m 21s\n",
      "146:\tlearn: 0.6001878\ttest: 0.5930205\tbest: 0.5930205 (146)\ttotal: 8m 59s\tremaining: 6m 17s\n",
      "147:\tlearn: 0.6004594\ttest: 0.5932510\tbest: 0.5932510 (147)\ttotal: 9m 2s\tremaining: 6m 13s\n",
      "148:\tlearn: 0.6007463\ttest: 0.5934932\tbest: 0.5934932 (148)\ttotal: 9m 6s\tremaining: 6m 10s\n",
      "149:\tlearn: 0.6011963\ttest: 0.5939310\tbest: 0.5939310 (149)\ttotal: 9m 9s\tremaining: 6m 6s\n",
      "150:\tlearn: 0.6016128\ttest: 0.5942690\tbest: 0.5942690 (150)\ttotal: 9m 13s\tremaining: 6m 3s\n",
      "151:\tlearn: 0.6017262\ttest: 0.5943655\tbest: 0.5943655 (151)\ttotal: 9m 17s\tremaining: 5m 59s\n",
      "152:\tlearn: 0.6018386\ttest: 0.5944321\tbest: 0.5944321 (152)\ttotal: 9m 20s\tremaining: 5m 55s\n",
      "153:\tlearn: 0.6023544\ttest: 0.5948799\tbest: 0.5948799 (153)\ttotal: 9m 24s\tremaining: 5m 51s\n",
      "154:\tlearn: 0.6025039\ttest: 0.5949723\tbest: 0.5949723 (154)\ttotal: 9m 28s\tremaining: 5m 48s\n",
      "155:\tlearn: 0.6027783\ttest: 0.5952295\tbest: 0.5952295 (155)\ttotal: 9m 31s\tremaining: 5m 44s\n",
      "156:\tlearn: 0.6031606\ttest: 0.5954933\tbest: 0.5954933 (156)\ttotal: 9m 35s\tremaining: 5m 41s\n",
      "157:\tlearn: 0.6036547\ttest: 0.5957746\tbest: 0.5957746 (157)\ttotal: 9m 39s\tremaining: 5m 37s\n",
      "158:\tlearn: 0.6041483\ttest: 0.5961342\tbest: 0.5961342 (158)\ttotal: 9m 43s\tremaining: 5m 34s\n",
      "159:\tlearn: 0.6044798\ttest: 0.5963972\tbest: 0.5963972 (159)\ttotal: 9m 47s\tremaining: 5m 30s\n",
      "160:\tlearn: 0.6045628\ttest: 0.5964580\tbest: 0.5964580 (160)\ttotal: 9m 51s\tremaining: 5m 26s\n",
      "161:\tlearn: 0.6047590\ttest: 0.5966910\tbest: 0.5966910 (161)\ttotal: 9m 54s\tremaining: 5m 22s\n",
      "162:\tlearn: 0.6049088\ttest: 0.5968175\tbest: 0.5968175 (162)\ttotal: 9m 58s\tremaining: 5m 19s\n",
      "163:\tlearn: 0.6051543\ttest: 0.5969773\tbest: 0.5969773 (163)\ttotal: 10m 2s\tremaining: 5m 15s\n",
      "164:\tlearn: 0.6055957\ttest: 0.5974051\tbest: 0.5974051 (164)\ttotal: 10m 5s\tremaining: 5m 12s\n",
      "165:\tlearn: 0.6059353\ttest: 0.5977323\tbest: 0.5977323 (165)\ttotal: 10m 9s\tremaining: 5m 8s\n",
      "166:\tlearn: 0.6063387\ttest: 0.5980727\tbest: 0.5980727 (166)\ttotal: 10m 13s\tremaining: 5m 4s\n",
      "167:\tlearn: 0.6066259\ttest: 0.5982824\tbest: 0.5982824 (167)\ttotal: 10m 16s\tremaining: 5m 1s\n",
      "168:\tlearn: 0.6068656\ttest: 0.5984647\tbest: 0.5984647 (168)\ttotal: 10m 20s\tremaining: 4m 57s\n",
      "169:\tlearn: 0.6069494\ttest: 0.5986029\tbest: 0.5986029 (169)\ttotal: 10m 24s\tremaining: 4m 53s\n",
      "170:\tlearn: 0.6073816\ttest: 0.5988309\tbest: 0.5988309 (170)\ttotal: 10m 28s\tremaining: 4m 50s\n",
      "171:\tlearn: 0.6074779\ttest: 0.5988742\tbest: 0.5988742 (171)\ttotal: 10m 31s\tremaining: 4m 46s\n",
      "172:\tlearn: 0.6079010\ttest: 0.5992621\tbest: 0.5992621 (172)\ttotal: 10m 35s\tremaining: 4m 42s\n",
      "173:\tlearn: 0.6080339\ttest: 0.5993578\tbest: 0.5993578 (173)\ttotal: 10m 38s\tremaining: 4m 39s\n",
      "174:\tlearn: 0.6083402\ttest: 0.5995867\tbest: 0.5995867 (174)\ttotal: 10m 42s\tremaining: 4m 35s\n",
      "175:\tlearn: 0.6085646\ttest: 0.5997956\tbest: 0.5997956 (175)\ttotal: 10m 46s\tremaining: 4m 31s\n",
      "176:\tlearn: 0.6086789\ttest: 0.5999313\tbest: 0.5999313 (176)\ttotal: 10m 49s\tremaining: 4m 28s\n",
      "177:\tlearn: 0.6088090\ttest: 0.6001119\tbest: 0.6001119 (177)\ttotal: 10m 53s\tremaining: 4m 24s\n",
      "178:\tlearn: 0.6089344\ttest: 0.6002833\tbest: 0.6002833 (178)\ttotal: 10m 56s\tremaining: 4m 20s\n",
      "179:\tlearn: 0.6090252\ttest: 0.6003491\tbest: 0.6003491 (179)\ttotal: 11m\tremaining: 4m 16s\n",
      "180:\tlearn: 0.6092529\ttest: 0.6005455\tbest: 0.6005455 (180)\ttotal: 11m 4s\tremaining: 4m 13s\n",
      "181:\tlearn: 0.6094377\ttest: 0.6007544\tbest: 0.6007544 (181)\ttotal: 11m 8s\tremaining: 4m 9s\n",
      "182:\tlearn: 0.6095257\ttest: 0.6007910\tbest: 0.6007910 (182)\ttotal: 11m 11s\tremaining: 4m 5s\n",
      "183:\tlearn: 0.6099074\ttest: 0.6010457\tbest: 0.6010457 (183)\ttotal: 11m 15s\tremaining: 4m 2s\n",
      "184:\tlearn: 0.6102803\ttest: 0.6013795\tbest: 0.6013795 (184)\ttotal: 11m 19s\tremaining: 3m 58s\n",
      "185:\tlearn: 0.6104257\ttest: 0.6014161\tbest: 0.6014161 (185)\ttotal: 11m 23s\tremaining: 3m 55s\n",
      "186:\tlearn: 0.6106923\ttest: 0.6015301\tbest: 0.6015301 (186)\ttotal: 11m 26s\tremaining: 3m 51s\n",
      "187:\tlearn: 0.6109176\ttest: 0.6016983\tbest: 0.6016983 (187)\ttotal: 11m 30s\tremaining: 3m 47s\n",
      "188:\tlearn: 0.6111137\ttest: 0.6018606\tbest: 0.6018606 (188)\ttotal: 11m 34s\tremaining: 3m 44s\n",
      "189:\tlearn: 0.6112533\ttest: 0.6019729\tbest: 0.6019729 (189)\ttotal: 11m 38s\tremaining: 3m 40s\n",
      "190:\tlearn: 0.6114372\ttest: 0.6020537\tbest: 0.6020537 (190)\ttotal: 11m 42s\tremaining: 3m 36s\n",
      "191:\tlearn: 0.6115932\ttest: 0.6021527\tbest: 0.6021527 (191)\ttotal: 11m 46s\tremaining: 3m 33s\n",
      "192:\tlearn: 0.6118659\ttest: 0.6023999\tbest: 0.6023999 (192)\ttotal: 11m 50s\tremaining: 3m 29s\n",
      "193:\tlearn: 0.6120917\ttest: 0.6025988\tbest: 0.6025988 (193)\ttotal: 11m 53s\tremaining: 3m 26s\n",
      "194:\tlearn: 0.6123778\ttest: 0.6027254\tbest: 0.6027254 (194)\ttotal: 11m 57s\tremaining: 3m 22s\n",
      "195:\tlearn: 0.6125309\ttest: 0.6028202\tbest: 0.6028202 (195)\ttotal: 12m 1s\tremaining: 3m 18s\n",
      "196:\tlearn: 0.6127143\ttest: 0.6030217\tbest: 0.6030217 (196)\ttotal: 12m 4s\tremaining: 3m 14s\n",
      "197:\tlearn: 0.6129776\ttest: 0.6031698\tbest: 0.6031698 (197)\ttotal: 12m 8s\tremaining: 3m 11s\n",
      "198:\tlearn: 0.6131144\ttest: 0.6032780\tbest: 0.6032780 (198)\ttotal: 12m 12s\tremaining: 3m 7s\n",
      "199:\tlearn: 0.6133374\ttest: 0.6034628\tbest: 0.6034628 (199)\ttotal: 12m 16s\tremaining: 3m 4s\n",
      "200:\tlearn: 0.6134176\ttest: 0.6035369\tbest: 0.6035369 (200)\ttotal: 12m 19s\tremaining: 3m\n",
      "201:\tlearn: 0.6135577\ttest: 0.6036126\tbest: 0.6036126 (201)\ttotal: 12m 23s\tremaining: 2m 56s\n",
      "202:\tlearn: 0.6137503\ttest: 0.6037458\tbest: 0.6037458 (202)\ttotal: 12m 27s\tremaining: 2m 52s\n",
      "203:\tlearn: 0.6139883\ttest: 0.6038582\tbest: 0.6038582 (203)\ttotal: 12m 30s\tremaining: 2m 49s\n",
      "204:\tlearn: 0.6142302\ttest: 0.6041345\tbest: 0.6041345 (204)\ttotal: 12m 34s\tremaining: 2m 45s\n",
      "205:\tlearn: 0.6143154\ttest: 0.6041436\tbest: 0.6041436 (205)\ttotal: 12m 37s\tremaining: 2m 41s\n",
      "206:\tlearn: 0.6143118\ttest: 0.6041411\tbest: 0.6041436 (205)\ttotal: 12m 41s\tremaining: 2m 38s\n",
      "207:\tlearn: 0.6144622\ttest: 0.6043001\tbest: 0.6043001 (207)\ttotal: 12m 44s\tremaining: 2m 34s\n",
      "208:\tlearn: 0.6144619\ttest: 0.6043317\tbest: 0.6043317 (208)\ttotal: 12m 47s\tremaining: 2m 30s\n",
      "209:\tlearn: 0.6146356\ttest: 0.6044258\tbest: 0.6044258 (209)\ttotal: 12m 51s\tremaining: 2m 26s\n",
      "210:\tlearn: 0.6147646\ttest: 0.6045864\tbest: 0.6045864 (210)\ttotal: 12m 55s\tremaining: 2m 23s\n",
      "211:\tlearn: 0.6147296\ttest: 0.6045640\tbest: 0.6045864 (210)\ttotal: 12m 58s\tremaining: 2m 19s\n",
      "212:\tlearn: 0.6148059\ttest: 0.6046097\tbest: 0.6046097 (212)\ttotal: 13m 2s\tremaining: 2m 15s\n",
      "213:\tlearn: 0.6150079\ttest: 0.6048062\tbest: 0.6048062 (213)\ttotal: 13m 5s\tremaining: 2m 12s\n",
      "214:\tlearn: 0.6151142\ttest: 0.6048644\tbest: 0.6048644 (214)\ttotal: 13m 9s\tremaining: 2m 8s\n",
      "215:\tlearn: 0.6152168\ttest: 0.6049685\tbest: 0.6049685 (215)\ttotal: 13m 12s\tremaining: 2m 4s\n",
      "216:\tlearn: 0.6152873\ttest: 0.6050259\tbest: 0.6050259 (216)\ttotal: 13m 16s\tremaining: 2m 1s\n",
      "217:\tlearn: 0.6152876\ttest: 0.6050434\tbest: 0.6050434 (217)\ttotal: 13m 19s\tremaining: 1m 57s\n",
      "218:\tlearn: 0.6154474\ttest: 0.6051974\tbest: 0.6051974 (218)\ttotal: 13m 22s\tremaining: 1m 53s\n",
      "219:\tlearn: 0.6154474\ttest: 0.6051982\tbest: 0.6051982 (219)\ttotal: 13m 25s\tremaining: 1m 49s\n",
      "220:\tlearn: 0.6154463\ttest: 0.6051974\tbest: 0.6051982 (219)\ttotal: 13m 28s\tremaining: 1m 46s\n",
      "221:\tlearn: 0.6158702\ttest: 0.6054629\tbest: 0.6054629 (221)\ttotal: 13m 32s\tremaining: 1m 42s\n",
      "222:\tlearn: 0.6158683\ttest: 0.6054645\tbest: 0.6054645 (222)\ttotal: 13m 35s\tremaining: 1m 38s\n",
      "223:\tlearn: 0.6158699\ttest: 0.6054645\tbest: 0.6054645 (222)\ttotal: 13m 38s\tremaining: 1m 35s\n",
      "224:\tlearn: 0.6160000\ttest: 0.6055578\tbest: 0.6055578 (224)\ttotal: 13m 42s\tremaining: 1m 31s\n",
      "225:\tlearn: 0.6162281\ttest: 0.6057534\tbest: 0.6057534 (225)\ttotal: 13m 46s\tremaining: 1m 27s\n",
      "226:\tlearn: 0.6162278\ttest: 0.6057550\tbest: 0.6057550 (226)\ttotal: 13m 49s\tremaining: 1m 24s\n",
      "227:\tlearn: 0.6162289\ttest: 0.6057542\tbest: 0.6057550 (226)\ttotal: 13m 52s\tremaining: 1m 20s\n",
      "228:\tlearn: 0.6162425\ttest: 0.6057758\tbest: 0.6057758 (228)\ttotal: 13m 55s\tremaining: 1m 16s\n",
      "229:\tlearn: 0.6162436\ttest: 0.6057767\tbest: 0.6057767 (229)\ttotal: 13m 58s\tremaining: 1m 12s\n",
      "230:\tlearn: 0.6164453\ttest: 0.6059140\tbest: 0.6059140 (230)\ttotal: 14m 2s\tremaining: 1m 9s\n",
      "231:\tlearn: 0.6164495\ttest: 0.6059157\tbest: 0.6059157 (231)\ttotal: 14m 5s\tremaining: 1m 5s\n",
      "232:\tlearn: 0.6164481\ttest: 0.6059173\tbest: 0.6059173 (232)\ttotal: 14m 8s\tremaining: 1m 1s\n",
      "233:\tlearn: 0.6165100\ttest: 0.6059673\tbest: 0.6059673 (233)\ttotal: 14m 12s\tremaining: 58.3s\n",
      "234:\tlearn: 0.6165100\ttest: 0.6059664\tbest: 0.6059673 (233)\ttotal: 14m 15s\tremaining: 54.6s\n",
      "235:\tlearn: 0.6165732\ttest: 0.6060239\tbest: 0.6060239 (235)\ttotal: 14m 18s\tremaining: 50.9s\n",
      "236:\tlearn: 0.6165710\ttest: 0.6060180\tbest: 0.6060239 (235)\ttotal: 14m 21s\tremaining: 47.3s\n",
      "237:\tlearn: 0.6165755\ttest: 0.6060255\tbest: 0.6060255 (237)\ttotal: 14m 25s\tremaining: 43.6s\n",
      "238:\tlearn: 0.6168052\ttest: 0.6062819\tbest: 0.6062819 (238)\ttotal: 14m 28s\tremaining: 40s\n",
      "239:\tlearn: 0.6168038\ttest: 0.6062827\tbest: 0.6062827 (239)\ttotal: 14m 31s\tremaining: 36.3s\n",
      "240:\tlearn: 0.6169095\ttest: 0.6063892\tbest: 0.6063892 (240)\ttotal: 14m 35s\tremaining: 32.7s\n",
      "241:\tlearn: 0.6169098\ttest: 0.6063901\tbest: 0.6063901 (241)\ttotal: 14m 38s\tremaining: 29s\n",
      "242:\tlearn: 0.6169131\ttest: 0.6063826\tbest: 0.6063901 (241)\ttotal: 14m 41s\tremaining: 25.4s\n",
      "243:\tlearn: 0.6169117\ttest: 0.6063801\tbest: 0.6063901 (241)\ttotal: 14m 44s\tremaining: 21.8s\n",
      "244:\tlearn: 0.6169750\ttest: 0.6063959\tbest: 0.6063959 (244)\ttotal: 14m 48s\tremaining: 18.1s\n",
      "245:\tlearn: 0.6169753\ttest: 0.6063976\tbest: 0.6063976 (245)\ttotal: 14m 51s\tremaining: 14.5s\n",
      "246:\tlearn: 0.6170613\ttest: 0.6065016\tbest: 0.6065016 (246)\ttotal: 14m 54s\tremaining: 10.9s\n",
      "247:\tlearn: 0.6170618\ttest: 0.6065024\tbest: 0.6065024 (247)\ttotal: 14m 58s\tremaining: 7.24s\n",
      "248:\tlearn: 0.6170624\ttest: 0.6065058\tbest: 0.6065058 (248)\ttotal: 15m 1s\tremaining: 3.62s\n",
      "249:\tlearn: 0.6170618\ttest: 0.6065058\tbest: 0.6065058 (248)\ttotal: 15m 4s\tremaining: 0us\n",
      "bestTest = 0.606505773\n",
      "bestIteration = 248\n",
      "Shrink model to first 249 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fa82c3649a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model = catboost.CatBoostClassifier(iterations=250,\n",
    "                           learning_rate=0.05,\n",
    "                           depth=11,\n",
    "                           loss_function='MultiClass',\n",
    "                           task_type='GPU',\n",
    "                           gpu_ram_part=0.95,\n",
    "\n",
    "                           eval_metric='Accuracy',\n",
    "                           cat_features=[ 'begin_ref_1',\n",
    " 'begin_ref_2',\n",
    " 'begin_ref_3',\n",
    " 'begin_ref_4',\n",
    " 'begin_ref_5',\n",
    " 'begin_ref_6',\n",
    " 'begin_ref_7',\n",
    " 'begin_ref_8',\n",
    " 'begin_ref_9',\n",
    " 'begin_ref_10',\n",
    " 'begin_ref_11',\n",
    " 'begin_ref_12',\n",
    " 'abstract_0',\n",
    " 'abstract_1',\n",
    " 'key_0',\n",
    " 'key_1',\n",
    " 'annotation_0',\n",
    " 'annotation_1',\n",
    " 'sine_0',\n",
    " 'sine_1',\n",
    " 'sine_2',\n",
    " 'et_al_0',\n",
    " 'et_al_1',\n",
    " 'et_al_2',\n",
    " 'et_al_3',\n",
    " 'etc_0',\n",
    " 'etc_1'])\n",
    "boost_model.fit(train_dataset,eval_set=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DX2H1hLYEHdz",
    "outputId": "6c729d59-3e0a-4e7f-d4af-6e9bd302ce73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   IEEEannot       0.31      0.07      0.12     13829\n",
      "    IEEEtran       0.33      0.49      0.39     14633\n",
      "   IEEEtranN       0.48      0.55      0.51     14815\n",
      "   IEEEtranS       0.31      0.19      0.24     14399\n",
      "  IEEEtranSA       0.80      0.90      0.85     14944\n",
      "  IEEEtranSN       0.46      0.32      0.38     14934\n",
      "      JHEP-2       0.40      0.40      0.40     14299\n",
      "  aaai-named       0.94      0.88      0.91     13986\n",
      "    abstract       0.80      0.88      0.84     14027\n",
      "    acmtrans       0.65      0.71      0.68     14271\n",
      "      aichej       0.77      0.76      0.77     13692\n",
      "         aip       0.29      0.26      0.27     14315\n",
      "    alphanum       0.88      0.84      0.86     13942\n",
      "         ama       0.60      0.66      0.63     13918\n",
      "    amsalpha       0.96      0.93      0.94     10774\n",
      "    amsplain       0.70      0.83      0.76     10792\n",
      "    annotate       0.79      0.88      0.83     14295\n",
      "  annotation       1.00      1.00      1.00     12997\n",
      "         apa       0.56      0.63      0.60     14180\n",
      "apalike-ejor       0.96      0.90      0.93     13228\n",
      "     apasoft       0.94      0.93      0.94     14177\n",
      "      astron       0.75      0.91      0.82     13968\n",
      "         bbs       0.78      0.78      0.78     14346\n",
      " besjournals       0.72      0.79      0.76     14155\n",
      "  bestpapers       0.86      0.34      0.49       185\n",
      "     biolett       0.68      0.78      0.73     13722\n",
      "      bookdb       0.86      0.86      0.86     10884\n",
      "         cbe       0.62      0.61      0.61     14536\n",
      "     chicago       0.36      0.42      0.39     14260\n",
      "    chicagoa       0.38      0.32      0.35     14338\n",
      "          cj       0.48      0.53      0.50     14280\n",
      "         cpc       0.34      0.37      0.35     14246\n",
      "      decsci       0.65      0.66      0.65     14064\n",
      " development       0.76      0.90      0.82     14091\n",
      "         fbs       0.68      0.87      0.76     14321\n",
      "    finplain       0.33      0.45      0.38     14119\n",
      "    generate       0.45      0.24      0.31      3453\n",
      " h-elsevier3       0.52      0.37      0.43     14435\n",
      "  h-physrev3       0.29      0.11      0.16     14027\n",
      "  h-physrev4       0.24      0.21      0.23     13830\n",
      "  h-physrev5       0.21      0.08      0.12     13847\n",
      "        hum2       0.79      0.80      0.79     14387\n",
      "    humanbio       0.58      0.55      0.57     14321\n",
      "    humannat       0.68      0.52      0.59     14422\n",
      "        iaea       0.50      0.76      0.61     14326\n",
      "       jbact       0.50      0.75      0.60     14291\n",
      "         jcc       0.68      0.61      0.65     14214\n",
      "         jcp       0.33      0.11      0.16     14016\n",
      "         jmb       0.87      0.83      0.85     14134\n",
      "   jneurosci       0.80      0.83      0.81     14394\n",
      "         jpc       0.70      0.68      0.69     14031\n",
      "    jphysiol       0.68      0.84      0.75     14259\n",
      "     jqt1999       0.84      0.80      0.82     14134\n",
      "         jtb       0.77      0.77      0.77     14208\n",
      "      jtbnew       0.72      0.56      0.63     14055\n",
      "         mla       0.44      0.34      0.38     14345\n",
      "        mlaa       0.44      0.46      0.45     14409\n",
      "    namunsrt       0.99      1.00      0.99     14083\n",
      "         nar       0.60      0.66      0.63     14067\n",
      "      natbib       0.85      0.89      0.87     14036\n",
      "      neuron       0.74      0.77      0.75     14119\n",
      "   newcastle       0.90      0.89      0.90     12972\n",
      "          nf       0.43      0.27      0.33     14102\n",
      "       nflet       0.44      0.27      0.33     14261\n",
      "        pccp       0.59      0.59      0.59     14027\n",
      "  perception       0.98      0.98      0.98     13939\n",
      "          pf       0.31      0.17      0.22     14022\n",
      "       phjcp       0.29      0.08      0.12     14217\n",
      "     plainyr       0.22      0.51      0.31     14667\n",
      "        pnas       0.47      0.57      0.51     14326\n",
      "    pnas2009       0.45      0.39      0.42     13908\n",
      "        ppcf       0.71      0.80      0.75     14303\n",
      "      report       0.20      0.32      0.24     14044\n",
      " revcompchem       0.52      0.70      0.60     14446\n",
      "         rmp       0.96      0.81      0.88     13350\n",
      "       these       0.96      0.96      0.96     14262\n",
      "   ugost2003       0.47      0.40      0.43     10994\n",
      "  ugost2003s       0.47      0.55      0.51     10764\n",
      "   ugost2008       0.19      0.18      0.18     11132\n",
      "  ugost2008l       0.24      0.31      0.27     10899\n",
      " ugost2008ls       0.19      0.14      0.16     10954\n",
      "ugost2008mod       0.55      0.48      0.51     11049\n",
      "  ugost2008n       0.31      0.22      0.25        65\n",
      " ugost2008ns       0.28      0.25      0.26        61\n",
      "  ugost2008s       0.20      0.15      0.17     11023\n",
      "      utcaps       0.56      0.53      0.54     14049\n",
      "      utphys       0.50      0.53      0.52     13764\n",
      "         vak       0.65      1.00      0.79     14008\n",
      "   vancouver       0.82      0.84      0.83     13498\n",
      "     wmaainf       0.98      0.94      0.96     14207\n",
      "     zootaxa       0.81      0.83      0.82     14338\n",
      "\n",
      "    accuracy                           0.61   1201456\n",
      "   macro avg       0.59      0.59      0.58   1201456\n",
      "weighted avg       0.60      0.61      0.60   1201456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, boost_model.predict(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1R9yOQCfwZ9V",
    "outputId": "6858623c-3ccc-4d94-adb4-87b1c7af75d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn': {'Accuracy': 0.6170623674350406, 'MultiClass': 1.0738434509268624},\n",
       " 'validation': {'Accuracy': 0.6065057729954322,\n",
       "  'MultiClass': 1.082117239416175}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model.get_best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "An4Mj6_jsjiP",
    "outputId": "a89bec5b-38db-474d-ed7f-a27120fa3c06",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c48cd9cb-155d-4146-9340-de4ccd066df2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>begin_ref_1</td>\n",
       "      <td>21.717033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ampersands</td>\n",
       "      <td>15.680614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>round_brackets</td>\n",
       "      <td>15.167533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>begin_ref_3</td>\n",
       "      <td>13.150782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>begin_ref_5</td>\n",
       "      <td>6.249451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dots</td>\n",
       "      <td>4.739864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>begin_ref_11</td>\n",
       "      <td>3.814263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>slashes</td>\n",
       "      <td>2.868023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>colons</td>\n",
       "      <td>2.307490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>page_ref</td>\n",
       "      <td>2.163333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>commas</td>\n",
       "      <td>2.147454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>quotes</td>\n",
       "      <td>1.894138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>capital_letters</td>\n",
       "      <td>1.798586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ands</td>\n",
       "      <td>1.313437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>et_al_1</td>\n",
       "      <td>0.936240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>semicolons</td>\n",
       "      <td>0.638012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>et_al_0</td>\n",
       "      <td>0.568039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>begin_ref_7</td>\n",
       "      <td>0.517335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>years</td>\n",
       "      <td>0.415436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>begin_ref_8</td>\n",
       "      <td>0.412528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>key_0</td>\n",
       "      <td>0.270928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>begin_ref_2</td>\n",
       "      <td>0.254684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>begin_ref_4</td>\n",
       "      <td>0.238117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>square_brackets</td>\n",
       "      <td>0.195622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tirets</td>\n",
       "      <td>0.188894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>begin_ref_6</td>\n",
       "      <td>0.160843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>begin_ref_10</td>\n",
       "      <td>0.111425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>begin_ref_9</td>\n",
       "      <td>0.069638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>begin_ref_12</td>\n",
       "      <td>0.006662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>et_al_2</td>\n",
       "      <td>0.003596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>inverse_slashes</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>abstract_0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>abstract_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>key_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>annotation_0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>annotation_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>sine_0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sine_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sine_2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>et_al_3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>etc_0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>etc_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c48cd9cb-155d-4146-9340-de4ccd066df2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c48cd9cb-155d-4146-9340-de4ccd066df2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c48cd9cb-155d-4146-9340-de4ccd066df2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         Feature Id  Importances\n",
       "0       begin_ref_1    21.717033\n",
       "1        ampersands    15.680614\n",
       "2    round_brackets    15.167533\n",
       "3       begin_ref_3    13.150782\n",
       "4       begin_ref_5     6.249451\n",
       "5              dots     4.739864\n",
       "6      begin_ref_11     3.814263\n",
       "7           slashes     2.868023\n",
       "8            colons     2.307490\n",
       "9          page_ref     2.163333\n",
       "10           commas     2.147454\n",
       "11           quotes     1.894138\n",
       "12  capital_letters     1.798586\n",
       "13             ands     1.313437\n",
       "14          et_al_1     0.936240\n",
       "15       semicolons     0.638012\n",
       "16          et_al_0     0.568039\n",
       "17      begin_ref_7     0.517335\n",
       "18            years     0.415436\n",
       "19      begin_ref_8     0.412528\n",
       "20            key_0     0.270928\n",
       "21      begin_ref_2     0.254684\n",
       "22      begin_ref_4     0.238117\n",
       "23  square_brackets     0.195622\n",
       "24           tirets     0.188894\n",
       "25      begin_ref_6     0.160843\n",
       "26     begin_ref_10     0.111425\n",
       "27      begin_ref_9     0.069638\n",
       "28     begin_ref_12     0.006662\n",
       "29          et_al_2     0.003596\n",
       "30  inverse_slashes     0.000000\n",
       "31       abstract_0     0.000000\n",
       "32       abstract_1     0.000000\n",
       "33            key_1     0.000000\n",
       "34     annotation_0     0.000000\n",
       "35     annotation_1     0.000000\n",
       "36           sine_0     0.000000\n",
       "37           sine_1     0.000000\n",
       "38           sine_2     0.000000\n",
       "39          et_al_3     0.000000\n",
       "40            etc_0     0.000000\n",
       "41            etc_1     0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-7qnVppjsEN"
   },
   "outputs": [],
   "source": [
    "metrics = boost_model.eval_metrics(\n",
    "    data=train_dataset,\n",
    "    metrics=['Precision','Recall','F1','Accuracy'],\n",
    "    ntree_start=0,\n",
    "    ntree_end=0,\n",
    "    eval_period=1,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ch-hQJ7VEB_V"
   },
   "outputs": [],
   "source": [
    "from catboost import cv\n",
    "\n",
    "params = {\n",
    "    'loss_function': 'MultiClass',\n",
    "    'iterations': 250,\n",
    "    'depth': 10,\n",
    "    'random_seed': 0,\n",
    "    'learning_rate': 0.05,\n",
    "    'task_type': 'GPU',\n",
    "    'gpu_ram_part': 0.95,\n",
    "    'eval_metric': 'Accuracy'\n",
    "}\n",
    "\n",
    "cv_data = cv(\n",
    "    params=params,\n",
    "    pool=catboost.Pool(data=X, label=y),\n",
    "    fold_count=5,\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "    plot=True,\n",
    "    stratified=True, \n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eV63aUhvv5zF"
   },
   "outputs": [],
   "source": [
    "cv_model = catboost.CatBoostClassifier(\n",
    "                           loss_function='MultiClass',\n",
    "                           task_type='GPU',\n",
    "                           gpu_ram_part=0.95,\n",
    "                           eval_metric='Accuracy',\n",
    "                          )\n",
    "\n",
    "parameters = {\n",
    "    'iterations': range(150, 351, 50),\n",
    "    'depth': range(6, 14),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "cv_model.grid_search(parameters, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKFlVxAYWVav"
   },
   "source": [
    "# Наивная байесовская классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jwmh1TY6YnxC"
   },
   "outputs": [],
   "source": [
    "precisions = precision_score(y_test, bayes_clf.predict(X_test), average=None)\n",
    "recalls = recall_score(y_test, bayes_clf.predict(X_test), average=None)\n",
    "f1_scores = f1_score(y_test, bayes_clf.predict(X_test), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZXb97UaqYpEB",
    "outputId": "5aa1e741-5b4b-43ba-aed5-ace6eb748ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  min =  0.09152843601895734 max =  0.9041331535636246 mean =  0.3503485530217752 median =  0.34906358513121194\n",
      "recall:  min =  0.00959335624284078 max =  0.9831151104595319 mean =  0.32680261035539704 median =  0.3074704491725768\n",
      "f1_score:  min =  0.018126888217522657 max =  0.9419714216517318 mean =  0.31132752247121714 median =  0.2896955711369486\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", \"min = \", precisions.min(), \"max = \", precisions.max(), \"mean = \", np.mean(precisions), \"median = \", np.median(precisions))\n",
    "print(\"recall: \", \"min = \", recalls.min(), \"max = \", recalls.max(), \"mean = \", np.mean(recalls), \"median = \", np.median(recalls))\n",
    "print(\"f1_score: \", \"min = \", f1_scores.min(), \"max = \", f1_scores.max(), \"mean = \", np.mean(f1_scores), \"median = \", np.median(f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CK8Yl6bobmCi"
   },
   "outputs": [],
   "source": [
    "cv_bayes_clf = MultinomialNB()\n",
    "parameters = {'var_smoothing': [1e-2, 5e-2, 1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5, 1e-6, 5e-6, 1e-7, 5e-7]}\n",
    "grid = GridSearchCV(cv_bayes_clf, parameters)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BF3i-FQiMFg",
    "outputId": "24d874f0-6836-4b05-d825-f2ee5e4f26e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3669924935522677"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf = grid.best_estimator_\n",
    "best_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvdT1AIu3ZOT"
   },
   "source": [
    "# Линейная классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyU0dwPP3XuK"
   },
   "outputs": [],
   "source": [
    "sgd_clf_1 = SGDClassifier(loss='hinge', early_stopping=True, n_jobs=-1, random_state=0)\n",
    "sgd_clf_1.fit(X_train, y_train)\n",
    "sgd_clf_1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03akx5tiDij2"
   },
   "outputs": [],
   "source": [
    "precisions = precision_score(y_test, sgd_clf_1.predict(X_test), average=None)\n",
    "recalls = recall_score(y_test, sgd_clf_1.predict(X_test), average=None)\n",
    "f1_scores = f1_score(y_test, sgd_clf_1.predict(X_test), average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zAwyq5PQxYV",
    "outputId": "30b73f73-67a4-4068-8921-897feeaadd5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  min =  0.0 max =  0.9944520765085069 mean =  0.40912341157097065 median =  0.38881491344873503\n",
      "recall:  min =  0.0 max =  0.9994787223959815 mean =  0.39585435843587163 median =  0.3600458190148912\n",
      "f1_score:  min =  0.0 max =  0.9946708168270137 mean =  0.36837470035717856 median =  0.3093249349582364\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", \"min = \", precisions.min(), \"max = \", precisions.max(), \"mean = \", np.mean(precisions), \"median = \", np.median(precisions))\n",
    "print(\"recall: \", \"min = \", recalls.min(), \"max = \", recalls.max(), \"mean = \", np.mean(recalls), \"median = \", np.median(recalls))\n",
    "print(\"f1_score: \", \"min = \", f1_scores.min(), \"max = \", f1_scores.max(), \"mean = \", np.mean(f1_scores), \"median = \", np.median(f1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vKVcGJxfEHP"
   },
   "source": [
    "# Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "c1gM9DlOfKp2"
   },
   "outputs": [],
   "source": [
    "text_data_frame = pd.read_csv('./bib_data_union_v3.csv.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ASdzdbVhf1k",
    "outputId": "7ec661d3-cf30-4269-f83e-c3f53d884159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6006215, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "T5yg-GxmhxjP",
    "outputId": "32acb44f-d4c6-42b6-c2ba-58ec3205caf9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_record</th>\n",
       "      <th>style_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ num ] sp upword , sp caplet . sp caplet . sp...</td>\n",
       "      <td>iaea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ capword sp othword sp capword ( year ) ] sp ...</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ capword ( year ) ] sp caplet . sp caplet . s...</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ capword sp othword sp capword ( year ) ] sp ...</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ capword ( year ) ] sp capword sp caplet . sp...</td>\n",
       "      <td>bestpapers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    tokenized_record  style_name\n",
       "0  [ num ] sp upword , sp caplet . sp caplet . sp...        iaea\n",
       "1  [ capword sp othword sp capword ( year ) ] sp ...  bestpapers\n",
       "2  [ capword ( year ) ] sp caplet . sp caplet . s...  bestpapers\n",
       "3  [ capword sp othword sp capword ( year ) ] sp ...  bestpapers\n",
       "4  [ capword ( year ) ] sp capword sp caplet . sp...  bestpapers"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CVb7WAkyg_O0"
   },
   "outputs": [],
   "source": [
    "corpus = text_data_frame.tokenized_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# ngram_range=(1, 1) => униграммы, ngram_range=(2, 2) => биграммы и т.д.\n",
    "vectorizer = CountVectorizer(tokenizer=lambda txt: txt.split(), ngram_range=(3, 3))\n",
    "vectorized_data = vectorizer.fit_transform(corpus).toarray()\n",
    "print(\"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# временный код\n",
    "X = pd.read_csv('2grams_bib_data.csv')\n",
    "y = X.style_name\n",
    "X = X.drop(['style_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data=vectorized_data, columns=vectorizer.get_feature_names())\n",
    "y = text_data_frame.style_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная классификация на новом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf_1 = SGDClassifier(loss='hinge', early_stopping=False, n_jobs=-1, random_state=0)\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "sgd_clf_1.fit(X_train, y_train)\n",
    "\n",
    "t_finish = time.time()\n",
    "print(t_finish - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   IEEEannot       0.31      0.04      0.07     20957\n",
      "    IEEEtran       0.25      0.73      0.37     21931\n",
      "   IEEEtranN       0.43      0.41      0.42     21967\n",
      "   IEEEtranS       0.34      0.01      0.01     21680\n",
      "  IEEEtranSA       0.73      0.80      0.77     22415\n",
      "  IEEEtranSN       0.36      0.57      0.44     22108\n",
      "      JHEP-2       0.79      0.58      0.67     21360\n",
      "  aaai-named       0.91      0.90      0.91     20922\n",
      "    abstract       0.75      0.00      0.00     21111\n",
      "    acmtrans       0.71      0.76      0.74     21473\n",
      "      aichej       0.96      0.91      0.94     20369\n",
      "         aip       0.16      0.00      0.01     21412\n",
      "    alphanum       0.35      0.88      0.50     20977\n",
      "         ama       0.96      0.90      0.93     20961\n",
      "    amsalpha       0.97      0.92      0.94     16073\n",
      "    amsplain       0.96      0.83      0.89     16271\n",
      "    annotate       0.51      0.04      0.08     21166\n",
      "  annotation       0.97      0.94      0.95     19652\n",
      "         apa       0.76      0.86      0.81     21645\n",
      "apalike-ejor       0.93      0.88      0.91     19949\n",
      "     apasoft       0.97      0.96      0.96     21763\n",
      "      astron       0.97      0.98      0.97     21605\n",
      "         bbs       0.79      0.82      0.81     21412\n",
      " besjournals       0.97      0.93      0.95     21461\n",
      "  bestpapers       0.00      0.00      0.00       300\n",
      "     biolett       0.95      0.96      0.96     20687\n",
      "      bookdb       0.99      0.89      0.94     16427\n",
      "         cbe       0.89      0.79      0.84     21583\n",
      "     chicago       0.46      0.19      0.27     21344\n",
      "    chicagoa       0.44      0.65      0.52     21509\n",
      "          cj       0.90      0.90      0.90     21088\n",
      "         cpc       0.39      0.74      0.51     21448\n",
      "      decsci       0.92      0.82      0.87     21205\n",
      " development       0.94      0.92      0.93     21407\n",
      "         fbs       1.00      0.96      0.98     21308\n",
      "    finplain       0.61      0.64      0.62     20924\n",
      "    generate       0.47      0.36      0.41      5122\n",
      " h-elsevier3       0.29      0.64      0.40     21416\n",
      "  h-physrev3       0.02      0.01      0.01     20967\n",
      "  h-physrev4       0.26      0.05      0.09     21228\n",
      "  h-physrev5       0.15      0.50      0.23     20880\n",
      "        hum2       0.82      0.82      0.82     21527\n",
      "    humanbio       0.73      0.77      0.75     21181\n",
      "    humannat       0.86      0.96      0.91     21317\n",
      "        iaea       0.50      0.51      0.50     21432\n",
      "       jbact       0.96      0.86      0.91     21569\n",
      "         jcc       0.60      0.63      0.61     21342\n",
      "         jcp       0.30      0.16      0.21     20980\n",
      "         jmb       0.89      0.84      0.86     21214\n",
      "   jneurosci       0.91      0.95      0.93     21520\n",
      "         jpc       0.66      0.73      0.69     21432\n",
      "    jphysiol       0.91      0.90      0.90     21382\n",
      "     jqt1999       0.88      0.64      0.74     21399\n",
      "         jtb       1.00      0.97      0.99     21603\n",
      "      jtbnew       0.95      0.73      0.83     20839\n",
      "         mla       0.09      0.06      0.07     21279\n",
      "        mlaa       0.47      0.60      0.53     21366\n",
      "    namunsrt       0.98      1.00      0.99     21096\n",
      "         nar       0.92      0.85      0.89     21122\n",
      "      natbib       0.91      0.96      0.93     21296\n",
      "      neuron       0.92      0.87      0.89     21383\n",
      "   newcastle       0.97      0.89      0.93     19237\n",
      "          nf       0.35      0.31      0.33     21449\n",
      "       nflet       0.57      0.43      0.49     21458\n",
      "        pccp       0.78      0.78      0.78     20999\n",
      "  perception       1.00      0.96      0.98     21245\n",
      "          pf       0.19      0.41      0.26     20949\n",
      "       phjcp       0.09      0.04      0.05     21479\n",
      "     plainyr       0.01      0.00      0.00     21520\n",
      "        pnas       0.50      0.72      0.59     21517\n",
      "    pnas2009       0.51      0.26      0.35     20951\n",
      "        ppcf       0.66      0.88      0.75     21268\n",
      "      report       0.42      0.53      0.47     21057\n",
      " revcompchem       0.69      0.79      0.74     21249\n",
      "         rmp       0.91      0.94      0.92     19812\n",
      "       these       0.94      0.90      0.92     21288\n",
      "   ugost2003       0.50      0.00      0.00     16521\n",
      "  ugost2003s       0.50      0.94      0.65     16514\n",
      "   ugost2008       0.23      0.08      0.11     16539\n",
      "  ugost2008l       0.23      0.57      0.33     16307\n",
      " ugost2008ls       0.24      0.08      0.12     16257\n",
      "ugost2008mod       0.73      0.40      0.51     16531\n",
      "  ugost2008n       0.67      0.05      0.09        80\n",
      " ugost2008ns       0.44      0.31      0.36        87\n",
      "  ugost2008s       0.22      0.27      0.24     16558\n",
      "      utcaps       0.51      0.54      0.52     20887\n",
      "      utphys       0.55      0.47      0.51     20786\n",
      "         vak       0.97      0.98      0.97     20920\n",
      "   vancouver       0.99      0.94      0.96     20300\n",
      "     wmaainf       0.90      0.89      0.90     21200\n",
      "     zootaxa       0.93      0.90      0.91     21510\n",
      "\n",
      "    accuracy                           0.65   1802237\n",
      "   macro avg       0.65      0.62      0.61   1802237\n",
      "weighted avg       0.66      0.65      0.63   1802237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, sgd_clf_1.predict(X_test), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.6365399183623635\n",
      "precision:  min =  0.0 max =  1.0 mean =  0.6484155952821647 median =  0.723570564864398\n",
      "recall:  min =  0.0 max =  0.986599586232838 mean =  0.6283646477473733 median =  0.7510262529832935\n",
      "f1_score:  min =  0.0 max =  0.9863568634755074 mean =  0.6173944345170069 median =  0.6971282255038298\n"
     ]
    }
   ],
   "source": [
    "print_metrics(sgd_clf_1, X_test, y_test, _average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./SGDClassifier_2grams.sav']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './SGDClassifier_2grams.sav'\n",
    "joblib.dump(sgd_clf_1, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6455904523101013"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_clf = joblib.load('./SGDClassifier_2grams.sav')\n",
    "loaded_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивный Байесовский алгоритм на новом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   IEEEannot       0.17      0.01      0.01     20807\n",
      "    IEEEtran       0.23      0.56      0.32     21899\n",
      "   IEEEtranN       0.46      0.53      0.49     21766\n",
      "   IEEEtranS       0.22      0.00      0.01     21727\n",
      "  IEEEtranSA       0.48      0.43      0.46     22438\n",
      "  IEEEtranSN       0.41      0.02      0.03     22245\n",
      "      JHEP-2       0.75      0.30      0.43     21299\n",
      "  aaai-named       0.60      0.26      0.37     20864\n",
      "    abstract       0.39      0.10      0.15     20966\n",
      "    acmtrans       0.51      0.17      0.26     21347\n",
      "      aichej       0.89      0.44      0.59     20229\n",
      "         aip       0.20      0.06      0.09     21472\n",
      "    alphanum       0.40      0.33      0.36     20913\n",
      "         ama       0.86      0.69      0.77     20797\n",
      "    amsalpha       0.74      0.58      0.65     16031\n",
      "    amsplain       0.64      0.68      0.66     16277\n",
      "    annotate       0.28      0.08      0.12     21378\n",
      "  annotation       0.88      0.37      0.53     19443\n",
      "         apa       0.74      0.17      0.28     21541\n",
      "apalike-ejor       0.90      0.75      0.82     19905\n",
      "     apasoft       0.95      0.93      0.94     21600\n",
      "      astron       0.13      0.98      0.22     21467\n",
      "         bbs       0.66      0.46      0.55     21385\n",
      " besjournals       0.73      0.91      0.81     21364\n",
      "     biolett       0.75      0.65      0.70     20804\n",
      "      bookdb       0.68      0.88      0.77     16459\n",
      "         cbe       0.59      0.18      0.28     21420\n",
      "     chicago       0.34      0.02      0.05     21335\n",
      "    chicagoa       0.36      0.38      0.37     21484\n",
      "          cj       0.75      0.70      0.72     21032\n",
      "         cpc       0.78      0.08      0.14     21409\n",
      "      decsci       0.81      0.41      0.55     21006\n",
      " development       0.58      0.91      0.71     21494\n",
      "         fbs       0.97      0.93      0.95     21342\n",
      "    finplain       0.50      0.08      0.14     21091\n",
      "    generate       0.20      0.86      0.32      5124\n",
      " h-elsevier3       0.07      0.91      0.13     21310\n",
      "  h-physrev3       0.15      0.04      0.07     20884\n",
      "  h-physrev4       0.25      0.00      0.00     20986\n",
      "  h-physrev5       0.38      0.05      0.09     21051\n",
      "        hum2       0.56      0.22      0.31     21491\n",
      "    humanbio       0.52      0.23      0.32     21422\n",
      "    humannat       0.87      0.34      0.49     21482\n",
      "        iaea       0.36      0.14      0.20     21641\n",
      "       jbact       0.43      0.86      0.57     21554\n",
      "         jcc       0.50      0.29      0.37     21315\n",
      "         jcp       0.17      0.14      0.15     20961\n",
      "         jmb       0.38      0.93      0.54     21390\n",
      "   jneurosci       0.98      0.71      0.83     21354\n",
      "         jpc       0.46      0.77      0.57     21263\n",
      "    jphysiol       0.85      0.81      0.83     21570\n",
      "     jqt1999       0.98      0.57      0.72     21355\n",
      "         jtb       0.27      0.96      0.42     21636\n",
      "      jtbnew       0.58      0.66      0.62     20830\n",
      "         mla       0.40      0.16      0.23     21401\n",
      "        mlaa       0.22      0.01      0.01     21432\n",
      "    namunsrt       0.99      0.97      0.98     21268\n",
      "         nar       0.79      0.41      0.54     21039\n",
      "      natbib       0.80      0.86      0.82     21264\n",
      "      neuron       0.52      0.77      0.62     21321\n",
      "   newcastle       0.91      0.54      0.68     19367\n",
      "          nf       0.42      0.02      0.03     21261\n",
      "       nflet       0.48      0.30      0.37     21546\n",
      "        pccp       0.33      0.57      0.42     21004\n",
      "  perception       0.98      0.86      0.92     20945\n",
      "          pf       0.24      0.04      0.07     21002\n",
      "       phjcp       0.19      0.00      0.01     21548\n",
      "     plainyr       0.61      0.11      0.19     21776\n",
      "        pnas       0.49      0.79      0.60     21664\n",
      "    pnas2009       0.45      0.04      0.08     20937\n",
      "        ppcf       0.48      0.37      0.41     21297\n",
      "      report       0.66      0.03      0.06     21029\n",
      " revcompchem       0.48      0.49      0.48     21512\n",
      "         rmp       0.61      0.11      0.18     19847\n",
      "       these       0.87      0.75      0.81     21348\n",
      "   ugost2003       0.41      0.08      0.13     16508\n",
      "  ugost2003s       0.48      0.91      0.63     16283\n",
      "   ugost2008       0.19      0.18      0.19     16374\n",
      "  ugost2008l       0.17      0.71      0.28     16503\n",
      " ugost2008ls       0.18      0.05      0.08     16488\n",
      "ugost2008mod       0.81      0.38      0.52     16579\n",
      " ugost2008ns       0.02      0.97      0.03        70\n",
      "  ugost2008s       0.16      0.05      0.08     16611\n",
      "      utcaps       0.30      0.02      0.04     20867\n",
      "      utphys       0.35      0.23      0.28     20950\n",
      "         vak       0.99      0.94      0.96     21134\n",
      "   vancouver       0.86      0.89      0.87     20201\n",
      "     wmaainf       0.76      0.51      0.61     21369\n",
      "     zootaxa       0.86      0.72      0.78     21465\n",
      "\n",
      "    accuracy                           0.43   1801865\n",
      "   macro avg       0.54      0.44      0.41   1801865\n",
      "weighted avg       0.55      0.43      0.42   1801865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, nb_clf.predict(X_test), zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.5512366353750142\n",
      "precision:  min =  0.10247349823321555 max =  0.9970263381478335 mean =  0.5722132801623461 median =  0.5541376455116653\n",
      "recall:  min =  0.04753208054981497 max =  0.9693084500767288 mean =  0.5548585606161551 median =  0.5698594245981761\n",
      "f1_score:  min =  0.08279961488551217 max =  0.9730892381394668 mean =  0.5415205346974971 median =  0.582771258739105\n"
     ]
    }
   ],
   "source": [
    "print_metrics(nb_clf, X_test, y_test, _average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг на новом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = catboost.Pool(data=X_train, label=y_train)\n",
    "test_data = catboost.Pool(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(_iterations: int, _learning_rate: float, _depth: int):\n",
    "    boost_model = catboost.CatBoostClassifier(iterations=_iterations,\n",
    "                           learning_rate=_learning_rate,\n",
    "                           depth=_depth,\n",
    "                           loss_function='MultiClass',\n",
    "#                            task_type='GPU',\n",
    "#                            gpu_ram_part=0.75,\n",
    "                           eval_metric='Accuracy')\n",
    "    time_start = time.time()\n",
    "    boost_model.fit(train_dataset,eval_set=(X_val, y_val))\n",
    "    time_finish = time.time()\n",
    "    print(time_finish - time_start)\n",
    "    return boost_model\n",
    "\n",
    "# boost_model_1 = gradient_boosting(250, 0.05, 6)\n",
    "# print(\"SUCCESS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_model_1.get_best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(boost_model_1, X_test, y_test, _average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ num</td>\n",
       "      <td>15.665995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>( year</td>\n",
       "      <td>11.726335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>) .</td>\n",
       "      <td>7.452743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>. ,</td>\n",
       "      <td>5.989705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num ]</td>\n",
       "      <td>5.017204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>— num</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>— othword</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>— smallet</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>— upword</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>— year</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature Id  Importances\n",
       "0        [ num    15.665995\n",
       "1       ( year    11.726335\n",
       "2          ) .     7.452743\n",
       "3          . ,     5.989705\n",
       "4        num ]     5.017204\n",
       "..         ...          ...\n",
       "457      — num     0.000000\n",
       "458  — othword     0.000000\n",
       "459  — smallet     0.000000\n",
       "460   — upword     0.000000\n",
       "461     — year     0.000000\n",
       "\n",
       "[462 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model_1.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = boost_model_1.eval_metrics(\n",
    "    data=train_dataset,\n",
    "    metrics=['Precision','Recall','F1','Accuracy'],\n",
    "    ntree_start=0,\n",
    "    ntree_end=0,\n",
    "    eval_period=1,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './CatBoostClassifier_2grams_v2.sav'\n",
    "joblib.dump(boost_model_1, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SGDClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ab06ae24ef20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloaded_catboost_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./CatBoostClassifier_2grams.sav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print_metrics(loaded_catboost_model, X_test, y_test, _average=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_catboost_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'catboost_2grams_feature_importances.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SGDClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "loaded_catboost_model = joblib.load('./CatBoostClassifier_2grams.sav')\n",
    "# print_metrics(loaded_catboost_model, X_test, y_test, _average=None)\n",
    "fi = loaded_catboost_model.feature_importances_\n",
    "f = open('catboost_2grams_feature_importances.txt', 'w')\n",
    "f.write(fi)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest на новом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 8\n",
      "0.6121901870259536\n",
      "accuracy = 0.6121901870259536\n",
      "precision:  min =  0.0 max =  0.9922599488864549 mean =  0.5980777286744221 median =  0.6239096724171351\n",
      "recall:  min =  0.0 max =  0.9895473061255861 mean =  0.5889736611021662 median =  0.6566919076726576\n",
      "f1_score:  min =  0.0 max =  0.9842465505377902 mean =  0.5712248490553617 median =  0.5860415116182917\n",
      "___________________________\n",
      "20 9\n",
      "0.6254969866607407\n",
      "accuracy = 0.6254969866607407\n",
      "precision:  min =  0.0 max =  0.9902464065708418 mean =  0.6207565322099907 median =  0.624644315229494\n",
      "recall:  min =  0.0 max =  0.9809168519979913 mean =  0.6032118706864673 median =  0.6765921670286555\n",
      "f1_score:  min =  0.0 max =  0.9801117805037382 mean =  0.5878706135994055 median =  0.6192770198212775\n",
      "___________________________\n",
      "20 10\n",
      "0.6454280556408662\n",
      "accuracy = 0.6454280556408662\n",
      "precision:  min =  0.0 max =  0.9898599358039101 mean =  0.6252949321279772 median =  0.6232141723284018\n",
      "recall:  min =  0.0 max =  0.9942031059901238 mean =  0.6201769396455216 median =  0.7018633540372671\n",
      "f1_score:  min =  0.0 max =  0.9823354810685586 mean =  0.6019909394066633 median =  0.6472813095706376\n",
      "___________________________\n",
      "20 11\n",
      "0.6591817999468993\n",
      "accuracy = 0.6591817999468993\n",
      "precision:  min =  0.1888917998428085 max =  1.0 mean =  0.6510102760387438 median =  0.6906576728499156\n",
      "recall:  min =  0.0055008685581933985 max =  0.9975667358477063 mean =  0.6339937901701653 median =  0.741009730644479\n",
      "f1_score:  min =  0.010731431798926857 max =  0.9910486393212784 mean =  0.6193367398712646 median =  0.6888246628131021\n",
      "___________________________\n",
      "20 12\n",
      "0.6731111593844648\n",
      "accuracy = 0.6731111593844648\n",
      "precision:  min =  0.17777777777777778 max =  0.9936104530117023 mean =  0.6613794459726209 median =  0.7345554537121907\n",
      "recall:  min =  0.011001737116386797 max =  0.9953481714735561 mean =  0.6478533331602974 median =  0.775006888950124\n",
      "f1_score:  min =  0.02087338643229882 max =  0.9940029446619025 mean =  0.6367816575509253 median =  0.734720241138951\n",
      "___________________________\n",
      "30 8\n",
      "0.6189942329988323\n",
      "accuracy = 0.6189942329988323\n",
      "precision:  min =  0.0 max =  0.9939469993356462 mean =  0.606891209335614 median =  0.6315643619232368\n",
      "recall:  min =  0.0 max =  0.9876905460531024 mean =  0.597180056393067 median =  0.6403933965577802\n",
      "f1_score:  min =  0.0 max =  0.9805206626615692 mean =  0.577081548444821 median =  0.608611638916621\n",
      "___________________________\n",
      "30 9\n",
      "0.6459524041378587\n",
      "accuracy = 0.6459524041378587\n",
      "precision:  min =  0.0 max =  0.9903318903318903 mean =  0.6243164297732058 median =  0.6713718820861678\n",
      "recall:  min =  0.0 max =  0.9921992413941172 mean =  0.6211856879057444 median =  0.7632087184439234\n",
      "f1_score:  min =  0.0 max =  0.988264093887249 mean =  0.6005479914209069 median =  0.6677607458360977\n",
      "___________________________\n",
      "30 10\n",
      "0.656234628474121\n",
      "accuracy = 0.656234628474121\n",
      "precision:  min =  0.0 max =  0.991773609740046 mean =  0.6412477815964887 median =  0.6805763874009\n",
      "recall:  min =  0.0 max =  0.9985686681457095 mean =  0.6304394837144764 median =  0.7621617782827924\n",
      "f1_score:  min =  0.0 max =  0.98451207624824 mean =  0.6136257239052186 median =  0.6885222068764992\n",
      "___________________________\n",
      "30 11\n",
      "0.668243873653652\n",
      "accuracy = 0.668243873653652\n",
      "precision:  min =  0.175 max =  1.0 mean =  0.656561179570074 median =  0.7002788405421179\n",
      "recall:  min =  0.004053271569195136 max =  0.9972089028841337 mean =  0.6408477693620286 median =  0.7586231120477696\n",
      "f1_score:  min =  0.007936507936507936 max =  0.9935789360404635 mean =  0.6255738979087584 median =  0.7149715306464218\n",
      "___________________________\n",
      "30 12\n",
      "0.6810163372010277\n",
      "accuracy = 0.6810163372010277\n",
      "precision:  min =  0.17142857142857143 max =  0.9957144012290774 mean =  0.6730087554683193 median =  0.7318342563555081\n",
      "recall:  min =  0.003474232773595831 max =  0.998491162523351 mean =  0.6561468804137487 median =  0.7717885894294715\n",
      "f1_score:  min =  0.006810442678774121 max =  0.9964864477269467 mean =  0.6445370943832527 median =  0.7313448753954993\n",
      "___________________________\n",
      "40 8\n",
      "0.6333389097379839\n",
      "accuracy = 0.6333389097379839\n",
      "precision:  min =  0.0 max =  0.9949811794228356 mean =  0.6282342825915113 median =  0.6803656662082356\n",
      "recall:  min =  0.0 max =  0.9981392685894225 mean =  0.609756867260832 median =  0.727188414068631\n",
      "f1_score:  min =  0.0 max =  0.9816143007973205 mean =  0.5894646370266222 median =  0.6293732460243219\n",
      "___________________________\n",
      "40 9\n",
      "0.6510352553618796\n",
      "accuracy = 0.6510352553618796\n",
      "precision:  min =  0.0 max =  0.9947288612896238 mean =  0.639642785122441 median =  0.6655099286678234\n",
      "recall:  min =  0.0 max =  0.9975667358477063 mean =  0.6259203910430416 median =  0.75508356545961\n",
      "f1_score:  min =  0.0 max =  0.9922569957143371 mean =  0.6072124524698934 median =  0.6779520600905777\n",
      "___________________________\n",
      "40 10\n",
      "0.6589545822648692\n",
      "accuracy = 0.6589545822648692\n",
      "precision:  min =  0.0 max =  0.9946262823644357 mean =  0.6421096198878361 median =  0.6955187231430325\n",
      "recall:  min =  0.0 max =  0.9946194131573284 mean =  0.6324649383794025 median =  0.7376865410215091\n",
      "f1_score:  min =  0.0 max =  0.9890990470690154 mean =  0.6157831625759101 median =  0.6931260846600771\n",
      "___________________________\n",
      "40 11\n",
      "0.6725102393609274\n",
      "accuracy = 0.6725102393609274\n",
      "precision:  min =  0.15151515151515152 max =  1.0 mean =  0.6649364442295697 median =  0.7309990806006742\n",
      "recall:  min =  0.0014475969889982628 max =  0.9978530022185643 mean =  0.6458462004590358 median =  0.7575078753937697\n",
      "f1_score:  min =  0.002867794665901921 max =  0.98971972730224 mean =  0.631611028134404 median =  0.7167287553899857\n",
      "___________________________\n",
      "40 12\n",
      "0.6802681002188115\n",
      "accuracy = 0.6802681002188115\n",
      "precision:  min =  0.1487603305785124 max =  1.0 mean =  0.6685013159274936 median =  0.7467857142857143\n",
      "recall:  min =  0.0052113491603937466 max =  0.9989265011092822 mean =  0.6549770435022322 median =  0.7718912009090263\n",
      "f1_score:  min =  0.01006993006993007 max =  0.9950341849586182 mean =  0.6418074649589743 median =  0.7318607527831772\n",
      "___________________________\n",
      "50 8\n",
      "0.6373431011967631\n",
      "accuracy = 0.6373431011967631\n",
      "precision:  min =  0.0 max =  0.9935201548430531 mean =  0.6196776013955417 median =  0.6562458515863534\n",
      "recall:  min =  0.0 max =  0.9987833679238531 mean =  0.6121979612976045 median =  0.7413888123449986\n",
      "f1_score:  min =  0.0 max =  0.9787063953488373 mean =  0.5907694821122605 median =  0.6715483956863266\n",
      "___________________________\n",
      "50 9\n",
      "0.6496503094904581\n",
      "accuracy = 0.6496503094904581\n",
      "precision:  min =  0.0 max =  0.989843028624192 mean =  0.6400425807536639 median =  0.6845435557193759\n",
      "recall:  min =  0.0 max =  0.9989980677019967 mean =  0.6241589635265554 median =  0.7605993892479227\n",
      "f1_score:  min =  0.0 max =  0.9835011482070306 mean =  0.6063503686610889 median =  0.6597236265588137\n",
      "___________________________\n",
      "50 10\n",
      "0.6619849836578052\n",
      "accuracy = 0.6619849836578052\n",
      "precision:  min =  0.09090909090909091 max =  1.0 mean =  0.6579674015484624 median =  0.7096847745539532\n",
      "recall:  min =  0.00028951939779965256 max =  0.9942746725828383 mean =  0.635381328319056 median =  0.767430453366968\n",
      "f1_score:  min =  0.0005772005772005771 max =  0.9930617967429989 mean =  0.6189352334237966 median =  0.7020568192426175\n",
      "___________________________\n",
      "50 11\n",
      "0.6759326536778053\n",
      "accuracy = 0.6759326536778053\n",
      "precision:  min =  0.03333333333333333 max =  1.0 mean =  0.6697021109095074 median =  0.7496198385776114\n",
      "recall:  min =  0.00028951939779965256 max =  0.9988549345165677 mean =  0.649285730275621 median =  0.7824002256381328\n",
      "f1_score:  min =  0.000574052812858783 max =  0.9959755659360402 mean =  0.6351756387825411 median =  0.7268504093136561\n",
      "___________________________\n",
      "50 12\n",
      "0.6811536665692877\n",
      "accuracy = 0.6811536665692877\n",
      "precision:  min =  0.06493506493506493 max =  1.0 mean =  0.667462029825876 median =  0.7445112155649432\n",
      "recall:  min =  0.0014475969889982628 max =  0.9989265011092822 mean =  0.6536798879300858 median =  0.7652934692752824\n",
      "f1_score:  min =  0.0028320589068252617 max =  0.9957645369705672 mean =  0.6394675564399441 median =  0.7337916161207712\n",
      "___________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _n_estimators in range(20, 51, 10):\n",
    "    for _max_depth in range(10, 13):\n",
    "        rf_clf = RandomForestClassifier(criterion='entropy', n_estimators=_n_estimators, max_depth=_max_depth, n_jobs=-1)\n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        print(_n_estimators, _max_depth)\n",
    "        print(rf_clf.score(X_test, y_test))\n",
    "        print_metrics(rf_clf, X_test, y_test, _average=None)\n",
    "        print('___________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6972223963884883"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf_2 = RandomForestClassifier(criterion='entropy', n_estimators=200, max_depth=18, n_jobs=-1)\n",
    "rf_clf_2.fit(X_train, y_train)\n",
    "rf_clf_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rf_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f4d3406201fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "print_metrics(rf_clf, X_test, y_test, _average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка отдельными батчами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8b78b5011515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2grams_bib_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'style_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mget_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m     \"\"\"\n\u001b[1;32m    539\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chunksize = 6 * 10**5\n",
    "i = 0\n",
    "with pd.read_csv('2grams_bib_data.csv', chunksize=chunksize) as reader:\n",
    "    for chunk in reader:        \n",
    "        X = chunk.drop(['style_name'], axis=1)\n",
    "        y = chunk.style_name\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "        train_dataset = catboost.Pool(data=X_train, label=y_train)\n",
    "        test_data = catboost.Pool(data=X_test, label=y_test)\n",
    "        \n",
    "        if i == 0:\n",
    "            boost_model = catboost.CatBoostClassifier(iterations=250,\n",
    "                           learning_rate=0.05,\n",
    "                           depth=6,\n",
    "                            task_type='GPU',\n",
    "                                                      \n",
    "                           loss_function='MultiClass',\n",
    "                           eval_metric='Accuracy')\n",
    "            time_start = time.time()\n",
    "            boost_model.fit(train_dataset, eval_set=(X_val, y_val))\n",
    "            time_finish = time.time()\n",
    "            print(time_finish - time_start)\n",
    "        else:\n",
    "            time_start = time.time()\n",
    "            boost_model.fit(train_dataset, eval_set=(X_val, y_val), init_model='cat_boost_model.cbm')\n",
    "            time_finish = time.time()\n",
    "            print(time_finish - time_start)\n",
    "        print(boost_model.get_best_score())\n",
    "        boost_model.save_model('cat_boost_model.cbm')\n",
    "        i += 1\n",
    "        del X, y, X_train, X_test, y_train, y_test, X_val, y_val, train_dataset, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг (2-граммы) на GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 6858.1875 Total: 12053.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1694692\ttest: 0.1699597\tbest: 0.1699597 (0)\ttotal: 576ms\tremaining: 2m 23s\n",
      "1:\tlearn: 0.2919545\ttest: 0.2919556\tbest: 0.2919556 (1)\ttotal: 1.13s\tremaining: 2m 20s\n",
      "2:\tlearn: 0.3427248\ttest: 0.3420284\tbest: 0.3420284 (2)\ttotal: 1.67s\tremaining: 2m 17s\n",
      "3:\tlearn: 0.3530561\ttest: 0.3522557\tbest: 0.3522557 (3)\ttotal: 2.21s\tremaining: 2m 15s\n",
      "4:\tlearn: 0.3647705\ttest: 0.3641484\tbest: 0.3641484 (4)\ttotal: 2.79s\tremaining: 2m 16s\n",
      "5:\tlearn: 0.3886175\ttest: 0.3883591\tbest: 0.3883591 (5)\ttotal: 4.02s\tremaining: 2m 43s\n",
      "6:\tlearn: 0.4008640\ttest: 0.4006156\tbest: 0.4006156 (6)\ttotal: 5.27s\tremaining: 3m 3s\n",
      "7:\tlearn: 0.3993489\ttest: 0.3991066\tbest: 0.4006156 (6)\ttotal: 6.48s\tremaining: 3m 16s\n",
      "8:\tlearn: 0.3992793\ttest: 0.3990384\tbest: 0.4006156 (6)\ttotal: 7.66s\tremaining: 3m 25s\n",
      "9:\tlearn: 0.4323349\ttest: 0.4325284\tbest: 0.4325284 (9)\ttotal: 8.3s\tremaining: 3m 19s\n",
      "10:\tlearn: 0.4363022\ttest: 0.4365451\tbest: 0.4365451 (10)\ttotal: 8.87s\tremaining: 3m 12s\n",
      "11:\tlearn: 0.4472045\ttest: 0.4472435\tbest: 0.4472435 (11)\ttotal: 9.42s\tremaining: 3m 6s\n",
      "12:\tlearn: 0.4472111\ttest: 0.4472035\tbest: 0.4472435 (11)\ttotal: 9.96s\tremaining: 3m 1s\n",
      "13:\tlearn: 0.4487584\ttest: 0.4487433\tbest: 0.4487433 (13)\ttotal: 10.5s\tremaining: 2m 57s\n",
      "14:\tlearn: 0.4660314\ttest: 0.4660176\tbest: 0.4660176 (14)\ttotal: 11.1s\tremaining: 2m 53s\n",
      "15:\tlearn: 0.4662927\ttest: 0.4662141\tbest: 0.4662141 (15)\ttotal: 12.5s\tremaining: 3m 3s\n",
      "16:\tlearn: 0.4759166\ttest: 0.4756681\tbest: 0.4756681 (16)\ttotal: 14s\tremaining: 3m 11s\n",
      "17:\tlearn: 0.4806282\ttest: 0.4803815\tbest: 0.4803815 (17)\ttotal: 15.4s\tremaining: 3m 19s\n",
      "18:\tlearn: 0.4800184\ttest: 0.4797323\tbest: 0.4803815 (17)\ttotal: 16.9s\tremaining: 3m 25s\n",
      "19:\tlearn: 0.4962982\ttest: 0.4960969\tbest: 0.4960969 (19)\ttotal: 18.4s\tremaining: 3m 31s\n",
      "20:\tlearn: 0.5000067\ttest: 0.4997707\tbest: 0.4997707 (20)\ttotal: 19.9s\tremaining: 3m 37s\n",
      "21:\tlearn: 0.5087017\ttest: 0.5084799\tbest: 0.5084799 (21)\ttotal: 21.5s\tremaining: 3m 42s\n",
      "22:\tlearn: 0.5122645\ttest: 0.5119381\tbest: 0.5119381 (22)\ttotal: 22.9s\tremaining: 3m 46s\n",
      "23:\tlearn: 0.5200964\ttest: 0.5197700\tbest: 0.5197700 (23)\ttotal: 24.2s\tremaining: 3m 47s\n",
      "24:\tlearn: 0.5287121\ttest: 0.5284026\tbest: 0.5284026 (24)\ttotal: 24.7s\tremaining: 3m 42s\n",
      "25:\tlearn: 0.5286097\ttest: 0.5284251\tbest: 0.5284251 (25)\ttotal: 25.3s\tremaining: 3m 38s\n",
      "26:\tlearn: 0.5352784\ttest: 0.5350502\tbest: 0.5350502 (26)\ttotal: 25.9s\tremaining: 3m 33s\n",
      "27:\tlearn: 0.5486837\ttest: 0.5483653\tbest: 0.5483653 (27)\ttotal: 26.5s\tremaining: 3m 30s\n",
      "28:\tlearn: 0.5535113\ttest: 0.5531852\tbest: 0.5531852 (28)\ttotal: 28s\tremaining: 3m 33s\n",
      "29:\tlearn: 0.5552109\ttest: 0.5549496\tbest: 0.5549496 (29)\ttotal: 29.4s\tremaining: 3m 35s\n",
      "30:\tlearn: 0.5678113\ttest: 0.5673983\tbest: 0.5673983 (30)\ttotal: 30.8s\tremaining: 3m 37s\n",
      "31:\tlearn: 0.5684289\ttest: 0.5680226\tbest: 0.5680226 (31)\ttotal: 32.2s\tremaining: 3m 39s\n",
      "32:\tlearn: 0.5717969\ttest: 0.5712377\tbest: 0.5712377 (32)\ttotal: 33.6s\tremaining: 3m 41s\n",
      "33:\tlearn: 0.5792624\ttest: 0.5788474\tbest: 0.5788474 (33)\ttotal: 35.1s\tremaining: 3m 42s\n",
      "34:\tlearn: 0.5803477\ttest: 0.5800052\tbest: 0.5800052 (34)\ttotal: 36.3s\tremaining: 3m 43s\n",
      "35:\tlearn: 0.5795606\ttest: 0.5792528\tbest: 0.5800052 (34)\ttotal: 37.8s\tremaining: 3m 44s\n",
      "36:\tlearn: 0.5831714\ttest: 0.5827709\tbest: 0.5827709 (36)\ttotal: 39.3s\tremaining: 3m 46s\n",
      "37:\tlearn: 0.5863624\ttest: 0.5860160\tbest: 0.5860160 (37)\ttotal: 40.7s\tremaining: 3m 46s\n",
      "38:\tlearn: 0.5926557\ttest: 0.5922300\tbest: 0.5922300 (38)\ttotal: 42.1s\tremaining: 3m 47s\n",
      "39:\tlearn: 0.5931801\ttest: 0.5928317\tbest: 0.5928317 (39)\ttotal: 43.5s\tremaining: 3m 48s\n",
      "40:\tlearn: 0.5979480\ttest: 0.5977257\tbest: 0.5977257 (40)\ttotal: 44.9s\tremaining: 3m 48s\n",
      "41:\tlearn: 0.5999589\ttest: 0.5995750\tbest: 0.5995750 (41)\ttotal: 46.2s\tremaining: 3m 48s\n",
      "42:\tlearn: 0.6015086\ttest: 0.6010815\tbest: 0.6010815 (42)\ttotal: 47.6s\tremaining: 3m 48s\n",
      "43:\tlearn: 0.6026164\ttest: 0.6021835\tbest: 0.6021835 (43)\ttotal: 48.9s\tremaining: 3m 49s\n",
      "44:\tlearn: 0.6097653\ttest: 0.6094644\tbest: 0.6094644 (44)\ttotal: 50.4s\tremaining: 3m 49s\n",
      "45:\tlearn: 0.6112920\ttest: 0.6110141\tbest: 0.6110141 (45)\ttotal: 51.8s\tremaining: 3m 49s\n",
      "46:\tlearn: 0.6117018\ttest: 0.6114752\tbest: 0.6114752 (46)\ttotal: 53.1s\tremaining: 3m 49s\n",
      "47:\tlearn: 0.6125005\ttest: 0.6122718\tbest: 0.6122718 (47)\ttotal: 54.4s\tremaining: 3m 49s\n",
      "48:\tlearn: 0.6192380\ttest: 0.6191241\tbest: 0.6191241 (48)\ttotal: 55.7s\tremaining: 3m 48s\n",
      "49:\tlearn: 0.6233213\ttest: 0.6233788\tbest: 0.6233788 (49)\ttotal: 57.2s\tremaining: 3m 48s\n",
      "50:\tlearn: 0.6253304\ttest: 0.6253089\tbest: 0.6253089 (50)\ttotal: 58.6s\tremaining: 3m 48s\n",
      "51:\tlearn: 0.6268818\ttest: 0.6268545\tbest: 0.6268545 (51)\ttotal: 1m\tremaining: 3m 48s\n",
      "52:\tlearn: 0.6284427\ttest: 0.6284292\tbest: 0.6284292 (52)\ttotal: 1m 1s\tremaining: 3m 48s\n",
      "53:\tlearn: 0.6301131\ttest: 0.6302353\tbest: 0.6302353 (53)\ttotal: 1m 2s\tremaining: 3m 48s\n",
      "54:\tlearn: 0.6350428\ttest: 0.6350726\tbest: 0.6350726 (54)\ttotal: 1m 4s\tremaining: 3m 47s\n",
      "55:\tlearn: 0.6373086\ttest: 0.6373489\tbest: 0.6373489 (55)\ttotal: 1m 5s\tremaining: 3m 46s\n",
      "56:\tlearn: 0.6379300\ttest: 0.6380048\tbest: 0.6380048 (56)\ttotal: 1m 6s\tremaining: 3m 46s\n",
      "57:\tlearn: 0.6386059\ttest: 0.6386523\tbest: 0.6386523 (57)\ttotal: 1m 8s\tremaining: 3m 45s\n",
      "58:\tlearn: 0.6401248\ttest: 0.6401288\tbest: 0.6401288 (58)\ttotal: 1m 9s\tremaining: 3m 44s\n",
      "59:\tlearn: 0.6409613\ttest: 0.6409378\tbest: 0.6409378 (59)\ttotal: 1m 10s\tremaining: 3m 44s\n",
      "60:\tlearn: 0.6413858\ttest: 0.6414871\tbest: 0.6414871 (60)\ttotal: 1m 12s\tremaining: 3m 43s\n",
      "61:\tlearn: 0.6422647\ttest: 0.6422770\tbest: 0.6422770 (61)\ttotal: 1m 13s\tremaining: 3m 43s\n",
      "62:\tlearn: 0.6437242\ttest: 0.6435937\tbest: 0.6435937 (62)\ttotal: 1m 15s\tremaining: 3m 42s\n",
      "63:\tlearn: 0.6462389\ttest: 0.6460922\tbest: 0.6460922 (63)\ttotal: 1m 16s\tremaining: 3m 42s\n",
      "64:\tlearn: 0.6481743\ttest: 0.6480173\tbest: 0.6480173 (64)\ttotal: 1m 18s\tremaining: 3m 42s\n",
      "65:\tlearn: 0.6482747\ttest: 0.6481838\tbest: 0.6481838 (65)\ttotal: 1m 19s\tremaining: 3m 41s\n",
      "66:\tlearn: 0.6493966\ttest: 0.6492974\tbest: 0.6492974 (66)\ttotal: 1m 20s\tremaining: 3m 40s\n",
      "67:\tlearn: 0.6506171\ttest: 0.6506840\tbest: 0.6506840 (67)\ttotal: 1m 22s\tremaining: 3m 40s\n",
      "68:\tlearn: 0.6542845\ttest: 0.6542854\tbest: 0.6542854 (68)\ttotal: 1m 23s\tremaining: 3m 39s\n",
      "69:\tlearn: 0.6574095\ttest: 0.6574606\tbest: 0.6574606 (69)\ttotal: 1m 24s\tremaining: 3m 38s\n",
      "70:\tlearn: 0.6637671\ttest: 0.6639184\tbest: 0.6639184 (70)\ttotal: 1m 26s\tremaining: 3m 37s\n",
      "71:\tlearn: 0.6639613\ttest: 0.6640058\tbest: 0.6640058 (71)\ttotal: 1m 27s\tremaining: 3m 36s\n",
      "72:\tlearn: 0.6657480\ttest: 0.6658652\tbest: 0.6658652 (72)\ttotal: 1m 29s\tremaining: 3m 36s\n",
      "73:\tlearn: 0.6710009\ttest: 0.6711861\tbest: 0.6711861 (73)\ttotal: 1m 30s\tremaining: 3m 35s\n",
      "74:\tlearn: 0.6724866\ttest: 0.6725735\tbest: 0.6725735 (74)\ttotal: 1m 32s\tremaining: 3m 34s\n",
      "75:\tlearn: 0.6732978\ttest: 0.6733842\tbest: 0.6733842 (75)\ttotal: 1m 33s\tremaining: 3m 33s\n",
      "76:\tlearn: 0.6736138\ttest: 0.6736696\tbest: 0.6736696 (76)\ttotal: 1m 34s\tremaining: 3m 32s\n",
      "77:\tlearn: 0.6742119\ttest: 0.6742930\tbest: 0.6742930 (77)\ttotal: 1m 36s\tremaining: 3m 32s\n",
      "78:\tlearn: 0.6764675\ttest: 0.6765519\tbest: 0.6765519 (78)\ttotal: 1m 37s\tremaining: 3m 31s\n",
      "79:\tlearn: 0.6769152\ttest: 0.6770047\tbest: 0.6770047 (79)\ttotal: 1m 39s\tremaining: 3m 30s\n",
      "80:\tlearn: 0.6804483\ttest: 0.6808232\tbest: 0.6808232 (80)\ttotal: 1m 40s\tremaining: 3m 29s\n",
      "81:\tlearn: 0.6828545\ttest: 0.6831628\tbest: 0.6831628 (81)\ttotal: 1m 42s\tremaining: 3m 29s\n",
      "82:\tlearn: 0.6832238\ttest: 0.6835232\tbest: 0.6835232 (82)\ttotal: 1m 43s\tremaining: 3m 28s\n",
      "83:\tlearn: 0.6844487\ttest: 0.6847692\tbest: 0.6847692 (83)\ttotal: 1m 44s\tremaining: 3m 27s\n",
      "84:\tlearn: 0.6854313\ttest: 0.6856905\tbest: 0.6856905 (84)\ttotal: 1m 46s\tremaining: 3m 26s\n",
      "85:\tlearn: 0.6877937\ttest: 0.6880077\tbest: 0.6880077 (85)\ttotal: 1m 47s\tremaining: 3m 25s\n",
      "86:\tlearn: 0.6894744\ttest: 0.6898986\tbest: 0.6898986 (86)\ttotal: 1m 48s\tremaining: 3m 24s\n",
      "87:\tlearn: 0.6901152\ttest: 0.6904962\tbest: 0.6904962 (87)\ttotal: 1m 50s\tremaining: 3m 23s\n",
      "88:\tlearn: 0.6907494\ttest: 0.6912386\tbest: 0.6912386 (88)\ttotal: 1m 51s\tremaining: 3m 22s\n",
      "89:\tlearn: 0.6925433\ttest: 0.6931338\tbest: 0.6931338 (89)\ttotal: 1m 53s\tremaining: 3m 21s\n",
      "90:\tlearn: 0.6932172\ttest: 0.6938729\tbest: 0.6938729 (90)\ttotal: 1m 54s\tremaining: 3m 20s\n",
      "91:\tlearn: 0.6934672\ttest: 0.6941192\tbest: 0.6941192 (91)\ttotal: 1m 56s\tremaining: 3m 19s\n",
      "92:\tlearn: 0.6945259\ttest: 0.6951862\tbest: 0.6951862 (92)\ttotal: 1m 57s\tremaining: 3m 18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93:\tlearn: 0.6945888\ttest: 0.6953028\tbest: 0.6953028 (93)\ttotal: 1m 58s\tremaining: 3m 17s\n",
      "94:\tlearn: 0.6963281\ttest: 0.6970081\tbest: 0.6970081 (94)\ttotal: 2m\tremaining: 3m 16s\n",
      "95:\tlearn: 0.6967267\ttest: 0.6974226\tbest: 0.6974226 (95)\ttotal: 2m 1s\tremaining: 3m 15s\n",
      "96:\tlearn: 0.6979935\ttest: 0.6987202\tbest: 0.6987202 (96)\ttotal: 2m 3s\tremaining: 3m 14s\n",
      "97:\tlearn: 0.6997893\ttest: 0.7003115\tbest: 0.7003115 (97)\ttotal: 2m 4s\tremaining: 3m 12s\n",
      "98:\tlearn: 0.7015954\ttest: 0.7020793\tbest: 0.7020793 (98)\ttotal: 2m 5s\tremaining: 3m 12s\n",
      "99:\tlearn: 0.7022424\ttest: 0.7026686\tbest: 0.7026686 (99)\ttotal: 2m 7s\tremaining: 3m 10s\n",
      "100:\tlearn: 0.7035336\ttest: 0.7039678\tbest: 0.7039678 (100)\ttotal: 2m 8s\tremaining: 3m 9s\n",
      "101:\tlearn: 0.7039675\ttest: 0.7047635\tbest: 0.7047635 (101)\ttotal: 2m 10s\tremaining: 3m 8s\n",
      "102:\tlearn: 0.7046627\ttest: 0.7053977\tbest: 0.7053977 (102)\ttotal: 2m 11s\tremaining: 3m 7s\n",
      "103:\tlearn: 0.7052922\ttest: 0.7060852\tbest: 0.7060852 (103)\ttotal: 2m 12s\tremaining: 3m 6s\n",
      "104:\tlearn: 0.7061245\ttest: 0.7068118\tbest: 0.7068118 (104)\ttotal: 2m 14s\tremaining: 3m 5s\n",
      "105:\tlearn: 0.7083753\ttest: 0.7090681\tbest: 0.7090681 (105)\ttotal: 2m 15s\tremaining: 3m 4s\n",
      "106:\tlearn: 0.7092273\ttest: 0.7099362\tbest: 0.7099362 (106)\ttotal: 2m 17s\tremaining: 3m 3s\n",
      "107:\tlearn: 0.7097838\ttest: 0.7105105\tbest: 0.7105105 (107)\ttotal: 2m 18s\tremaining: 3m 2s\n",
      "108:\tlearn: 0.7104846\ttest: 0.7112479\tbest: 0.7112479 (108)\ttotal: 2m 19s\tremaining: 3m\n",
      "109:\tlearn: 0.7113150\ttest: 0.7120469\tbest: 0.7120469 (109)\ttotal: 2m 21s\tremaining: 2m 59s\n",
      "110:\tlearn: 0.7125648\ttest: 0.7131905\tbest: 0.7131905 (110)\ttotal: 2m 22s\tremaining: 2m 58s\n",
      "111:\tlearn: 0.7139048\ttest: 0.7145389\tbest: 0.7145389 (111)\ttotal: 2m 23s\tremaining: 2m 57s\n",
      "112:\tlearn: 0.7143878\ttest: 0.7150299\tbest: 0.7150299 (112)\ttotal: 2m 25s\tremaining: 2m 56s\n",
      "113:\tlearn: 0.7147075\ttest: 0.7153212\tbest: 0.7153212 (113)\ttotal: 2m 26s\tremaining: 2m 54s\n",
      "114:\tlearn: 0.7168639\ttest: 0.7174960\tbest: 0.7174960 (114)\ttotal: 2m 27s\tremaining: 2m 53s\n",
      "115:\tlearn: 0.7172540\ttest: 0.7179296\tbest: 0.7179296 (115)\ttotal: 2m 29s\tremaining: 2m 52s\n",
      "116:\tlearn: 0.7182017\ttest: 0.7188968\tbest: 0.7188968 (116)\ttotal: 2m 30s\tremaining: 2m 51s\n",
      "117:\tlearn: 0.7186881\ttest: 0.7194353\tbest: 0.7194353 (117)\ttotal: 2m 31s\tremaining: 2m 49s\n",
      "118:\tlearn: 0.7189519\ttest: 0.7196350\tbest: 0.7196350 (118)\ttotal: 2m 33s\tremaining: 2m 48s\n",
      "119:\tlearn: 0.7196213\ttest: 0.7203000\tbest: 0.7203000 (119)\ttotal: 2m 34s\tremaining: 2m 47s\n",
      "120:\tlearn: 0.7212380\ttest: 0.7218156\tbest: 0.7218156 (120)\ttotal: 2m 36s\tremaining: 2m 46s\n",
      "121:\tlearn: 0.7217260\ttest: 0.7223258\tbest: 0.7223258 (121)\ttotal: 2m 37s\tremaining: 2m 45s\n",
      "122:\tlearn: 0.7219973\ttest: 0.7226355\tbest: 0.7226355 (122)\ttotal: 2m 39s\tremaining: 2m 44s\n",
      "123:\tlearn: 0.7224118\ttest: 0.7230458\tbest: 0.7230458 (123)\ttotal: 2m 40s\tremaining: 2m 43s\n",
      "124:\tlearn: 0.7228587\ttest: 0.7235651\tbest: 0.7235651 (124)\ttotal: 2m 41s\tremaining: 2m 41s\n",
      "125:\tlearn: 0.7236599\ttest: 0.7243558\tbest: 0.7243558 (125)\ttotal: 2m 43s\tremaining: 2m 40s\n",
      "126:\tlearn: 0.7238652\ttest: 0.7245489\tbest: 0.7245489 (126)\ttotal: 2m 44s\tremaining: 2m 39s\n",
      "127:\tlearn: 0.7245244\ttest: 0.7251923\tbest: 0.7251923 (127)\ttotal: 2m 46s\tremaining: 2m 38s\n",
      "128:\tlearn: 0.7248743\ttest: 0.7254411\tbest: 0.7254411 (128)\ttotal: 2m 47s\tremaining: 2m 37s\n",
      "129:\tlearn: 0.7252297\ttest: 0.7259355\tbest: 0.7259355 (129)\ttotal: 2m 48s\tremaining: 2m 35s\n",
      "130:\tlearn: 0.7253154\ttest: 0.7260213\tbest: 0.7260213 (130)\ttotal: 2m 50s\tremaining: 2m 34s\n",
      "131:\tlearn: 0.7256613\ttest: 0.7263250\tbest: 0.7263250 (131)\ttotal: 2m 51s\tremaining: 2m 33s\n",
      "132:\tlearn: 0.7262539\ttest: 0.7269618\tbest: 0.7269618 (132)\ttotal: 2m 52s\tremaining: 2m 32s\n",
      "133:\tlearn: 0.7270532\ttest: 0.7276742\tbest: 0.7276742 (133)\ttotal: 2m 54s\tremaining: 2m 30s\n",
      "134:\tlearn: 0.7277424\ttest: 0.7282876\tbest: 0.7282876 (134)\ttotal: 2m 55s\tremaining: 2m 29s\n",
      "135:\tlearn: 0.7294963\ttest: 0.7299147\tbest: 0.7299147 (135)\ttotal: 2m 57s\tremaining: 2m 28s\n",
      "136:\tlearn: 0.7304693\ttest: 0.7309618\tbest: 0.7309618 (136)\ttotal: 2m 58s\tremaining: 2m 27s\n",
      "137:\tlearn: 0.7310158\ttest: 0.7315411\tbest: 0.7315411 (137)\ttotal: 2m 59s\tremaining: 2m 25s\n",
      "138:\tlearn: 0.7315299\ttest: 0.7320388\tbest: 0.7320388 (138)\ttotal: 3m 1s\tremaining: 2m 24s\n",
      "139:\tlearn: 0.7323788\ttest: 0.7328652\tbest: 0.7328652 (139)\ttotal: 3m 2s\tremaining: 2m 23s\n",
      "140:\tlearn: 0.7325250\ttest: 0.7330284\tbest: 0.7330284 (140)\ttotal: 3m 4s\tremaining: 2m 22s\n",
      "141:\tlearn: 0.7333424\ttest: 0.7339023\tbest: 0.7339023 (141)\ttotal: 3m 5s\tremaining: 2m 21s\n",
      "142:\tlearn: 0.7339513\ttest: 0.7344949\tbest: 0.7344949 (142)\ttotal: 3m 6s\tremaining: 2m 19s\n",
      "143:\tlearn: 0.7341666\ttest: 0.7346971\tbest: 0.7346971 (143)\ttotal: 3m 8s\tremaining: 2m 18s\n",
      "144:\tlearn: 0.7347564\ttest: 0.7352631\tbest: 0.7352631 (144)\ttotal: 3m 9s\tremaining: 2m 17s\n",
      "145:\tlearn: 0.7357311\ttest: 0.7362510\tbest: 0.7362510 (145)\ttotal: 3m 11s\tremaining: 2m 16s\n",
      "146:\tlearn: 0.7361522\ttest: 0.7366855\tbest: 0.7366855 (146)\ttotal: 3m 12s\tremaining: 2m 14s\n",
      "147:\tlearn: 0.7367273\ttest: 0.7372864\tbest: 0.7372864 (147)\ttotal: 3m 13s\tremaining: 2m 13s\n",
      "148:\tlearn: 0.7372991\ttest: 0.7378416\tbest: 0.7378416 (148)\ttotal: 3m 15s\tremaining: 2m 12s\n",
      "149:\tlearn: 0.7374051\ttest: 0.7379348\tbest: 0.7379348 (149)\ttotal: 3m 16s\tremaining: 2m 10s\n",
      "150:\tlearn: 0.7382121\ttest: 0.7386988\tbest: 0.7386988 (150)\ttotal: 3m 17s\tremaining: 2m 9s\n",
      "151:\tlearn: 0.7394845\ttest: 0.7399348\tbest: 0.7399348 (151)\ttotal: 3m 19s\tremaining: 2m 8s\n",
      "152:\tlearn: 0.7399711\ttest: 0.7404042\tbest: 0.7404042 (152)\ttotal: 3m 20s\tremaining: 2m 7s\n",
      "153:\tlearn: 0.7403340\ttest: 0.7407438\tbest: 0.7407438 (153)\ttotal: 3m 22s\tremaining: 2m 5s\n",
      "154:\tlearn: 0.7407823\ttest: 0.7412290\tbest: 0.7412290 (154)\ttotal: 3m 23s\tremaining: 2m 4s\n",
      "155:\tlearn: 0.7413549\ttest: 0.7417525\tbest: 0.7417525 (155)\ttotal: 3m 24s\tremaining: 2m 3s\n",
      "156:\tlearn: 0.7414814\ttest: 0.7418649\tbest: 0.7418649 (156)\ttotal: 3m 26s\tremaining: 2m 2s\n",
      "157:\tlearn: 0.7418121\ttest: 0.7422569\tbest: 0.7422569 (157)\ttotal: 3m 27s\tremaining: 2m\n",
      "158:\tlearn: 0.7425531\ttest: 0.7429602\tbest: 0.7429602 (158)\ttotal: 3m 28s\tremaining: 1m 59s\n",
      "159:\tlearn: 0.7429390\ttest: 0.7433297\tbest: 0.7433297 (159)\ttotal: 3m 30s\tremaining: 1m 58s\n",
      "160:\tlearn: 0.7430844\ttest: 0.7435553\tbest: 0.7435553 (160)\ttotal: 3m 31s\tremaining: 1m 57s\n",
      "161:\tlearn: 0.7432284\ttest: 0.7437151\tbest: 0.7437151 (161)\ttotal: 3m 33s\tremaining: 1m 55s\n",
      "162:\tlearn: 0.7440488\ttest: 0.7444958\tbest: 0.7444958 (162)\ttotal: 3m 34s\tremaining: 1m 54s\n",
      "163:\tlearn: 0.7447487\ttest: 0.7452291\tbest: 0.7452291 (163)\ttotal: 3m 36s\tremaining: 1m 53s\n",
      "164:\tlearn: 0.7450500\ttest: 0.7455412\tbest: 0.7455412 (164)\ttotal: 3m 37s\tremaining: 1m 52s\n",
      "165:\tlearn: 0.7454104\ttest: 0.7459232\tbest: 0.7459232 (165)\ttotal: 3m 38s\tremaining: 1m 50s\n",
      "166:\tlearn: 0.7455602\ttest: 0.7460938\tbest: 0.7460938 (166)\ttotal: 3m 40s\tremaining: 1m 49s\n",
      "167:\tlearn: 0.7460990\ttest: 0.7466723\tbest: 0.7466723 (167)\ttotal: 3m 41s\tremaining: 1m 48s\n",
      "168:\tlearn: 0.7467532\ttest: 0.7472748\tbest: 0.7472748 (168)\ttotal: 3m 43s\tremaining: 1m 46s\n",
      "169:\tlearn: 0.7474060\ttest: 0.7479548\tbest: 0.7479548 (169)\ttotal: 3m 44s\tremaining: 1m 45s\n",
      "170:\tlearn: 0.7478310\ttest: 0.7482736\tbest: 0.7482736 (170)\ttotal: 3m 45s\tremaining: 1m 44s\n",
      "171:\tlearn: 0.7483174\ttest: 0.7488038\tbest: 0.7488038 (171)\ttotal: 3m 47s\tremaining: 1m 42s\n",
      "172:\tlearn: 0.7484747\ttest: 0.7489336\tbest: 0.7489336 (172)\ttotal: 3m 48s\tremaining: 1m 41s\n",
      "173:\tlearn: 0.7490509\ttest: 0.7495395\tbest: 0.7495395 (173)\ttotal: 3m 49s\tremaining: 1m 40s\n",
      "174:\tlearn: 0.7492984\ttest: 0.7497776\tbest: 0.7497776 (174)\ttotal: 3m 51s\tremaining: 1m 39s\n",
      "175:\tlearn: 0.7494718\ttest: 0.7499440\tbest: 0.7499440 (175)\ttotal: 3m 52s\tremaining: 1m 37s\n",
      "176:\tlearn: 0.7499015\ttest: 0.7503402\tbest: 0.7503402 (176)\ttotal: 3m 54s\tremaining: 1m 36s\n",
      "177:\tlearn: 0.7506256\ttest: 0.7510660\tbest: 0.7510660 (177)\ttotal: 3m 55s\tremaining: 1m 35s\n",
      "178:\tlearn: 0.7507238\ttest: 0.7511867\tbest: 0.7511867 (178)\ttotal: 3m 56s\tremaining: 1m 33s\n",
      "179:\tlearn: 0.7515045\ttest: 0.7519574\tbest: 0.7519574 (179)\ttotal: 3m 58s\tremaining: 1m 32s\n",
      "180:\tlearn: 0.7517539\ttest: 0.7522112\tbest: 0.7522112 (180)\ttotal: 3m 59s\tremaining: 1m 31s\n",
      "181:\tlearn: 0.7519085\ttest: 0.7523544\tbest: 0.7523544 (181)\ttotal: 4m\tremaining: 1m 30s\n",
      "182:\tlearn: 0.7528132\ttest: 0.7533848\tbest: 0.7533848 (182)\ttotal: 4m 2s\tremaining: 1m 28s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183:\tlearn: 0.7529910\ttest: 0.7536128\tbest: 0.7536128 (183)\ttotal: 4m 3s\tremaining: 1m 27s\n",
      "184:\tlearn: 0.7531486\ttest: 0.7537726\tbest: 0.7537726 (184)\ttotal: 4m 4s\tremaining: 1m 26s\n",
      "185:\tlearn: 0.7538683\ttest: 0.7544534\tbest: 0.7544534 (185)\ttotal: 4m 6s\tremaining: 1m 24s\n",
      "186:\tlearn: 0.7541593\ttest: 0.7547464\tbest: 0.7547464 (186)\ttotal: 4m 7s\tremaining: 1m 23s\n",
      "187:\tlearn: 0.7545166\ttest: 0.7551767\tbest: 0.7551767 (187)\ttotal: 4m 9s\tremaining: 1m 22s\n",
      "188:\tlearn: 0.7549760\ttest: 0.7555687\tbest: 0.7555687 (188)\ttotal: 4m 10s\tremaining: 1m 20s\n",
      "189:\tlearn: 0.7558261\ttest: 0.7564043\tbest: 0.7564043 (189)\ttotal: 4m 11s\tremaining: 1m 19s\n",
      "190:\tlearn: 0.7560722\ttest: 0.7566324\tbest: 0.7566324 (190)\ttotal: 4m 13s\tremaining: 1m 18s\n",
      "191:\tlearn: 0.7563127\ttest: 0.7568305\tbest: 0.7568305 (191)\ttotal: 4m 14s\tremaining: 1m 16s\n",
      "192:\tlearn: 0.7575298\ttest: 0.7580198\tbest: 0.7580198 (192)\ttotal: 4m 15s\tremaining: 1m 15s\n",
      "193:\tlearn: 0.7576056\ttest: 0.7580931\tbest: 0.7580931 (193)\ttotal: 4m 17s\tremaining: 1m 14s\n",
      "194:\tlearn: 0.7576463\ttest: 0.7581397\tbest: 0.7581397 (194)\ttotal: 4m 18s\tremaining: 1m 12s\n",
      "195:\tlearn: 0.7579657\ttest: 0.7584510\tbest: 0.7584510 (195)\ttotal: 4m 20s\tremaining: 1m 11s\n",
      "196:\tlearn: 0.7587303\ttest: 0.7591825\tbest: 0.7591825 (196)\ttotal: 4m 21s\tremaining: 1m 10s\n",
      "197:\tlearn: 0.7592754\ttest: 0.7597743\tbest: 0.7597743 (197)\ttotal: 4m 22s\tremaining: 1m 9s\n",
      "198:\tlearn: 0.7598719\ttest: 0.7603078\tbest: 0.7603078 (198)\ttotal: 4m 24s\tremaining: 1m 7s\n",
      "199:\tlearn: 0.7603710\ttest: 0.7608496\tbest: 0.7608496 (199)\ttotal: 4m 25s\tremaining: 1m 6s\n",
      "200:\tlearn: 0.7606737\ttest: 0.7611418\tbest: 0.7611418 (200)\ttotal: 4m 27s\tremaining: 1m 5s\n",
      "201:\tlearn: 0.7610188\ttest: 0.7615055\tbest: 0.7615055 (201)\ttotal: 4m 28s\tremaining: 1m 3s\n",
      "202:\tlearn: 0.7611475\ttest: 0.7616278\tbest: 0.7616278 (202)\ttotal: 4m 30s\tremaining: 1m 2s\n",
      "203:\tlearn: 0.7615493\ttest: 0.7620040\tbest: 0.7620040 (203)\ttotal: 4m 31s\tremaining: 1m 1s\n",
      "204:\tlearn: 0.7619904\ttest: 0.7624027\tbest: 0.7624027 (204)\ttotal: 4m 32s\tremaining: 59.9s\n",
      "205:\tlearn: 0.7621227\ttest: 0.7625134\tbest: 0.7625134 (205)\ttotal: 4m 34s\tremaining: 58.5s\n",
      "206:\tlearn: 0.7627938\ttest: 0.7632625\tbest: 0.7632625 (206)\ttotal: 4m 35s\tremaining: 57.2s\n",
      "207:\tlearn: 0.7629464\ttest: 0.7633715\tbest: 0.7633715 (207)\ttotal: 4m 36s\tremaining: 55.9s\n",
      "208:\tlearn: 0.7630075\ttest: 0.7634448\tbest: 0.7634448 (208)\ttotal: 4m 38s\tremaining: 54.5s\n",
      "209:\tlearn: 0.7636239\ttest: 0.7640573\tbest: 0.7640573 (209)\ttotal: 4m 39s\tremaining: 53.2s\n",
      "210:\tlearn: 0.7638658\ttest: 0.7643628\tbest: 0.7643628 (210)\ttotal: 4m 40s\tremaining: 51.9s\n",
      "211:\tlearn: 0.7643114\ttest: 0.7647881\tbest: 0.7647881 (211)\ttotal: 4m 42s\tremaining: 50.6s\n",
      "212:\tlearn: 0.7644182\ttest: 0.7649071\tbest: 0.7649071 (212)\ttotal: 4m 43s\tremaining: 49.3s\n",
      "213:\tlearn: 0.7650397\ttest: 0.7655796\tbest: 0.7655796 (213)\ttotal: 4m 44s\tremaining: 47.9s\n",
      "214:\tlearn: 0.7653049\ttest: 0.7658285\tbest: 0.7658285 (214)\ttotal: 4m 46s\tremaining: 46.6s\n",
      "215:\tlearn: 0.7657907\ttest: 0.7663162\tbest: 0.7663162 (215)\ttotal: 4m 47s\tremaining: 45.3s\n",
      "216:\tlearn: 0.7670100\ttest: 0.7675263\tbest: 0.7675263 (216)\ttotal: 4m 49s\tremaining: 44s\n",
      "217:\tlearn: 0.7681999\ttest: 0.7686616\tbest: 0.7686616 (217)\ttotal: 4m 50s\tremaining: 42.7s\n",
      "218:\tlearn: 0.7688691\ttest: 0.7692742\tbest: 0.7692742 (218)\ttotal: 4m 52s\tremaining: 41.3s\n",
      "219:\tlearn: 0.7691989\ttest: 0.7696279\tbest: 0.7696279 (219)\ttotal: 4m 53s\tremaining: 40s\n",
      "220:\tlearn: 0.7693146\ttest: 0.7697619\tbest: 0.7697619 (220)\ttotal: 4m 54s\tremaining: 38.7s\n",
      "221:\tlearn: 0.7697125\ttest: 0.7700973\tbest: 0.7700973 (221)\ttotal: 4m 56s\tremaining: 37.4s\n",
      "222:\tlearn: 0.7698695\ttest: 0.7702629\tbest: 0.7702629 (222)\ttotal: 4m 57s\tremaining: 36s\n",
      "223:\tlearn: 0.7700282\ttest: 0.7704569\tbest: 0.7704569 (223)\ttotal: 4m 59s\tremaining: 34.7s\n",
      "224:\tlearn: 0.7701400\ttest: 0.7705251\tbest: 0.7705251 (224)\ttotal: 5m\tremaining: 33.4s\n",
      "225:\tlearn: 0.7711743\ttest: 0.7715214\tbest: 0.7715214 (225)\ttotal: 5m 1s\tremaining: 32.1s\n",
      "226:\tlearn: 0.7711995\ttest: 0.7715855\tbest: 0.7715855 (226)\ttotal: 5m 3s\tremaining: 30.7s\n",
      "227:\tlearn: 0.7713954\ttest: 0.7718169\tbest: 0.7718169 (227)\ttotal: 5m 4s\tremaining: 29.4s\n",
      "228:\tlearn: 0.7717352\ttest: 0.7721972\tbest: 0.7721972 (228)\ttotal: 5m 5s\tremaining: 28.1s\n",
      "229:\tlearn: 0.7719788\ttest: 0.7724119\tbest: 0.7724119 (229)\ttotal: 5m 7s\tremaining: 26.7s\n",
      "230:\tlearn: 0.7727828\ttest: 0.7732667\tbest: 0.7732667 (230)\ttotal: 5m 8s\tremaining: 25.4s\n",
      "231:\tlearn: 0.7728450\ttest: 0.7733699\tbest: 0.7733699 (231)\ttotal: 5m 10s\tremaining: 24.1s\n",
      "232:\tlearn: 0.7728871\ttest: 0.7733941\tbest: 0.7733941 (232)\ttotal: 5m 11s\tremaining: 22.7s\n",
      "233:\tlearn: 0.7730747\ttest: 0.7735430\tbest: 0.7735430 (233)\ttotal: 5m 12s\tremaining: 21.4s\n",
      "234:\tlearn: 0.7732902\ttest: 0.7738052\tbest: 0.7738052 (234)\ttotal: 5m 14s\tremaining: 20.1s\n",
      "235:\tlearn: 0.7733682\ttest: 0.7739217\tbest: 0.7739217 (235)\ttotal: 5m 15s\tremaining: 18.7s\n",
      "236:\tlearn: 0.7735485\ttest: 0.7741698\tbest: 0.7741698 (236)\ttotal: 5m 15s\tremaining: 17.3s\n",
      "237:\tlearn: 0.7736889\ttest: 0.7742938\tbest: 0.7742938 (237)\ttotal: 5m 16s\tremaining: 15.9s\n",
      "238:\tlearn: 0.7738834\ttest: 0.7744819\tbest: 0.7744819 (238)\ttotal: 5m 16s\tremaining: 14.6s\n",
      "239:\tlearn: 0.7743201\ttest: 0.7748589\tbest: 0.7748589 (239)\ttotal: 5m 17s\tremaining: 13.2s\n",
      "240:\tlearn: 0.7746419\ttest: 0.7751319\tbest: 0.7751319 (240)\ttotal: 5m 17s\tremaining: 11.9s\n",
      "241:\tlearn: 0.7749989\ttest: 0.7755031\tbest: 0.7755031 (241)\ttotal: 5m 18s\tremaining: 10.5s\n",
      "242:\tlearn: 0.7751243\ttest: 0.7756471\tbest: 0.7756471 (242)\ttotal: 5m 19s\tremaining: 9.21s\n",
      "243:\tlearn: 0.7758304\ttest: 0.7762896\tbest: 0.7762896 (243)\ttotal: 5m 20s\tremaining: 7.89s\n",
      "244:\tlearn: 0.7761478\ttest: 0.7766592\tbest: 0.7766592 (244)\ttotal: 5m 21s\tremaining: 6.57s\n",
      "245:\tlearn: 0.7771926\ttest: 0.7776712\tbest: 0.7776712 (245)\ttotal: 5m 23s\tremaining: 5.25s\n",
      "246:\tlearn: 0.7774570\ttest: 0.7779484\tbest: 0.7779484 (246)\ttotal: 5m 23s\tremaining: 3.93s\n",
      "247:\tlearn: 0.7775352\ttest: 0.7780433\tbest: 0.7780433 (247)\ttotal: 5m 24s\tremaining: 2.62s\n",
      "248:\tlearn: 0.7776282\ttest: 0.7781199\tbest: 0.7781199 (248)\ttotal: 5m 25s\tremaining: 1.3s\n",
      "249:\tlearn: 0.7777971\ttest: 0.7782888\tbest: 0.7782888 (249)\ttotal: 5m 25s\tremaining: 0us\n",
      "bestTest = 0.7782888095\n",
      "bestIteration = 249\n",
      "332.7625231742859\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('2grams_bib_data.csv')\n",
    "X = df.drop(['style_name'], axis=1)\n",
    "y = df.style_name\n",
    "del df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "train_dataset = catboost.Pool(data=X_train, label=y_train)\n",
    "test_data = catboost.Pool(data=X_test, label=y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 6858.1875 Total: 12053.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0926543\ttest: 0.0922787\tbest: 0.0922787 (0)\ttotal: 1.21s\tremaining: 20m 13s\n",
      "1:\tlearn: 0.2339866\ttest: 0.2337820\tbest: 0.2337820 (1)\ttotal: 2.35s\tremaining: 19m 35s\n",
      "2:\tlearn: 0.2760943\ttest: 0.2755518\tbest: 0.2755518 (2)\ttotal: 3.51s\tremaining: 19m 27s\n",
      "3:\tlearn: 0.2944892\ttest: 0.2939839\tbest: 0.2939839 (3)\ttotal: 4.67s\tremaining: 19m 23s\n",
      "4:\tlearn: 0.3077829\ttest: 0.3071767\tbest: 0.3071767 (4)\ttotal: 5.81s\tremaining: 19m 16s\n",
      "5:\tlearn: 0.3402318\ttest: 0.3400658\tbest: 0.3400658 (5)\ttotal: 7s\tremaining: 19m 20s\n",
      "6:\tlearn: 0.3439455\ttest: 0.3436522\tbest: 0.3436522 (6)\ttotal: 8.17s\tremaining: 19m 19s\n",
      "7:\tlearn: 0.3490816\ttest: 0.3488857\tbest: 0.3488857 (7)\ttotal: 9.35s\tremaining: 19m 19s\n",
      "8:\tlearn: 0.3491785\ttest: 0.3489539\tbest: 0.3489539 (8)\ttotal: 10.5s\tremaining: 19m 17s\n",
      "9:\tlearn: 0.3493557\ttest: 0.3491320\tbest: 0.3491320 (9)\ttotal: 11.6s\tremaining: 19m 9s\n",
      "10:\tlearn: 0.3524616\ttest: 0.3522881\tbest: 0.3522881 (10)\ttotal: 12.7s\tremaining: 19m 4s\n",
      "11:\tlearn: 0.3595975\ttest: 0.3594276\tbest: 0.3594276 (11)\ttotal: 13.9s\tremaining: 19m 4s\n",
      "12:\tlearn: 0.3584525\ttest: 0.3582399\tbest: 0.3594276 (11)\ttotal: 15.1s\tremaining: 19m 2s\n",
      "13:\tlearn: 0.3809903\ttest: 0.3809567\tbest: 0.3809567 (13)\ttotal: 16.2s\tremaining: 19m 2s\n",
      "14:\tlearn: 0.4097382\ttest: 0.4098558\tbest: 0.4098558 (14)\ttotal: 17.4s\tremaining: 19m\n",
      "15:\tlearn: 0.4103189\ttest: 0.4103676\tbest: 0.4103676 (15)\ttotal: 18.6s\tremaining: 19m 1s\n",
      "16:\tlearn: 0.4144829\ttest: 0.4145033\tbest: 0.4145033 (16)\ttotal: 19.7s\tremaining: 18m 58s\n",
      "17:\tlearn: 0.4232601\ttest: 0.4233831\tbest: 0.4233831 (17)\ttotal: 20.9s\tremaining: 18m 57s\n",
      "18:\tlearn: 0.4273120\ttest: 0.4272949\tbest: 0.4272949 (18)\ttotal: 22s\tremaining: 18m 56s\n",
      "19:\tlearn: 0.4374655\ttest: 0.4375805\tbest: 0.4375805 (19)\ttotal: 23.2s\tremaining: 18m 56s\n",
      "20:\tlearn: 0.4534936\ttest: 0.4538885\tbest: 0.4538885 (20)\ttotal: 24.4s\tremaining: 18m 56s\n",
      "21:\tlearn: 0.4506546\ttest: 0.4509647\tbest: 0.4538885 (20)\ttotal: 25.5s\tremaining: 18m 53s\n",
      "22:\tlearn: 0.4588872\ttest: 0.4592744\tbest: 0.4592744 (22)\ttotal: 26.6s\tremaining: 18m 48s\n",
      "23:\tlearn: 0.4661623\ttest: 0.4665603\tbest: 0.4665603 (23)\ttotal: 27.6s\tremaining: 18m 44s\n",
      "24:\tlearn: 0.4653408\ttest: 0.4657288\tbest: 0.4665603 (23)\ttotal: 28.8s\tremaining: 18m 42s\n",
      "25:\tlearn: 0.4681163\ttest: 0.4685520\tbest: 0.4685520 (25)\ttotal: 29.9s\tremaining: 18m 40s\n",
      "26:\tlearn: 0.4678477\ttest: 0.4681708\tbest: 0.4685520 (25)\ttotal: 31.1s\tremaining: 18m 39s\n",
      "27:\tlearn: 0.4698688\ttest: 0.4701225\tbest: 0.4701225 (27)\ttotal: 32.2s\tremaining: 18m 39s\n",
      "28:\tlearn: 0.4699620\ttest: 0.4701359\tbest: 0.4701359 (28)\ttotal: 33.3s\tremaining: 18m 35s\n",
      "29:\tlearn: 0.4719049\ttest: 0.4721683\tbest: 0.4721683 (29)\ttotal: 34.5s\tremaining: 18m 35s\n",
      "30:\tlearn: 0.4737609\ttest: 0.4739861\tbest: 0.4739861 (30)\ttotal: 35.6s\tremaining: 18m 32s\n",
      "31:\tlearn: 0.4819774\ttest: 0.4822450\tbest: 0.4822450 (31)\ttotal: 36.8s\tremaining: 18m 32s\n",
      "32:\tlearn: 0.4983643\ttest: 0.4986579\tbest: 0.4986579 (32)\ttotal: 37.9s\tremaining: 18m 31s\n",
      "33:\tlearn: 0.5085633\ttest: 0.5086114\tbest: 0.5086114 (33)\ttotal: 39.1s\tremaining: 18m 30s\n",
      "34:\tlearn: 0.5093711\ttest: 0.5094362\tbest: 0.5094362 (34)\ttotal: 40.3s\tremaining: 18m 30s\n",
      "35:\tlearn: 0.5094372\ttest: 0.5095344\tbest: 0.5095344 (35)\ttotal: 41.4s\tremaining: 18m 29s\n",
      "36:\tlearn: 0.5237302\ttest: 0.5238341\tbest: 0.5238341 (36)\ttotal: 42.6s\tremaining: 18m 29s\n",
      "37:\tlearn: 0.5280582\ttest: 0.5283003\tbest: 0.5283003 (37)\ttotal: 43.8s\tremaining: 18m 28s\n",
      "38:\tlearn: 0.5281855\ttest: 0.5283802\tbest: 0.5283802 (38)\ttotal: 44.9s\tremaining: 18m 27s\n",
      "39:\tlearn: 0.5283478\ttest: 0.5284800\tbest: 0.5284800 (39)\ttotal: 46.1s\tremaining: 18m 26s\n",
      "40:\tlearn: 0.5309668\ttest: 0.5311950\tbest: 0.5311950 (40)\ttotal: 47.2s\tremaining: 18m 25s\n",
      "41:\tlearn: 0.5397295\ttest: 0.5398293\tbest: 0.5398293 (41)\ttotal: 48.4s\tremaining: 18m 24s\n",
      "42:\tlearn: 0.5446468\ttest: 0.5443162\tbest: 0.5443162 (42)\ttotal: 49.6s\tremaining: 18m 24s\n",
      "43:\tlearn: 0.5464426\ttest: 0.5460948\tbest: 0.5460948 (43)\ttotal: 50.8s\tremaining: 18m 22s\n",
      "44:\tlearn: 0.5500359\ttest: 0.5496812\tbest: 0.5496812 (44)\ttotal: 51.9s\tremaining: 18m 21s\n",
      "45:\tlearn: 0.5512849\ttest: 0.5510803\tbest: 0.5510803 (45)\ttotal: 53.1s\tremaining: 18m 20s\n",
      "46:\tlearn: 0.5532513\ttest: 0.5528880\tbest: 0.5528880 (46)\ttotal: 54.1s\tremaining: 18m 17s\n",
      "47:\tlearn: 0.5594869\ttest: 0.5593467\tbest: 0.5593467 (47)\ttotal: 55.2s\tremaining: 18m 14s\n",
      "48:\tlearn: 0.5603120\ttest: 0.5602947\tbest: 0.5602947 (48)\ttotal: 56.3s\tremaining: 18m 13s\n",
      "49:\tlearn: 0.5575191\ttest: 0.5573791\tbest: 0.5602947 (48)\ttotal: 57.5s\tremaining: 18m 12s\n",
      "50:\tlearn: 0.5582673\ttest: 0.5580891\tbest: 0.5602947 (48)\ttotal: 58.7s\tremaining: 18m 11s\n",
      "51:\tlearn: 0.5604552\ttest: 0.5603454\tbest: 0.5603454 (51)\ttotal: 59.7s\tremaining: 18m 8s\n",
      "52:\tlearn: 0.5670745\ttest: 0.5668831\tbest: 0.5668831 (52)\ttotal: 1m\tremaining: 18m 7s\n",
      "53:\tlearn: 0.5688461\ttest: 0.5684895\tbest: 0.5684895 (53)\ttotal: 1m 2s\tremaining: 18m 7s\n",
      "54:\tlearn: 0.5692129\ttest: 0.5688582\tbest: 0.5688582 (54)\ttotal: 1m 3s\tremaining: 18m 5s\n",
      "55:\tlearn: 0.5717897\ttest: 0.5714375\tbest: 0.5714375 (55)\ttotal: 1m 4s\tremaining: 18m 5s\n",
      "56:\tlearn: 0.5714665\ttest: 0.5711454\tbest: 0.5714375 (55)\ttotal: 1m 5s\tremaining: 18m 4s\n",
      "57:\tlearn: 0.5734868\ttest: 0.5730771\tbest: 0.5730771 (57)\ttotal: 1m 6s\tremaining: 18m 2s\n",
      "58:\tlearn: 0.5739459\ttest: 0.5735141\tbest: 0.5735141 (58)\ttotal: 1m 7s\tremaining: 18m 2s\n",
      "59:\tlearn: 0.5789855\ttest: 0.5785570\tbest: 0.5785570 (59)\ttotal: 1m 9s\tremaining: 18m 1s\n",
      "60:\tlearn: 0.5821174\ttest: 0.5816490\tbest: 0.5816490 (60)\ttotal: 1m 10s\tremaining: 18m\n",
      "61:\tlearn: 0.5822467\ttest: 0.5818878\tbest: 0.5818878 (61)\ttotal: 1m 11s\tremaining: 17m 59s\n",
      "62:\tlearn: 0.5834083\ttest: 0.5832029\tbest: 0.5832029 (62)\ttotal: 1m 12s\tremaining: 17m 58s\n",
      "63:\tlearn: 0.5839599\ttest: 0.5837846\tbest: 0.5837846 (63)\ttotal: 1m 13s\tremaining: 17m 56s\n",
      "64:\tlearn: 0.5846351\ttest: 0.5843881\tbest: 0.5843881 (64)\ttotal: 1m 14s\tremaining: 17m 54s\n",
      "65:\tlearn: 0.5893654\ttest: 0.5891255\tbest: 0.5891255 (65)\ttotal: 1m 15s\tremaining: 17m 52s\n",
      "66:\tlearn: 0.5905078\ttest: 0.5902225\tbest: 0.5902225 (66)\ttotal: 1m 16s\tremaining: 17m 51s\n",
      "67:\tlearn: 0.5903727\ttest: 0.5901393\tbest: 0.5902225 (66)\ttotal: 1m 18s\tremaining: 17m 50s\n",
      "68:\tlearn: 0.5907828\ttest: 0.5904888\tbest: 0.5904888 (68)\ttotal: 1m 19s\tremaining: 17m 49s\n",
      "69:\tlearn: 0.5920712\ttest: 0.5918097\tbest: 0.5918097 (69)\ttotal: 1m 20s\tremaining: 17m 48s\n",
      "70:\tlearn: 0.5921930\ttest: 0.5919262\tbest: 0.5919262 (70)\ttotal: 1m 21s\tremaining: 17m 46s\n",
      "71:\tlearn: 0.5924493\ttest: 0.5921276\tbest: 0.5921276 (71)\ttotal: 1m 22s\tremaining: 17m 44s\n",
      "72:\tlearn: 0.5935541\ttest: 0.5932654\tbest: 0.5932654 (72)\ttotal: 1m 23s\tremaining: 17m 43s\n",
      "73:\tlearn: 0.5947029\ttest: 0.5945313\tbest: 0.5945313 (73)\ttotal: 1m 24s\tremaining: 17m 42s\n",
      "74:\tlearn: 0.5989046\ttest: 0.5986936\tbest: 0.5986936 (74)\ttotal: 1m 26s\tremaining: 17m 41s\n",
      "75:\tlearn: 0.6000105\ttest: 0.5997848\tbest: 0.5997848 (75)\ttotal: 1m 27s\tremaining: 17m 40s\n",
      "76:\tlearn: 0.6006977\ttest: 0.6004256\tbest: 0.6004256 (76)\ttotal: 1m 28s\tremaining: 17m 39s\n",
      "77:\tlearn: 0.6022111\ttest: 0.6019529\tbest: 0.6019529 (77)\ttotal: 1m 29s\tremaining: 17m 38s\n",
      "78:\tlearn: 0.6019711\ttest: 0.6016674\tbest: 0.6019529 (77)\ttotal: 1m 30s\tremaining: 17m 37s\n",
      "79:\tlearn: 0.6034565\ttest: 0.6030391\tbest: 0.6030391 (79)\ttotal: 1m 31s\tremaining: 17m 36s\n",
      "80:\tlearn: 0.6076521\ttest: 0.6074835\tbest: 0.6074835 (80)\ttotal: 1m 33s\tremaining: 17m 36s\n",
      "81:\tlearn: 0.6088442\ttest: 0.6087103\tbest: 0.6087103 (81)\ttotal: 1m 34s\tremaining: 17m 34s\n",
      "82:\tlearn: 0.6139845\ttest: 0.6139488\tbest: 0.6139488 (82)\ttotal: 1m 35s\tremaining: 17m 34s\n",
      "83:\tlearn: 0.6150180\ttest: 0.6150150\tbest: 0.6150150 (83)\ttotal: 1m 36s\tremaining: 17m 33s\n",
      "84:\tlearn: 0.6151373\ttest: 0.6151091\tbest: 0.6151091 (84)\ttotal: 1m 37s\tremaining: 17m 31s\n",
      "85:\tlearn: 0.6166210\ttest: 0.6163975\tbest: 0.6163975 (85)\ttotal: 1m 38s\tremaining: 17m 30s\n",
      "86:\tlearn: 0.6174333\ttest: 0.6172306\tbest: 0.6172306 (86)\ttotal: 1m 40s\tremaining: 17m 29s\n",
      "87:\tlearn: 0.6173256\ttest: 0.6171132\tbest: 0.6172306 (86)\ttotal: 1m 41s\tremaining: 17m 28s\n",
      "88:\tlearn: 0.6204604\ttest: 0.6203617\tbest: 0.6203617 (88)\ttotal: 1m 42s\tremaining: 17m 27s\n",
      "89:\tlearn: 0.6231476\ttest: 0.6230009\tbest: 0.6230009 (89)\ttotal: 1m 43s\tremaining: 17m 26s\n",
      "90:\tlearn: 0.6267448\ttest: 0.6265407\tbest: 0.6265407 (90)\ttotal: 1m 44s\tremaining: 17m 26s\n",
      "91:\tlearn: 0.6279253\ttest: 0.6276635\tbest: 0.6276635 (91)\ttotal: 1m 45s\tremaining: 17m 25s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92:\tlearn: 0.6283786\ttest: 0.6280563\tbest: 0.6280563 (92)\ttotal: 1m 47s\tremaining: 17m 24s\n",
      "93:\tlearn: 0.6284022\ttest: 0.6280896\tbest: 0.6280896 (93)\ttotal: 1m 48s\tremaining: 17m 22s\n",
      "94:\tlearn: 0.6292134\ttest: 0.6288553\tbest: 0.6288553 (94)\ttotal: 1m 49s\tremaining: 17m 21s\n",
      "95:\tlearn: 0.6291282\ttest: 0.6287546\tbest: 0.6288553 (94)\ttotal: 1m 50s\tremaining: 17m 20s\n",
      "96:\tlearn: 0.6305856\ttest: 0.6302652\tbest: 0.6302652 (96)\ttotal: 1m 51s\tremaining: 17m 19s\n",
      "97:\tlearn: 0.6307448\ttest: 0.6303701\tbest: 0.6303701 (97)\ttotal: 1m 52s\tremaining: 17m 18s\n",
      "98:\tlearn: 0.6327246\ttest: 0.6324292\tbest: 0.6324292 (98)\ttotal: 1m 54s\tremaining: 17m 18s\n",
      "99:\tlearn: 0.6368361\ttest: 0.6363910\tbest: 0.6363910 (99)\ttotal: 1m 55s\tremaining: 17m 17s\n",
      "100:\tlearn: 0.6368825\ttest: 0.6364609\tbest: 0.6364609 (100)\ttotal: 1m 56s\tremaining: 17m 15s\n",
      "101:\tlearn: 0.6378626\ttest: 0.6375528\tbest: 0.6375528 (101)\ttotal: 1m 57s\tremaining: 17m 14s\n",
      "102:\tlearn: 0.6388287\ttest: 0.6384917\tbest: 0.6384917 (102)\ttotal: 1m 58s\tremaining: 17m 13s\n",
      "103:\tlearn: 0.6392104\ttest: 0.6387971\tbest: 0.6387971 (103)\ttotal: 1m 59s\tremaining: 17m 12s\n",
      "104:\tlearn: 0.6393660\ttest: 0.6389278\tbest: 0.6389278 (104)\ttotal: 2m 1s\tremaining: 17m 11s\n",
      "105:\tlearn: 0.6400577\ttest: 0.6397551\tbest: 0.6397551 (105)\ttotal: 2m 2s\tremaining: 17m 10s\n",
      "106:\tlearn: 0.6416490\ttest: 0.6415962\tbest: 0.6415962 (106)\ttotal: 2m 3s\tremaining: 17m 9s\n",
      "107:\tlearn: 0.6420799\ttest: 0.6419574\tbest: 0.6419574 (107)\ttotal: 2m 4s\tremaining: 17m 8s\n",
      "108:\tlearn: 0.6427782\ttest: 0.6427223\tbest: 0.6427223 (108)\ttotal: 2m 5s\tremaining: 17m 7s\n",
      "109:\tlearn: 0.6490804\ttest: 0.6492491\tbest: 0.6492491 (109)\ttotal: 2m 6s\tremaining: 17m 6s\n",
      "110:\tlearn: 0.6506689\ttest: 0.6509121\tbest: 0.6509121 (110)\ttotal: 2m 8s\tremaining: 17m 5s\n",
      "111:\tlearn: 0.6506870\ttest: 0.6507947\tbest: 0.6509121 (110)\ttotal: 2m 9s\tremaining: 17m 4s\n",
      "112:\tlearn: 0.6521077\ttest: 0.6522471\tbest: 0.6522471 (112)\ttotal: 2m 10s\tremaining: 17m 3s\n",
      "113:\tlearn: 0.6527525\ttest: 0.6529071\tbest: 0.6529071 (113)\ttotal: 2m 11s\tremaining: 17m 2s\n",
      "114:\tlearn: 0.6539540\ttest: 0.6541447\tbest: 0.6541447 (114)\ttotal: 2m 12s\tremaining: 17m 1s\n",
      "115:\tlearn: 0.6608907\ttest: 0.6610437\tbest: 0.6610437 (115)\ttotal: 2m 13s\tremaining: 17m\n",
      "116:\tlearn: 0.6614217\ttest: 0.6616379\tbest: 0.6616379 (116)\ttotal: 2m 15s\tremaining: 16m 59s\n",
      "117:\tlearn: 0.6642748\ttest: 0.6646076\tbest: 0.6646076 (117)\ttotal: 2m 16s\tremaining: 16m 58s\n",
      "118:\tlearn: 0.6656778\ttest: 0.6660216\tbest: 0.6660216 (118)\ttotal: 2m 17s\tremaining: 16m 57s\n",
      "119:\tlearn: 0.6659511\ttest: 0.6663013\tbest: 0.6663013 (119)\ttotal: 2m 18s\tremaining: 16m 56s\n",
      "120:\tlearn: 0.6669973\ttest: 0.6674024\tbest: 0.6674024 (120)\ttotal: 2m 19s\tremaining: 16m 55s\n",
      "121:\tlearn: 0.6677497\ttest: 0.6681373\tbest: 0.6681373 (121)\ttotal: 2m 20s\tremaining: 16m 54s\n",
      "122:\tlearn: 0.6683800\ttest: 0.6687732\tbest: 0.6687732 (122)\ttotal: 2m 22s\tremaining: 16m 53s\n",
      "123:\tlearn: 0.6693033\ttest: 0.6697936\tbest: 0.6697936 (123)\ttotal: 2m 23s\tremaining: 16m 51s\n",
      "124:\tlearn: 0.6742513\ttest: 0.6746950\tbest: 0.6746950 (124)\ttotal: 2m 24s\tremaining: 16m 51s\n",
      "125:\tlearn: 0.6743437\ttest: 0.6747566\tbest: 0.6747566 (125)\ttotal: 2m 25s\tremaining: 16m 49s\n",
      "126:\tlearn: 0.6746078\ttest: 0.6750313\tbest: 0.6750313 (126)\ttotal: 2m 26s\tremaining: 16m 49s\n",
      "127:\tlearn: 0.6758726\ttest: 0.6763721\tbest: 0.6763721 (127)\ttotal: 2m 27s\tremaining: 16m 47s\n",
      "128:\tlearn: 0.6769610\ttest: 0.6773551\tbest: 0.6773551 (128)\ttotal: 2m 29s\tremaining: 16m 46s\n",
      "129:\tlearn: 0.6795431\ttest: 0.6800600\tbest: 0.6800600 (129)\ttotal: 2m 30s\tremaining: 16m 45s\n",
      "130:\tlearn: 0.6802017\ttest: 0.6806593\tbest: 0.6806593 (130)\ttotal: 2m 31s\tremaining: 16m 44s\n",
      "131:\tlearn: 0.6806892\ttest: 0.6811071\tbest: 0.6811071 (131)\ttotal: 2m 32s\tremaining: 16m 43s\n",
      "132:\tlearn: 0.6814513\ttest: 0.6819643\tbest: 0.6819643 (132)\ttotal: 2m 33s\tremaining: 16m 42s\n",
      "133:\tlearn: 0.6817012\ttest: 0.6821583\tbest: 0.6821583 (133)\ttotal: 2m 34s\tremaining: 16m 41s\n",
      "134:\tlearn: 0.6824503\ttest: 0.6827500\tbest: 0.6827500 (134)\ttotal: 2m 36s\tremaining: 16m 40s\n",
      "135:\tlearn: 0.6823809\ttest: 0.6827151\tbest: 0.6827500 (134)\ttotal: 2m 37s\tremaining: 16m 38s\n",
      "136:\tlearn: 0.6827033\ttest: 0.6830680\tbest: 0.6830680 (136)\ttotal: 2m 38s\tremaining: 16m 37s\n",
      "137:\tlearn: 0.6846423\ttest: 0.6851745\tbest: 0.6851745 (137)\ttotal: 2m 39s\tremaining: 16m 35s\n",
      "138:\tlearn: 0.6847330\ttest: 0.6852378\tbest: 0.6852378 (138)\ttotal: 2m 40s\tremaining: 16m 34s\n",
      "139:\tlearn: 0.6858888\ttest: 0.6863972\tbest: 0.6863972 (139)\ttotal: 2m 41s\tremaining: 16m 33s\n",
      "140:\tlearn: 0.6876197\ttest: 0.6880734\tbest: 0.6880734 (140)\ttotal: 2m 42s\tremaining: 16m 32s\n",
      "141:\tlearn: 0.6885111\ttest: 0.6890172\tbest: 0.6890172 (141)\ttotal: 2m 44s\tremaining: 16m 31s\n",
      "142:\tlearn: 0.6892671\ttest: 0.6897696\tbest: 0.6897696 (142)\ttotal: 2m 45s\tremaining: 16m 30s\n",
      "143:\tlearn: 0.6907555\ttest: 0.6912245\tbest: 0.6912245 (143)\ttotal: 2m 46s\tremaining: 16m 28s\n",
      "144:\tlearn: 0.6914369\ttest: 0.6919469\tbest: 0.6919469 (144)\ttotal: 2m 47s\tremaining: 16m 27s\n",
      "145:\tlearn: 0.6920062\ttest: 0.6925104\tbest: 0.6925104 (145)\ttotal: 2m 48s\tremaining: 16m 26s\n",
      "146:\tlearn: 0.6946646\ttest: 0.6949782\tbest: 0.6949782 (146)\ttotal: 2m 49s\tremaining: 16m 25s\n",
      "147:\tlearn: 0.6953687\ttest: 0.6956715\tbest: 0.6956715 (147)\ttotal: 2m 50s\tremaining: 16m 23s\n",
      "148:\tlearn: 0.6960107\ttest: 0.6962383\tbest: 0.6962383 (148)\ttotal: 2m 52s\tremaining: 16m 23s\n",
      "149:\tlearn: 0.6960784\ttest: 0.6963539\tbest: 0.6963539 (149)\ttotal: 2m 53s\tremaining: 16m 21s\n",
      "150:\tlearn: 0.6964313\ttest: 0.6966527\tbest: 0.6966527 (150)\ttotal: 2m 54s\tremaining: 16m 20s\n",
      "151:\tlearn: 0.6965725\ttest: 0.6968467\tbest: 0.6968467 (151)\ttotal: 2m 55s\tremaining: 16m 19s\n",
      "152:\tlearn: 0.6968385\ttest: 0.6970814\tbest: 0.6970814 (152)\ttotal: 2m 56s\tremaining: 16m 18s\n",
      "153:\tlearn: 0.6967647\ttest: 0.6970381\tbest: 0.6970814 (152)\ttotal: 2m 57s\tremaining: 16m 17s\n",
      "154:\tlearn: 0.6972946\ttest: 0.6976032\tbest: 0.6976032 (154)\ttotal: 2m 59s\tremaining: 16m 16s\n",
      "155:\tlearn: 0.6979649\ttest: 0.6984713\tbest: 0.6984713 (155)\ttotal: 3m\tremaining: 16m 15s\n",
      "156:\tlearn: 0.6987084\ttest: 0.6992945\tbest: 0.6992945 (156)\ttotal: 3m 1s\tremaining: 16m 14s\n",
      "157:\tlearn: 0.6991043\ttest: 0.6996682\tbest: 0.6996682 (157)\ttotal: 3m 2s\tremaining: 16m 13s\n",
      "158:\tlearn: 0.7001023\ttest: 0.7006586\tbest: 0.7006586 (158)\ttotal: 3m 3s\tremaining: 16m 12s\n",
      "159:\tlearn: 0.7002954\ttest: 0.7009349\tbest: 0.7009349 (159)\ttotal: 3m 4s\tremaining: 16m 11s\n",
      "160:\tlearn: 0.7010186\ttest: 0.7015741\tbest: 0.7015741 (160)\ttotal: 3m 6s\tremaining: 16m 10s\n",
      "161:\tlearn: 0.7014106\ttest: 0.7019728\tbest: 0.7019728 (161)\ttotal: 3m 7s\tremaining: 16m 9s\n",
      "162:\tlearn: 0.7015788\ttest: 0.7021709\tbest: 0.7021709 (162)\ttotal: 3m 8s\tremaining: 16m 7s\n",
      "163:\tlearn: 0.7019930\ttest: 0.7025862\tbest: 0.7025862 (163)\ttotal: 3m 9s\tremaining: 16m 7s\n",
      "164:\tlearn: 0.7026300\ttest: 0.7032412\tbest: 0.7032412 (164)\ttotal: 3m 10s\tremaining: 16m 5s\n",
      "165:\tlearn: 0.7030425\ttest: 0.7035841\tbest: 0.7035841 (165)\ttotal: 3m 12s\tremaining: 16m 5s\n",
      "166:\tlearn: 0.7046957\ttest: 0.7052537\tbest: 0.7052537 (166)\ttotal: 3m 13s\tremaining: 16m 3s\n",
      "167:\tlearn: 0.7047085\ttest: 0.7051963\tbest: 0.7052537 (166)\ttotal: 3m 14s\tremaining: 16m 2s\n",
      "168:\tlearn: 0.7044621\ttest: 0.7049624\tbest: 0.7052537 (166)\ttotal: 3m 15s\tremaining: 16m 1s\n",
      "169:\tlearn: 0.7051529\ttest: 0.7056258\tbest: 0.7056258 (169)\ttotal: 3m 16s\tremaining: 16m\n",
      "170:\tlearn: 0.7059988\ttest: 0.7064464\tbest: 0.7064464 (170)\ttotal: 3m 17s\tremaining: 15m 59s\n",
      "171:\tlearn: 0.7061223\ttest: 0.7065346\tbest: 0.7065346 (171)\ttotal: 3m 19s\tremaining: 15m 58s\n",
      "172:\tlearn: 0.7069920\ttest: 0.7074410\tbest: 0.7074410 (172)\ttotal: 3m 20s\tremaining: 15m 57s\n",
      "173:\tlearn: 0.7075144\ttest: 0.7079346\tbest: 0.7079346 (173)\ttotal: 3m 21s\tremaining: 15m 56s\n",
      "174:\tlearn: 0.7082369\ttest: 0.7087202\tbest: 0.7087202 (174)\ttotal: 3m 22s\tremaining: 15m 55s\n",
      "175:\tlearn: 0.7086872\ttest: 0.7091456\tbest: 0.7091456 (175)\ttotal: 3m 23s\tremaining: 15m 54s\n",
      "176:\tlearn: 0.7094329\ttest: 0.7098855\tbest: 0.7098855 (176)\ttotal: 3m 24s\tremaining: 15m 52s\n",
      "177:\tlearn: 0.7095258\ttest: 0.7099729\tbest: 0.7099729 (177)\ttotal: 3m 26s\tremaining: 15m 51s\n",
      "178:\tlearn: 0.7102114\ttest: 0.7106928\tbest: 0.7106928 (178)\ttotal: 3m 27s\tremaining: 15m 50s\n",
      "179:\tlearn: 0.7103542\ttest: 0.7108476\tbest: 0.7108476 (179)\ttotal: 3m 28s\tremaining: 15m 49s\n",
      "180:\tlearn: 0.7111208\ttest: 0.7116233\tbest: 0.7116233 (180)\ttotal: 3m 29s\tremaining: 15m 48s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181:\tlearn: 0.7117209\ttest: 0.7122475\tbest: 0.7122475 (181)\ttotal: 3m 30s\tremaining: 15m 47s\n",
      "182:\tlearn: 0.7124258\ttest: 0.7129708\tbest: 0.7129708 (182)\ttotal: 3m 31s\tremaining: 15m 46s\n",
      "183:\tlearn: 0.7126864\ttest: 0.7131864\tbest: 0.7131864 (183)\ttotal: 3m 33s\tremaining: 15m 45s\n",
      "184:\tlearn: 0.7132970\ttest: 0.7137407\tbest: 0.7137407 (184)\ttotal: 3m 34s\tremaining: 15m 44s\n",
      "185:\tlearn: 0.7133919\ttest: 0.7138364\tbest: 0.7138364 (185)\ttotal: 3m 35s\tremaining: 15m 42s\n",
      "186:\tlearn: 0.7135414\ttest: 0.7140370\tbest: 0.7140370 (186)\ttotal: 3m 36s\tremaining: 15m 41s\n",
      "187:\tlearn: 0.7140524\ttest: 0.7145721\tbest: 0.7145721 (187)\ttotal: 3m 37s\tremaining: 15m 40s\n",
      "188:\tlearn: 0.7144142\ttest: 0.7149433\tbest: 0.7149433 (188)\ttotal: 3m 38s\tremaining: 15m 39s\n",
      "189:\tlearn: 0.7150265\ttest: 0.7154244\tbest: 0.7154244 (189)\ttotal: 3m 40s\tremaining: 15m 38s\n",
      "190:\tlearn: 0.7154912\ttest: 0.7159721\tbest: 0.7159721 (190)\ttotal: 3m 41s\tremaining: 15m 37s\n",
      "191:\tlearn: 0.7157412\ttest: 0.7162334\tbest: 0.7162334 (191)\ttotal: 3m 42s\tremaining: 15m 36s\n",
      "192:\tlearn: 0.7158616\ttest: 0.7163541\tbest: 0.7163541 (192)\ttotal: 3m 43s\tremaining: 15m 35s\n",
      "193:\tlearn: 0.7159540\ttest: 0.7163924\tbest: 0.7163924 (193)\ttotal: 3m 44s\tremaining: 15m 34s\n",
      "194:\tlearn: 0.7168695\ttest: 0.7173961\tbest: 0.7173961 (194)\ttotal: 3m 46s\tremaining: 15m 33s\n",
      "195:\tlearn: 0.7173691\ttest: 0.7178880\tbest: 0.7178880 (195)\ttotal: 3m 47s\tremaining: 15m 32s\n",
      "196:\tlearn: 0.7175936\ttest: 0.7181743\tbest: 0.7181743 (196)\ttotal: 3m 48s\tremaining: 15m 30s\n",
      "197:\tlearn: 0.7180142\ttest: 0.7185988\tbest: 0.7185988 (197)\ttotal: 3m 49s\tremaining: 15m 29s\n",
      "198:\tlearn: 0.7181013\ttest: 0.7186737\tbest: 0.7186737 (198)\ttotal: 3m 50s\tremaining: 15m 28s\n",
      "199:\tlearn: 0.7184320\ttest: 0.7190183\tbest: 0.7190183 (199)\ttotal: 3m 51s\tremaining: 15m 27s\n",
      "200:\tlearn: 0.7188148\ttest: 0.7194269\tbest: 0.7194269 (200)\ttotal: 3m 53s\tremaining: 15m 26s\n",
      "201:\tlearn: 0.7189314\ttest: 0.7195368\tbest: 0.7195368 (201)\ttotal: 3m 54s\tremaining: 15m 25s\n",
      "202:\tlearn: 0.7191652\ttest: 0.7197058\tbest: 0.7197058 (202)\ttotal: 3m 55s\tremaining: 15m 24s\n",
      "203:\tlearn: 0.7191325\ttest: 0.7197041\tbest: 0.7197058 (202)\ttotal: 3m 56s\tremaining: 15m 22s\n",
      "204:\tlearn: 0.7191192\ttest: 0.7197141\tbest: 0.7197141 (204)\ttotal: 3m 57s\tremaining: 15m 21s\n",
      "205:\tlearn: 0.7193281\ttest: 0.7198797\tbest: 0.7198797 (205)\ttotal: 3m 58s\tremaining: 15m 20s\n",
      "206:\tlearn: 0.7201890\ttest: 0.7207420\tbest: 0.7207420 (206)\ttotal: 4m\tremaining: 15m 19s\n",
      "207:\tlearn: 0.7202686\ttest: 0.7208593\tbest: 0.7208593 (207)\ttotal: 4m 1s\tremaining: 15m 18s\n",
      "208:\tlearn: 0.7204886\ttest: 0.7210924\tbest: 0.7210924 (208)\ttotal: 4m 2s\tremaining: 15m 17s\n",
      "209:\tlearn: 0.7206393\ttest: 0.7211781\tbest: 0.7211781 (209)\ttotal: 4m 3s\tremaining: 15m 16s\n",
      "210:\tlearn: 0.7213209\ttest: 0.7218315\tbest: 0.7218315 (210)\ttotal: 4m 4s\tremaining: 15m 15s\n",
      "211:\tlearn: 0.7216080\ttest: 0.7221119\tbest: 0.7221119 (211)\ttotal: 4m 5s\tremaining: 15m 14s\n",
      "212:\tlearn: 0.7219457\ttest: 0.7224898\tbest: 0.7224898 (212)\ttotal: 4m 7s\tremaining: 15m 12s\n",
      "213:\tlearn: 0.7219707\ttest: 0.7225306\tbest: 0.7225306 (213)\ttotal: 4m 8s\tremaining: 15m 11s\n",
      "214:\tlearn: 0.7219651\ttest: 0.7224632\tbest: 0.7225306 (213)\ttotal: 4m 9s\tremaining: 15m 10s\n",
      "215:\tlearn: 0.7223091\ttest: 0.7227528\tbest: 0.7227528 (215)\ttotal: 4m 10s\tremaining: 15m 9s\n",
      "216:\tlearn: 0.7225336\ttest: 0.7230491\tbest: 0.7230491 (216)\ttotal: 4m 11s\tremaining: 15m 8s\n",
      "217:\tlearn: 0.7227081\ttest: 0.7231823\tbest: 0.7231823 (217)\ttotal: 4m 12s\tremaining: 15m 7s\n",
      "218:\tlearn: 0.7231742\ttest: 0.7236176\tbest: 0.7236176 (218)\ttotal: 4m 13s\tremaining: 15m 5s\n",
      "219:\tlearn: 0.7235542\ttest: 0.7239879\tbest: 0.7239879 (219)\ttotal: 4m 15s\tremaining: 15m 4s\n",
      "220:\tlearn: 0.7236733\ttest: 0.7241486\tbest: 0.7241486 (220)\ttotal: 4m 16s\tremaining: 15m 2s\n",
      "221:\tlearn: 0.7238514\ttest: 0.7242992\tbest: 0.7242992 (221)\ttotal: 4m 16s\tremaining: 14m 58s\n",
      "222:\tlearn: 0.7239504\ttest: 0.7243899\tbest: 0.7243899 (222)\ttotal: 4m 16s\tremaining: 14m 55s\n",
      "223:\tlearn: 0.7254710\ttest: 0.7260088\tbest: 0.7260088 (223)\ttotal: 4m 17s\tremaining: 14m 51s\n",
      "224:\tlearn: 0.7258248\ttest: 0.7263683\tbest: 0.7263683 (224)\ttotal: 4m 17s\tremaining: 14m 48s\n",
      "225:\tlearn: 0.7264612\ttest: 0.7270625\tbest: 0.7270625 (225)\ttotal: 4m 18s\tremaining: 14m 45s\n",
      "226:\tlearn: 0.7267902\ttest: 0.7273146\tbest: 0.7273146 (226)\ttotal: 4m 18s\tremaining: 14m 41s\n",
      "227:\tlearn: 0.7275360\ttest: 0.7280246\tbest: 0.7280246 (227)\ttotal: 4m 19s\tremaining: 14m 38s\n",
      "228:\tlearn: 0.7276150\ttest: 0.7281153\tbest: 0.7281153 (228)\ttotal: 4m 20s\tremaining: 14m 36s\n",
      "229:\tlearn: 0.7278087\ttest: 0.7282918\tbest: 0.7282918 (229)\ttotal: 4m 21s\tremaining: 14m 34s\n",
      "230:\tlearn: 0.7281938\ttest: 0.7286821\tbest: 0.7286821 (230)\ttotal: 4m 22s\tremaining: 14m 33s\n",
      "231:\tlearn: 0.7288185\ttest: 0.7292689\tbest: 0.7292689 (231)\ttotal: 4m 23s\tremaining: 14m 31s\n",
      "232:\tlearn: 0.7291329\ttest: 0.7295810\tbest: 0.7295810 (232)\ttotal: 4m 24s\tremaining: 14m 30s\n",
      "233:\tlearn: 0.7291703\ttest: 0.7296326\tbest: 0.7296326 (233)\ttotal: 4m 24s\tremaining: 14m 27s\n",
      "234:\tlearn: 0.7293662\ttest: 0.7298240\tbest: 0.7298240 (234)\ttotal: 4m 25s\tremaining: 14m 24s\n",
      "235:\tlearn: 0.7294070\ttest: 0.7299064\tbest: 0.7299064 (235)\ttotal: 4m 25s\tremaining: 14m 21s\n",
      "236:\tlearn: 0.7296300\ttest: 0.7301037\tbest: 0.7301037 (236)\ttotal: 4m 26s\tremaining: 14m 17s\n",
      "237:\tlearn: 0.7297424\ttest: 0.7302160\tbest: 0.7302160 (237)\ttotal: 4m 26s\tremaining: 14m 14s\n",
      "238:\tlearn: 0.7311659\ttest: 0.7316742\tbest: 0.7316742 (238)\ttotal: 4m 27s\tremaining: 14m 11s\n",
      "239:\tlearn: 0.7314142\ttest: 0.7319481\tbest: 0.7319481 (239)\ttotal: 4m 27s\tremaining: 14m 8s\n",
      "240:\tlearn: 0.7317319\ttest: 0.7322993\tbest: 0.7322993 (240)\ttotal: 4m 28s\tremaining: 14m 5s\n",
      "241:\tlearn: 0.7318037\ttest: 0.7323742\tbest: 0.7323742 (241)\ttotal: 4m 29s\tremaining: 14m 4s\n",
      "242:\tlearn: 0.7318606\ttest: 0.7324166\tbest: 0.7324166 (242)\ttotal: 4m 30s\tremaining: 14m 3s\n",
      "243:\tlearn: 0.7320112\ttest: 0.7325565\tbest: 0.7325565 (243)\ttotal: 4m 32s\tremaining: 14m 2s\n",
      "244:\tlearn: 0.7319860\ttest: 0.7325398\tbest: 0.7325565 (243)\ttotal: 4m 33s\tremaining: 14m 1s\n",
      "245:\tlearn: 0.7324992\ttest: 0.7330592\tbest: 0.7330592 (245)\ttotal: 4m 34s\tremaining: 14m 1s\n",
      "246:\tlearn: 0.7334178\ttest: 0.7341187\tbest: 0.7341187 (246)\ttotal: 4m 35s\tremaining: 14m\n",
      "247:\tlearn: 0.7338476\ttest: 0.7345440\tbest: 0.7345440 (247)\ttotal: 4m 36s\tremaining: 13m 59s\n",
      "248:\tlearn: 0.7338689\ttest: 0.7345740\tbest: 0.7345740 (248)\ttotal: 4m 37s\tremaining: 13m 58s\n",
      "249:\tlearn: 0.7344421\ttest: 0.7351582\tbest: 0.7351582 (249)\ttotal: 4m 39s\tremaining: 13m 57s\n",
      "250:\tlearn: 0.7349193\ttest: 0.7356193\tbest: 0.7356193 (250)\ttotal: 4m 40s\tremaining: 13m 56s\n",
      "251:\tlearn: 0.7351288\ttest: 0.7357999\tbest: 0.7357999 (251)\ttotal: 4m 41s\tremaining: 13m 55s\n",
      "252:\tlearn: 0.7351279\ttest: 0.7357899\tbest: 0.7357999 (251)\ttotal: 4m 42s\tremaining: 13m 52s\n",
      "253:\tlearn: 0.7353335\ttest: 0.7360288\tbest: 0.7360288 (253)\ttotal: 4m 42s\tremaining: 13m 50s\n",
      "254:\tlearn: 0.7356842\ttest: 0.7364250\tbest: 0.7364250 (254)\ttotal: 4m 43s\tremaining: 13m 47s\n",
      "255:\tlearn: 0.7357463\ttest: 0.7364566\tbest: 0.7364566 (255)\ttotal: 4m 43s\tremaining: 13m 44s\n",
      "256:\tlearn: 0.7358900\ttest: 0.7366089\tbest: 0.7366089 (256)\ttotal: 4m 44s\tremaining: 13m 41s\n",
      "257:\tlearn: 0.7361958\ttest: 0.7368769\tbest: 0.7368769 (257)\ttotal: 4m 45s\tremaining: 13m 40s\n",
      "258:\tlearn: 0.7361439\ttest: 0.7368178\tbest: 0.7368769 (257)\ttotal: 4m 46s\tremaining: 13m 39s\n",
      "259:\tlearn: 0.7363778\ttest: 0.7370942\tbest: 0.7370942 (259)\ttotal: 4m 47s\tremaining: 13m 38s\n",
      "260:\tlearn: 0.7370150\ttest: 0.7376468\tbest: 0.7376468 (260)\ttotal: 4m 48s\tremaining: 13m 37s\n",
      "261:\tlearn: 0.7374364\ttest: 0.7381279\tbest: 0.7381279 (261)\ttotal: 4m 49s\tremaining: 13m 36s\n",
      "262:\tlearn: 0.7376498\ttest: 0.7383384\tbest: 0.7383384 (262)\ttotal: 4m 50s\tremaining: 13m 35s\n",
      "263:\tlearn: 0.7377541\ttest: 0.7384358\tbest: 0.7384358 (263)\ttotal: 4m 52s\tremaining: 13m 34s\n",
      "264:\tlearn: 0.7380188\ttest: 0.7387205\tbest: 0.7387205 (264)\ttotal: 4m 53s\tremaining: 13m 33s\n",
      "265:\tlearn: 0.7383925\ttest: 0.7391516\tbest: 0.7391516 (265)\ttotal: 4m 54s\tremaining: 13m 32s\n",
      "266:\tlearn: 0.7385279\ttest: 0.7392407\tbest: 0.7392407 (266)\ttotal: 4m 55s\tremaining: 13m 30s\n",
      "267:\tlearn: 0.7389471\ttest: 0.7396859\tbest: 0.7396859 (267)\ttotal: 4m 56s\tremaining: 13m 29s\n",
      "268:\tlearn: 0.7391515\ttest: 0.7399456\tbest: 0.7399456 (268)\ttotal: 4m 57s\tremaining: 13m 28s\n",
      "269:\tlearn: 0.7392955\ttest: 0.7400946\tbest: 0.7400946 (269)\ttotal: 4m 58s\tremaining: 13m 27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270:\tlearn: 0.7393180\ttest: 0.7400705\tbest: 0.7400946 (269)\ttotal: 4m 59s\tremaining: 13m 26s\n",
      "271:\tlearn: 0.7393887\ttest: 0.7401004\tbest: 0.7401004 (271)\ttotal: 5m 1s\tremaining: 13m 25s\n",
      "272:\tlearn: 0.7398365\ttest: 0.7406115\tbest: 0.7406115 (272)\ttotal: 5m 2s\tremaining: 13m 24s\n",
      "273:\tlearn: 0.7403240\ttest: 0.7410850\tbest: 0.7410850 (273)\ttotal: 5m 3s\tremaining: 13m 23s\n",
      "274:\tlearn: 0.7408175\ttest: 0.7415195\tbest: 0.7415195 (274)\ttotal: 5m 4s\tremaining: 13m 22s\n",
      "275:\tlearn: 0.7411726\ttest: 0.7418924\tbest: 0.7418924 (275)\ttotal: 5m 5s\tremaining: 13m 21s\n",
      "276:\tlearn: 0.7413716\ttest: 0.7420738\tbest: 0.7420738 (276)\ttotal: 5m 6s\tremaining: 13m 20s\n",
      "277:\tlearn: 0.7413993\ttest: 0.7421487\tbest: 0.7421487 (277)\ttotal: 5m 7s\tremaining: 13m 19s\n",
      "278:\tlearn: 0.7422765\ttest: 0.7429985\tbest: 0.7429985 (278)\ttotal: 5m 9s\tremaining: 13m 18s\n",
      "279:\tlearn: 0.7426572\ttest: 0.7433248\tbest: 0.7433248 (279)\ttotal: 5m 10s\tremaining: 13m 17s\n",
      "280:\tlearn: 0.7429796\ttest: 0.7435977\tbest: 0.7435977 (280)\ttotal: 5m 11s\tremaining: 13m 16s\n",
      "281:\tlearn: 0.7432778\ttest: 0.7438999\tbest: 0.7438999 (281)\ttotal: 5m 12s\tremaining: 13m 15s\n",
      "282:\tlearn: 0.7449640\ttest: 0.7456535\tbest: 0.7456535 (282)\ttotal: 5m 13s\tremaining: 13m 14s\n",
      "283:\tlearn: 0.7452098\ttest: 0.7458916\tbest: 0.7458916 (283)\ttotal: 5m 14s\tremaining: 13m 13s\n",
      "284:\tlearn: 0.7452281\ttest: 0.7458916\tbest: 0.7458916 (283)\ttotal: 5m 15s\tremaining: 13m 12s\n",
      "285:\tlearn: 0.7454906\ttest: 0.7461812\tbest: 0.7461812 (285)\ttotal: 5m 17s\tremaining: 13m 11s\n",
      "286:\tlearn: 0.7456213\ttest: 0.7462919\tbest: 0.7462919 (286)\ttotal: 5m 18s\tremaining: 13m 10s\n",
      "287:\tlearn: 0.7456787\ttest: 0.7464126\tbest: 0.7464126 (287)\ttotal: 5m 19s\tremaining: 13m 9s\n",
      "288:\tlearn: 0.7457214\ttest: 0.7464167\tbest: 0.7464167 (288)\ttotal: 5m 20s\tremaining: 13m 8s\n",
      "289:\tlearn: 0.7457475\ttest: 0.7463826\tbest: 0.7464167 (288)\ttotal: 5m 21s\tremaining: 13m 7s\n",
      "290:\tlearn: 0.7461906\ttest: 0.7469036\tbest: 0.7469036 (290)\ttotal: 5m 22s\tremaining: 13m 6s\n",
      "291:\tlearn: 0.7464658\ttest: 0.7471700\tbest: 0.7471700 (291)\ttotal: 5m 23s\tremaining: 13m 5s\n",
      "292:\tlearn: 0.7465759\ttest: 0.7472790\tbest: 0.7472790 (292)\ttotal: 5m 25s\tremaining: 13m 4s\n",
      "293:\tlearn: 0.7469596\ttest: 0.7475620\tbest: 0.7475620 (293)\ttotal: 5m 26s\tremaining: 13m 3s\n",
      "294:\tlearn: 0.7471705\ttest: 0.7478083\tbest: 0.7478083 (294)\ttotal: 5m 27s\tremaining: 13m 2s\n",
      "295:\tlearn: 0.7472523\ttest: 0.7478999\tbest: 0.7478999 (295)\ttotal: 5m 28s\tremaining: 13m 1s\n",
      "296:\tlearn: 0.7473882\ttest: 0.7480272\tbest: 0.7480272 (296)\ttotal: 5m 29s\tremaining: 13m\n",
      "297:\tlearn: 0.7474654\ttest: 0.7481038\tbest: 0.7481038 (297)\ttotal: 5m 30s\tremaining: 12m 59s\n",
      "298:\tlearn: 0.7475153\ttest: 0.7481704\tbest: 0.7481704 (298)\ttotal: 5m 31s\tremaining: 12m 58s\n",
      "299:\tlearn: 0.7475361\ttest: 0.7482212\tbest: 0.7482212 (299)\ttotal: 5m 33s\tremaining: 12m 57s\n",
      "300:\tlearn: 0.7474562\ttest: 0.7481546\tbest: 0.7482212 (299)\ttotal: 5m 34s\tremaining: 12m 56s\n",
      "301:\tlearn: 0.7476013\ttest: 0.7483036\tbest: 0.7483036 (301)\ttotal: 5m 35s\tremaining: 12m 55s\n",
      "302:\tlearn: 0.7477711\ttest: 0.7485008\tbest: 0.7485008 (302)\ttotal: 5m 36s\tremaining: 12m 54s\n",
      "303:\tlearn: 0.7479886\ttest: 0.7486964\tbest: 0.7486964 (303)\ttotal: 5m 37s\tremaining: 12m 53s\n",
      "304:\tlearn: 0.7483274\ttest: 0.7490801\tbest: 0.7490801 (304)\ttotal: 5m 38s\tremaining: 12m 52s\n",
      "305:\tlearn: 0.7485793\ttest: 0.7493348\tbest: 0.7493348 (305)\ttotal: 5m 40s\tremaining: 12m 51s\n",
      "306:\tlearn: 0.7490437\ttest: 0.7497593\tbest: 0.7497593 (306)\ttotal: 5m 41s\tremaining: 12m 50s\n",
      "307:\tlearn: 0.7496158\ttest: 0.7502586\tbest: 0.7502586 (307)\ttotal: 5m 42s\tremaining: 12m 49s\n",
      "308:\tlearn: 0.7498641\ttest: 0.7504892\tbest: 0.7504892 (308)\ttotal: 5m 43s\tremaining: 12m 48s\n",
      "309:\tlearn: 0.7501787\ttest: 0.7508329\tbest: 0.7508329 (309)\ttotal: 5m 44s\tremaining: 12m 47s\n",
      "310:\tlearn: 0.7504231\ttest: 0.7510585\tbest: 0.7510585 (310)\ttotal: 5m 45s\tremaining: 12m 46s\n",
      "311:\tlearn: 0.7509302\ttest: 0.7515246\tbest: 0.7515246 (311)\ttotal: 5m 47s\tremaining: 12m 45s\n",
      "312:\tlearn: 0.7510090\ttest: 0.7516020\tbest: 0.7516020 (312)\ttotal: 5m 48s\tremaining: 12m 44s\n",
      "313:\tlearn: 0.7514085\ttest: 0.7520081\tbest: 0.7520081 (313)\ttotal: 5m 49s\tremaining: 12m 43s\n",
      "314:\tlearn: 0.7515062\ttest: 0.7521305\tbest: 0.7521305 (314)\ttotal: 5m 50s\tremaining: 12m 42s\n",
      "315:\tlearn: 0.7519803\ttest: 0.7526423\tbest: 0.7526423 (315)\ttotal: 5m 51s\tremaining: 12m 41s\n",
      "316:\tlearn: 0.7521720\ttest: 0.7528021\tbest: 0.7528021 (316)\ttotal: 5m 52s\tremaining: 12m 40s\n",
      "317:\tlearn: 0.7522178\ttest: 0.7528171\tbest: 0.7528171 (317)\ttotal: 5m 54s\tremaining: 12m 39s\n",
      "318:\tlearn: 0.7523152\ttest: 0.7529145\tbest: 0.7529145 (318)\ttotal: 5m 55s\tremaining: 12m 38s\n",
      "319:\tlearn: 0.7525013\ttest: 0.7531109\tbest: 0.7531109 (319)\ttotal: 5m 56s\tremaining: 12m 37s\n",
      "320:\tlearn: 0.7527696\ttest: 0.7533415\tbest: 0.7533415 (320)\ttotal: 5m 57s\tremaining: 12m 36s\n",
      "321:\tlearn: 0.7528920\ttest: 0.7535079\tbest: 0.7535079 (321)\ttotal: 5m 58s\tremaining: 12m 35s\n",
      "322:\tlearn: 0.7531186\ttest: 0.7537318\tbest: 0.7537318 (322)\ttotal: 5m 59s\tremaining: 12m 34s\n",
      "323:\tlearn: 0.7533594\ttest: 0.7539965\tbest: 0.7539965 (323)\ttotal: 6m 1s\tremaining: 12m 33s\n",
      "324:\tlearn: 0.7534066\ttest: 0.7540622\tbest: 0.7540622 (324)\ttotal: 6m 2s\tremaining: 12m 32s\n",
      "325:\tlearn: 0.7535972\ttest: 0.7541996\tbest: 0.7541996 (325)\ttotal: 6m 3s\tremaining: 12m 31s\n",
      "326:\tlearn: 0.7537625\ttest: 0.7544409\tbest: 0.7544409 (326)\ttotal: 6m 4s\tremaining: 12m 30s\n",
      "327:\tlearn: 0.7538638\ttest: 0.7545392\tbest: 0.7545392 (327)\ttotal: 6m 5s\tremaining: 12m 29s\n",
      "328:\tlearn: 0.7539046\ttest: 0.7546215\tbest: 0.7546215 (328)\ttotal: 6m 6s\tremaining: 12m 28s\n",
      "329:\tlearn: 0.7541418\ttest: 0.7548446\tbest: 0.7548446 (329)\ttotal: 6m 8s\tremaining: 12m 27s\n",
      "330:\tlearn: 0.7545263\ttest: 0.7552208\tbest: 0.7552208 (330)\ttotal: 6m 9s\tremaining: 12m 26s\n",
      "331:\tlearn: 0.7545732\ttest: 0.7552533\tbest: 0.7552533 (331)\ttotal: 6m 10s\tremaining: 12m 25s\n",
      "332:\tlearn: 0.7554316\ttest: 0.7561080\tbest: 0.7561080 (332)\ttotal: 6m 11s\tremaining: 12m 24s\n",
      "333:\tlearn: 0.7555065\ttest: 0.7562079\tbest: 0.7562079 (333)\ttotal: 6m 12s\tremaining: 12m 23s\n",
      "334:\tlearn: 0.7557179\ttest: 0.7564143\tbest: 0.7564143 (334)\ttotal: 6m 13s\tremaining: 12m 22s\n",
      "335:\tlearn: 0.7563307\ttest: 0.7569944\tbest: 0.7569944 (335)\ttotal: 6m 15s\tremaining: 12m 21s\n",
      "336:\tlearn: 0.7564359\ttest: 0.7571135\tbest: 0.7571135 (336)\ttotal: 6m 16s\tremaining: 12m 20s\n",
      "337:\tlearn: 0.7564500\ttest: 0.7571567\tbest: 0.7571567 (337)\ttotal: 6m 17s\tremaining: 12m 19s\n",
      "338:\tlearn: 0.7565982\ttest: 0.7573057\tbest: 0.7573057 (338)\ttotal: 6m 18s\tremaining: 12m 18s\n",
      "339:\tlearn: 0.7566148\ttest: 0.7573706\tbest: 0.7573706 (339)\ttotal: 6m 19s\tremaining: 12m 16s\n",
      "340:\tlearn: 0.7570279\ttest: 0.7578276\tbest: 0.7578276 (340)\ttotal: 6m 20s\tremaining: 12m 15s\n",
      "341:\tlearn: 0.7570546\ttest: 0.7578459\tbest: 0.7578459 (341)\ttotal: 6m 21s\tremaining: 12m 14s\n",
      "342:\tlearn: 0.7570521\ttest: 0.7578134\tbest: 0.7578459 (341)\ttotal: 6m 22s\tremaining: 12m 13s\n",
      "343:\tlearn: 0.7571203\ttest: 0.7578617\tbest: 0.7578617 (343)\ttotal: 6m 24s\tremaining: 12m 12s\n",
      "344:\tlearn: 0.7572801\ttest: 0.7580914\tbest: 0.7580914 (344)\ttotal: 6m 25s\tremaining: 12m 11s\n",
      "345:\tlearn: 0.7574749\ttest: 0.7582321\tbest: 0.7582321 (345)\ttotal: 6m 26s\tremaining: 12m 10s\n",
      "346:\tlearn: 0.7575587\ttest: 0.7583386\tbest: 0.7583386 (346)\ttotal: 6m 27s\tremaining: 12m 9s\n",
      "347:\tlearn: 0.7576108\ttest: 0.7583711\tbest: 0.7583711 (347)\ttotal: 6m 28s\tremaining: 12m 8s\n",
      "348:\tlearn: 0.7576707\ttest: 0.7584593\tbest: 0.7584593 (348)\ttotal: 6m 29s\tremaining: 12m 7s\n",
      "349:\tlearn: 0.7581854\ttest: 0.7589412\tbest: 0.7589412 (349)\ttotal: 6m 31s\tremaining: 12m 6s\n",
      "350:\tlearn: 0.7583582\ttest: 0.7590585\tbest: 0.7590585 (350)\ttotal: 6m 32s\tremaining: 12m 5s\n",
      "351:\tlearn: 0.7584048\ttest: 0.7591076\tbest: 0.7591076 (351)\ttotal: 6m 33s\tremaining: 12m 4s\n",
      "352:\tlearn: 0.7585086\ttest: 0.7592525\tbest: 0.7592525 (352)\ttotal: 6m 34s\tremaining: 12m 3s\n",
      "353:\tlearn: 0.7585305\ttest: 0.7592525\tbest: 0.7592525 (352)\ttotal: 6m 35s\tremaining: 12m 2s\n",
      "354:\tlearn: 0.7586187\ttest: 0.7593540\tbest: 0.7593540 (354)\ttotal: 6m 36s\tremaining: 12m 1s\n",
      "355:\tlearn: 0.7590390\ttest: 0.7597410\tbest: 0.7597410 (355)\ttotal: 6m 37s\tremaining: 11m 59s\n",
      "356:\tlearn: 0.7591794\ttest: 0.7599308\tbest: 0.7599308 (356)\ttotal: 6m 39s\tremaining: 11m 58s\n",
      "357:\tlearn: 0.7594946\ttest: 0.7602962\tbest: 0.7602962 (357)\ttotal: 6m 40s\tremaining: 11m 58s\n",
      "358:\tlearn: 0.7597784\ttest: 0.7605575\tbest: 0.7605575 (358)\ttotal: 6m 41s\tremaining: 11m 57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359:\tlearn: 0.7599820\ttest: 0.7607747\tbest: 0.7607747 (359)\ttotal: 6m 42s\tremaining: 11m 55s\n",
      "360:\tlearn: 0.7604784\ttest: 0.7612558\tbest: 0.7612558 (360)\ttotal: 6m 43s\tremaining: 11m 54s\n",
      "361:\tlearn: 0.7604820\ttest: 0.7612308\tbest: 0.7612558 (360)\ttotal: 6m 44s\tremaining: 11m 53s\n",
      "362:\tlearn: 0.7606326\ttest: 0.7613956\tbest: 0.7613956 (362)\ttotal: 6m 46s\tremaining: 11m 52s\n",
      "363:\tlearn: 0.7606903\ttest: 0.7614472\tbest: 0.7614472 (363)\ttotal: 6m 47s\tremaining: 11m 51s\n",
      "364:\tlearn: 0.7608698\ttest: 0.7616262\tbest: 0.7616262 (364)\ttotal: 6m 48s\tremaining: 11m 50s\n",
      "365:\tlearn: 0.7611609\ttest: 0.7619125\tbest: 0.7619125 (365)\ttotal: 6m 49s\tremaining: 11m 49s\n",
      "366:\tlearn: 0.7611778\ttest: 0.7618983\tbest: 0.7619125 (365)\ttotal: 6m 50s\tremaining: 11m 48s\n",
      "367:\tlearn: 0.7619074\ttest: 0.7625891\tbest: 0.7625891 (367)\ttotal: 6m 51s\tremaining: 11m 47s\n",
      "368:\tlearn: 0.7619568\ttest: 0.7626599\tbest: 0.7626599 (368)\ttotal: 6m 52s\tremaining: 11m 46s\n",
      "369:\tlearn: 0.7623913\ttest: 0.7630461\tbest: 0.7630461 (369)\ttotal: 6m 54s\tremaining: 11m 45s\n",
      "370:\tlearn: 0.7625744\ttest: 0.7632200\tbest: 0.7632200 (370)\ttotal: 6m 55s\tremaining: 11m 44s\n",
      "371:\tlearn: 0.7625450\ttest: 0.7631726\tbest: 0.7632200 (370)\ttotal: 6m 56s\tremaining: 11m 43s\n",
      "372:\tlearn: 0.7626357\ttest: 0.7633058\tbest: 0.7633058 (372)\ttotal: 6m 57s\tremaining: 11m 42s\n",
      "373:\tlearn: 0.7630535\ttest: 0.7636928\tbest: 0.7636928 (373)\ttotal: 6m 58s\tremaining: 11m 41s\n",
      "374:\tlearn: 0.7631084\ttest: 0.7637485\tbest: 0.7637485 (374)\ttotal: 6m 59s\tremaining: 11m 39s\n",
      "375:\tlearn: 0.7638564\ttest: 0.7644402\tbest: 0.7644402 (375)\ttotal: 7m 1s\tremaining: 11m 38s\n",
      "376:\tlearn: 0.7641180\ttest: 0.7646965\tbest: 0.7646965 (376)\ttotal: 7m 2s\tremaining: 11m 37s\n",
      "377:\tlearn: 0.7645614\ttest: 0.7651069\tbest: 0.7651069 (377)\ttotal: 7m 3s\tremaining: 11m 36s\n",
      "378:\tlearn: 0.7649911\ttest: 0.7655571\tbest: 0.7655571 (378)\ttotal: 7m 4s\tremaining: 11m 35s\n",
      "379:\tlearn: 0.7651670\ttest: 0.7657336\tbest: 0.7657336 (379)\ttotal: 7m 5s\tremaining: 11m 34s\n",
      "380:\tlearn: 0.7653365\ttest: 0.7658900\tbest: 0.7658900 (380)\ttotal: 7m 6s\tremaining: 11m 33s\n",
      "381:\tlearn: 0.7654028\ttest: 0.7659350\tbest: 0.7659350 (381)\ttotal: 7m 8s\tremaining: 11m 32s\n",
      "382:\tlearn: 0.7655332\ttest: 0.7660840\tbest: 0.7660840 (382)\ttotal: 7m 9s\tremaining: 11m 31s\n",
      "383:\tlearn: 0.7654530\ttest: 0.7660274\tbest: 0.7660840 (382)\ttotal: 7m 10s\tremaining: 11m 30s\n",
      "384:\tlearn: 0.7658073\ttest: 0.7663728\tbest: 0.7663728 (384)\ttotal: 7m 11s\tremaining: 11m 29s\n",
      "385:\tlearn: 0.7660337\ttest: 0.7665792\tbest: 0.7665792 (385)\ttotal: 7m 12s\tremaining: 11m 28s\n",
      "386:\tlearn: 0.7664926\ttest: 0.7670395\tbest: 0.7670395 (386)\ttotal: 7m 13s\tremaining: 11m 27s\n",
      "387:\tlearn: 0.7664951\ttest: 0.7670811\tbest: 0.7670811 (387)\ttotal: 7m 15s\tremaining: 11m 26s\n",
      "388:\tlearn: 0.7665611\ttest: 0.7671360\tbest: 0.7671360 (388)\ttotal: 7m 16s\tremaining: 11m 24s\n",
      "389:\tlearn: 0.7666377\ttest: 0.7671876\tbest: 0.7671876 (389)\ttotal: 7m 17s\tremaining: 11m 23s\n",
      "390:\tlearn: 0.7665869\ttest: 0.7671660\tbest: 0.7671876 (389)\ttotal: 7m 18s\tremaining: 11m 22s\n",
      "391:\tlearn: 0.7669057\ttest: 0.7674323\tbest: 0.7674323 (391)\ttotal: 7m 19s\tremaining: 11m 21s\n",
      "392:\tlearn: 0.7668829\ttest: 0.7674972\tbest: 0.7674972 (392)\ttotal: 7m 20s\tremaining: 11m 20s\n",
      "393:\tlearn: 0.7672366\ttest: 0.7678193\tbest: 0.7678193 (393)\ttotal: 7m 21s\tremaining: 11m 19s\n",
      "394:\tlearn: 0.7677871\ttest: 0.7684119\tbest: 0.7684119 (394)\ttotal: 7m 22s\tremaining: 11m 18s\n",
      "395:\tlearn: 0.7678814\ttest: 0.7685351\tbest: 0.7685351 (395)\ttotal: 7m 24s\tremaining: 11m 17s\n",
      "396:\tlearn: 0.7678201\ttest: 0.7684619\tbest: 0.7685351 (395)\ttotal: 7m 25s\tremaining: 11m 16s\n",
      "397:\tlearn: 0.7681480\ttest: 0.7688356\tbest: 0.7688356 (397)\ttotal: 7m 26s\tremaining: 11m 15s\n",
      "398:\tlearn: 0.7683536\ttest: 0.7690345\tbest: 0.7690345 (398)\ttotal: 7m 27s\tremaining: 11m 14s\n",
      "399:\tlearn: 0.7684449\ttest: 0.7691210\tbest: 0.7691210 (399)\ttotal: 7m 28s\tremaining: 11m 13s\n",
      "400:\tlearn: 0.7686341\ttest: 0.7693183\tbest: 0.7693183 (400)\ttotal: 7m 29s\tremaining: 11m 12s\n",
      "401:\tlearn: 0.7690075\ttest: 0.7697153\tbest: 0.7697153 (401)\ttotal: 7m 31s\tremaining: 11m 10s\n",
      "402:\tlearn: 0.7691837\ttest: 0.7699259\tbest: 0.7699259 (402)\ttotal: 7m 32s\tremaining: 11m 9s\n",
      "403:\tlearn: 0.7692799\ttest: 0.7699442\tbest: 0.7699442 (403)\ttotal: 7m 33s\tremaining: 11m 8s\n",
      "404:\tlearn: 0.7694292\ttest: 0.7700757\tbest: 0.7700757 (404)\ttotal: 7m 34s\tremaining: 11m 7s\n",
      "405:\tlearn: 0.7695485\ttest: 0.7701406\tbest: 0.7701406 (405)\ttotal: 7m 35s\tremaining: 11m 6s\n",
      "406:\tlearn: 0.7698517\ttest: 0.7704377\tbest: 0.7704377 (406)\ttotal: 7m 36s\tremaining: 11m 5s\n",
      "407:\tlearn: 0.7700878\ttest: 0.7706158\tbest: 0.7706158 (407)\ttotal: 7m 38s\tremaining: 11m 4s\n",
      "408:\tlearn: 0.7701489\ttest: 0.7706808\tbest: 0.7706808 (408)\ttotal: 7m 39s\tremaining: 11m 3s\n",
      "409:\tlearn: 0.7704316\ttest: 0.7709363\tbest: 0.7709363 (409)\ttotal: 7m 40s\tremaining: 11m 2s\n",
      "410:\tlearn: 0.7706546\ttest: 0.7711535\tbest: 0.7711535 (410)\ttotal: 7m 41s\tremaining: 11m 1s\n",
      "411:\tlearn: 0.7708680\ttest: 0.7713732\tbest: 0.7713732 (411)\ttotal: 7m 42s\tremaining: 11m\n",
      "412:\tlearn: 0.7716051\ttest: 0.7721265\tbest: 0.7721265 (412)\ttotal: 7m 43s\tremaining: 10m 59s\n",
      "413:\tlearn: 0.7719070\ttest: 0.7724169\tbest: 0.7724169 (413)\ttotal: 7m 45s\tremaining: 10m 58s\n",
      "414:\tlearn: 0.7721084\ttest: 0.7726308\tbest: 0.7726308 (414)\ttotal: 7m 46s\tremaining: 10m 57s\n",
      "415:\tlearn: 0.7723825\ttest: 0.7728922\tbest: 0.7728922 (415)\ttotal: 7m 47s\tremaining: 10m 56s\n",
      "416:\tlearn: 0.7724868\ttest: 0.7730320\tbest: 0.7730320 (416)\ttotal: 7m 48s\tremaining: 10m 55s\n",
      "417:\tlearn: 0.7725512\ttest: 0.7730770\tbest: 0.7730770 (417)\ttotal: 7m 49s\tremaining: 10m 54s\n",
      "418:\tlearn: 0.7725090\ttest: 0.7730636\tbest: 0.7730770 (417)\ttotal: 7m 50s\tremaining: 10m 52s\n",
      "419:\tlearn: 0.7725384\ttest: 0.7730911\tbest: 0.7730911 (419)\ttotal: 7m 52s\tremaining: 10m 51s\n",
      "420:\tlearn: 0.7730281\ttest: 0.7734856\tbest: 0.7734856 (420)\ttotal: 7m 53s\tremaining: 10m 50s\n",
      "421:\tlearn: 0.7734364\ttest: 0.7740075\tbest: 0.7740075 (421)\ttotal: 7m 54s\tremaining: 10m 49s\n",
      "422:\tlearn: 0.7735047\ttest: 0.7741140\tbest: 0.7741140 (422)\ttotal: 7m 55s\tremaining: 10m 48s\n",
      "423:\tlearn: 0.7735435\ttest: 0.7741423\tbest: 0.7741423 (423)\ttotal: 7m 56s\tremaining: 10m 47s\n",
      "424:\tlearn: 0.7736304\ttest: 0.7742630\tbest: 0.7742630 (424)\ttotal: 7m 57s\tremaining: 10m 46s\n",
      "425:\tlearn: 0.7742890\ttest: 0.7749471\tbest: 0.7749471 (425)\ttotal: 7m 58s\tremaining: 10m 45s\n",
      "426:\tlearn: 0.7745725\ttest: 0.7752426\tbest: 0.7752426 (426)\ttotal: 8m\tremaining: 10m 44s\n",
      "427:\tlearn: 0.7746119\ttest: 0.7752684\tbest: 0.7752684 (427)\ttotal: 8m 1s\tremaining: 10m 43s\n",
      "428:\tlearn: 0.7749227\ttest: 0.7755456\tbest: 0.7755456 (428)\ttotal: 8m 2s\tremaining: 10m 41s\n",
      "429:\tlearn: 0.7749673\ttest: 0.7755614\tbest: 0.7755614 (429)\ttotal: 8m 3s\tremaining: 10m 40s\n",
      "430:\tlearn: 0.7750686\ttest: 0.7756396\tbest: 0.7756396 (430)\ttotal: 8m 4s\tremaining: 10m 39s\n",
      "431:\tlearn: 0.7753183\ttest: 0.7759184\tbest: 0.7759184 (431)\ttotal: 8m 5s\tremaining: 10m 38s\n",
      "432:\tlearn: 0.7756137\ttest: 0.7761273\tbest: 0.7761273 (432)\ttotal: 8m 6s\tremaining: 10m 37s\n",
      "433:\tlearn: 0.7756892\ttest: 0.7762330\tbest: 0.7762330 (433)\ttotal: 8m 8s\tremaining: 10m 36s\n",
      "434:\tlearn: 0.7761914\ttest: 0.7767058\tbest: 0.7767058 (434)\ttotal: 8m 9s\tremaining: 10m 35s\n",
      "435:\tlearn: 0.7762554\ttest: 0.7767732\tbest: 0.7767732 (435)\ttotal: 8m 10s\tremaining: 10m 34s\n",
      "436:\tlearn: 0.7763853\ttest: 0.7769421\tbest: 0.7769421 (436)\ttotal: 8m 11s\tremaining: 10m 33s\n",
      "437:\tlearn: 0.7765728\ttest: 0.7771261\tbest: 0.7771261 (437)\ttotal: 8m 12s\tremaining: 10m 32s\n",
      "438:\tlearn: 0.7767873\ttest: 0.7773616\tbest: 0.7773616 (438)\ttotal: 8m 13s\tremaining: 10m 31s\n",
      "439:\tlearn: 0.7770481\ttest: 0.7776296\tbest: 0.7776296 (439)\ttotal: 8m 15s\tremaining: 10m 30s\n",
      "440:\tlearn: 0.7772012\ttest: 0.7777728\tbest: 0.7777728 (440)\ttotal: 8m 16s\tremaining: 10m 28s\n",
      "441:\tlearn: 0.7772362\ttest: 0.7777769\tbest: 0.7777769 (441)\ttotal: 8m 17s\tremaining: 10m 27s\n",
      "442:\tlearn: 0.7776576\ttest: 0.7782580\tbest: 0.7782580 (442)\ttotal: 8m 18s\tremaining: 10m 26s\n",
      "443:\tlearn: 0.7777575\ttest: 0.7783670\tbest: 0.7783670 (443)\ttotal: 8m 19s\tremaining: 10m 25s\n",
      "444:\tlearn: 0.7777289\ttest: 0.7783562\tbest: 0.7783670 (443)\ttotal: 8m 20s\tremaining: 10m 24s\n",
      "445:\tlearn: 0.7780748\ttest: 0.7786450\tbest: 0.7786450 (445)\ttotal: 8m 21s\tremaining: 10m 23s\n",
      "446:\tlearn: 0.7780918\ttest: 0.7786392\tbest: 0.7786450 (445)\ttotal: 8m 22s\tremaining: 10m 22s\n",
      "447:\tlearn: 0.7781811\ttest: 0.7787424\tbest: 0.7787424 (447)\ttotal: 8m 24s\tremaining: 10m 21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448:\tlearn: 0.7782566\ttest: 0.7788514\tbest: 0.7788514 (448)\ttotal: 8m 25s\tremaining: 10m 20s\n",
      "449:\tlearn: 0.7783967\ttest: 0.7789671\tbest: 0.7789671 (449)\ttotal: 8m 26s\tremaining: 10m 18s\n",
      "450:\tlearn: 0.7786816\ttest: 0.7791727\tbest: 0.7791727 (450)\ttotal: 8m 27s\tremaining: 10m 17s\n",
      "451:\tlearn: 0.7787620\ttest: 0.7792526\tbest: 0.7792526 (451)\ttotal: 8m 28s\tremaining: 10m 16s\n",
      "452:\tlearn: 0.7788958\ttest: 0.7793825\tbest: 0.7793825 (452)\ttotal: 8m 29s\tremaining: 10m 15s\n",
      "453:\tlearn: 0.7790092\ttest: 0.7794873\tbest: 0.7794873 (453)\ttotal: 8m 31s\tremaining: 10m 14s\n",
      "454:\tlearn: 0.7790961\ttest: 0.7795456\tbest: 0.7795456 (454)\ttotal: 8m 32s\tremaining: 10m 13s\n",
      "455:\tlearn: 0.7791382\ttest: 0.7796238\tbest: 0.7796238 (455)\ttotal: 8m 33s\tremaining: 10m 12s\n",
      "456:\tlearn: 0.7795641\ttest: 0.7800583\tbest: 0.7800583 (456)\ttotal: 8m 34s\tremaining: 10m 11s\n",
      "457:\tlearn: 0.7796967\ttest: 0.7802031\tbest: 0.7802031 (457)\ttotal: 8m 35s\tremaining: 10m 10s\n",
      "458:\tlearn: 0.7799051\ttest: 0.7803429\tbest: 0.7803429 (458)\ttotal: 8m 36s\tremaining: 10m 9s\n",
      "459:\tlearn: 0.7800069\ttest: 0.7804370\tbest: 0.7804370 (459)\ttotal: 8m 37s\tremaining: 10m 7s\n",
      "460:\tlearn: 0.7801070\ttest: 0.7805610\tbest: 0.7805610 (460)\ttotal: 8m 39s\tremaining: 10m 6s\n",
      "461:\tlearn: 0.7801975\ttest: 0.7806684\tbest: 0.7806684 (461)\ttotal: 8m 40s\tremaining: 10m 5s\n",
      "462:\tlearn: 0.7806983\ttest: 0.7810737\tbest: 0.7810737 (462)\ttotal: 8m 41s\tremaining: 10m 4s\n",
      "463:\tlearn: 0.7807532\ttest: 0.7811236\tbest: 0.7811236 (463)\ttotal: 8m 42s\tremaining: 10m 3s\n",
      "464:\tlearn: 0.7809432\ttest: 0.7812926\tbest: 0.7812926 (464)\ttotal: 8m 43s\tremaining: 10m 2s\n",
      "465:\tlearn: 0.7809538\ttest: 0.7813192\tbest: 0.7813192 (465)\ttotal: 8m 44s\tremaining: 10m 1s\n",
      "466:\tlearn: 0.7810550\ttest: 0.7813991\tbest: 0.7813991 (466)\ttotal: 8m 46s\tremaining: 10m\n",
      "467:\tlearn: 0.7812867\ttest: 0.7816954\tbest: 0.7816954 (467)\ttotal: 8m 47s\tremaining: 9m 59s\n",
      "468:\tlearn: 0.7814748\ttest: 0.7818669\tbest: 0.7818669 (468)\ttotal: 8m 48s\tremaining: 9m 58s\n",
      "469:\tlearn: 0.7815294\ttest: 0.7820042\tbest: 0.7820042 (469)\ttotal: 8m 49s\tremaining: 9m 57s\n",
      "470:\tlearn: 0.7817583\ttest: 0.7822123\tbest: 0.7822123 (470)\ttotal: 8m 50s\tremaining: 9m 56s\n",
      "471:\tlearn: 0.7818712\ttest: 0.7823213\tbest: 0.7823213 (471)\ttotal: 8m 51s\tremaining: 9m 54s\n",
      "472:\tlearn: 0.7818948\ttest: 0.7823887\tbest: 0.7823887 (472)\ttotal: 8m 52s\tremaining: 9m 53s\n",
      "473:\tlearn: 0.7821748\ttest: 0.7826817\tbest: 0.7826817 (473)\ttotal: 8m 54s\tremaining: 9m 52s\n",
      "474:\tlearn: 0.7822097\ttest: 0.7826933\tbest: 0.7826933 (474)\ttotal: 8m 55s\tremaining: 9m 51s\n",
      "475:\tlearn: 0.7822635\ttest: 0.7827283\tbest: 0.7827283 (475)\ttotal: 8m 56s\tremaining: 9m 50s\n",
      "476:\tlearn: 0.7825621\ttest: 0.7829863\tbest: 0.7829863 (476)\ttotal: 8m 57s\tremaining: 9m 49s\n",
      "477:\tlearn: 0.7827607\ttest: 0.7832268\tbest: 0.7832268 (477)\ttotal: 8m 58s\tremaining: 9m 48s\n",
      "478:\tlearn: 0.7827635\ttest: 0.7832335\tbest: 0.7832335 (478)\ttotal: 8m 59s\tremaining: 9m 47s\n",
      "479:\tlearn: 0.7829413\ttest: 0.7834382\tbest: 0.7834382 (479)\ttotal: 9m 1s\tremaining: 9m 46s\n",
      "480:\tlearn: 0.7829890\ttest: 0.7834607\tbest: 0.7834607 (480)\ttotal: 9m 2s\tremaining: 9m 45s\n",
      "481:\tlearn: 0.7830434\ttest: 0.7835181\tbest: 0.7835181 (481)\ttotal: 9m 3s\tremaining: 9m 44s\n",
      "482:\tlearn: 0.7832862\ttest: 0.7837295\tbest: 0.7837295 (482)\ttotal: 9m 4s\tremaining: 9m 42s\n",
      "483:\tlearn: 0.7833403\ttest: 0.7838469\tbest: 0.7838469 (483)\ttotal: 9m 5s\tremaining: 9m 41s\n",
      "484:\tlearn: 0.7833919\ttest: 0.7838968\tbest: 0.7838968 (484)\ttotal: 9m 6s\tremaining: 9m 40s\n",
      "485:\tlearn: 0.7834163\ttest: 0.7839052\tbest: 0.7839052 (485)\ttotal: 9m 8s\tremaining: 9m 39s\n",
      "486:\tlearn: 0.7834951\ttest: 0.7839726\tbest: 0.7839726 (486)\ttotal: 9m 9s\tremaining: 9m 38s\n",
      "487:\tlearn: 0.7840202\ttest: 0.7845643\tbest: 0.7845643 (487)\ttotal: 9m 10s\tremaining: 9m 37s\n",
      "488:\tlearn: 0.7841343\ttest: 0.7846459\tbest: 0.7846459 (488)\ttotal: 9m 11s\tremaining: 9m 36s\n",
      "489:\tlearn: 0.7842239\ttest: 0.7847533\tbest: 0.7847533 (489)\ttotal: 9m 12s\tremaining: 9m 35s\n",
      "490:\tlearn: 0.7842877\ttest: 0.7847991\tbest: 0.7847991 (490)\ttotal: 9m 13s\tremaining: 9m 34s\n",
      "491:\tlearn: 0.7847479\ttest: 0.7852626\tbest: 0.7852626 (491)\ttotal: 9m 15s\tremaining: 9m 33s\n",
      "492:\tlearn: 0.7849954\ttest: 0.7855473\tbest: 0.7855473 (492)\ttotal: 9m 16s\tremaining: 9m 31s\n",
      "493:\tlearn: 0.7849960\ttest: 0.7855298\tbest: 0.7855473 (492)\ttotal: 9m 17s\tremaining: 9m 30s\n",
      "494:\tlearn: 0.7851347\ttest: 0.7856455\tbest: 0.7856455 (494)\ttotal: 9m 18s\tremaining: 9m 29s\n",
      "495:\tlearn: 0.7855009\ttest: 0.7860791\tbest: 0.7860791 (495)\ttotal: 9m 19s\tremaining: 9m 28s\n",
      "496:\tlearn: 0.7856787\ttest: 0.7862223\tbest: 0.7862223 (496)\ttotal: 9m 20s\tremaining: 9m 27s\n",
      "497:\tlearn: 0.7859273\ttest: 0.7864212\tbest: 0.7864212 (497)\ttotal: 9m 21s\tremaining: 9m 26s\n",
      "498:\tlearn: 0.7862858\ttest: 0.7867816\tbest: 0.7867816 (498)\ttotal: 9m 22s\tremaining: 9m 25s\n",
      "499:\tlearn: 0.7863343\ttest: 0.7868731\tbest: 0.7868731 (499)\ttotal: 9m 24s\tremaining: 9m 24s\n",
      "500:\tlearn: 0.7865463\ttest: 0.7871170\tbest: 0.7871170 (500)\ttotal: 9m 25s\tremaining: 9m 22s\n",
      "501:\tlearn: 0.7868251\ttest: 0.7873234\tbest: 0.7873234 (501)\ttotal: 9m 26s\tremaining: 9m 21s\n",
      "502:\tlearn: 0.7870060\ttest: 0.7875099\tbest: 0.7875099 (502)\ttotal: 9m 27s\tremaining: 9m 20s\n",
      "503:\tlearn: 0.7870895\ttest: 0.7876414\tbest: 0.7876414 (503)\ttotal: 9m 28s\tremaining: 9m 19s\n",
      "504:\tlearn: 0.7871882\ttest: 0.7877287\tbest: 0.7877287 (504)\ttotal: 9m 29s\tremaining: 9m 18s\n",
      "505:\tlearn: 0.7872523\ttest: 0.7877870\tbest: 0.7877870 (505)\ttotal: 9m 30s\tremaining: 9m 17s\n",
      "506:\tlearn: 0.7872729\ttest: 0.7877970\tbest: 0.7877970 (506)\ttotal: 9m 32s\tremaining: 9m 16s\n",
      "507:\tlearn: 0.7872232\ttest: 0.7877521\tbest: 0.7877970 (506)\ttotal: 9m 33s\tremaining: 9m 15s\n",
      "508:\tlearn: 0.7873173\ttest: 0.7878444\tbest: 0.7878444 (508)\ttotal: 9m 34s\tremaining: 9m 14s\n",
      "509:\tlearn: 0.7874324\ttest: 0.7880117\tbest: 0.7880117 (509)\ttotal: 9m 35s\tremaining: 9m 13s\n",
      "510:\tlearn: 0.7874424\ttest: 0.7879901\tbest: 0.7880117 (509)\ttotal: 9m 36s\tremaining: 9m 11s\n",
      "511:\tlearn: 0.7875730\ttest: 0.7881466\tbest: 0.7881466 (511)\ttotal: 9m 37s\tremaining: 9m 10s\n",
      "512:\tlearn: 0.7876047\ttest: 0.7881391\tbest: 0.7881466 (511)\ttotal: 9m 38s\tremaining: 9m 8s\n",
      "513:\tlearn: 0.7876668\ttest: 0.7882007\tbest: 0.7882007 (513)\ttotal: 9m 38s\tremaining: 9m 7s\n",
      "514:\tlearn: 0.7877695\ttest: 0.7883213\tbest: 0.7883213 (514)\ttotal: 9m 38s\tremaining: 9m 5s\n",
      "515:\tlearn: 0.7880500\ttest: 0.7885744\tbest: 0.7885744 (515)\ttotal: 9m 39s\tremaining: 9m 3s\n",
      "516:\tlearn: 0.7882664\ttest: 0.7887650\tbest: 0.7887650 (516)\ttotal: 9m 40s\tremaining: 9m 1s\n",
      "517:\tlearn: 0.7882969\ttest: 0.7887749\tbest: 0.7887749 (517)\ttotal: 9m 40s\tremaining: 9m\n",
      "518:\tlearn: 0.7884508\ttest: 0.7889089\tbest: 0.7889089 (518)\ttotal: 9m 41s\tremaining: 8m 58s\n",
      "519:\tlearn: 0.7885227\ttest: 0.7889888\tbest: 0.7889888 (519)\ttotal: 9m 41s\tremaining: 8m 56s\n",
      "520:\tlearn: 0.7886018\ttest: 0.7890471\tbest: 0.7890471 (520)\ttotal: 9m 42s\tremaining: 8m 55s\n",
      "521:\tlearn: 0.7887605\ttest: 0.7892394\tbest: 0.7892394 (521)\ttotal: 9m 43s\tremaining: 8m 54s\n",
      "522:\tlearn: 0.7888295\ttest: 0.7892743\tbest: 0.7892743 (522)\ttotal: 9m 44s\tremaining: 8m 53s\n",
      "523:\tlearn: 0.7894133\ttest: 0.7898769\tbest: 0.7898769 (523)\ttotal: 9m 45s\tremaining: 8m 52s\n",
      "524:\tlearn: 0.7894221\ttest: 0.7898653\tbest: 0.7898769 (523)\ttotal: 9m 46s\tremaining: 8m 50s\n",
      "525:\tlearn: 0.7898752\ttest: 0.7903488\tbest: 0.7903488 (525)\ttotal: 9m 47s\tremaining: 8m 49s\n",
      "526:\tlearn: 0.7901318\ttest: 0.7905894\tbest: 0.7905894 (526)\ttotal: 9m 47s\tremaining: 8m 47s\n",
      "527:\tlearn: 0.7905324\ttest: 0.7909223\tbest: 0.7909223 (527)\ttotal: 9m 48s\tremaining: 8m 45s\n",
      "528:\tlearn: 0.7909025\ttest: 0.7913018\tbest: 0.7913018 (528)\ttotal: 9m 48s\tremaining: 8m 43s\n",
      "529:\tlearn: 0.7912393\ttest: 0.7916730\tbest: 0.7916730 (529)\ttotal: 9m 48s\tremaining: 8m 42s\n",
      "530:\tlearn: 0.7912879\ttest: 0.7917346\tbest: 0.7917346 (530)\ttotal: 9m 49s\tremaining: 8m 40s\n",
      "531:\tlearn: 0.7916785\ttest: 0.7921133\tbest: 0.7921133 (531)\ttotal: 9m 49s\tremaining: 8m 38s\n",
      "532:\tlearn: 0.7917792\ttest: 0.7921441\tbest: 0.7921441 (532)\ttotal: 9m 50s\tremaining: 8m 37s\n",
      "533:\tlearn: 0.7918594\ttest: 0.7922115\tbest: 0.7922115 (533)\ttotal: 9m 52s\tremaining: 8m 36s\n",
      "534:\tlearn: 0.7919418\ttest: 0.7922706\tbest: 0.7922706 (534)\ttotal: 9m 53s\tremaining: 8m 35s\n",
      "535:\tlearn: 0.7920303\ttest: 0.7923380\tbest: 0.7923380 (535)\ttotal: 9m 54s\tremaining: 8m 34s\n",
      "536:\tlearn: 0.7923113\ttest: 0.7927217\tbest: 0.7927217 (536)\ttotal: 9m 55s\tremaining: 8m 33s\n",
      "537:\tlearn: 0.7923621\ttest: 0.7926593\tbest: 0.7927217 (536)\ttotal: 9m 56s\tremaining: 8m 32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538:\tlearn: 0.7924431\ttest: 0.7927750\tbest: 0.7927750 (538)\ttotal: 9m 58s\tremaining: 8m 31s\n",
      "539:\tlearn: 0.7925091\ttest: 0.7928499\tbest: 0.7928499 (539)\ttotal: 9m 59s\tremaining: 8m 30s\n",
      "540:\tlearn: 0.7927719\ttest: 0.7931037\tbest: 0.7931037 (540)\ttotal: 10m\tremaining: 8m 29s\n",
      "541:\tlearn: 0.7928853\ttest: 0.7932036\tbest: 0.7932036 (541)\ttotal: 10m 1s\tremaining: 8m 28s\n",
      "542:\tlearn: 0.7930451\ttest: 0.7933601\tbest: 0.7933601 (542)\ttotal: 10m 2s\tremaining: 8m 27s\n",
      "543:\tlearn: 0.7931456\ttest: 0.7934816\tbest: 0.7934816 (543)\ttotal: 10m 3s\tremaining: 8m 26s\n",
      "544:\tlearn: 0.7933617\ttest: 0.7937005\tbest: 0.7937005 (544)\ttotal: 10m 4s\tremaining: 8m 24s\n",
      "545:\tlearn: 0.7934707\ttest: 0.7938062\tbest: 0.7938062 (545)\ttotal: 10m 4s\tremaining: 8m 22s\n",
      "546:\tlearn: 0.7935096\ttest: 0.7938736\tbest: 0.7938736 (546)\ttotal: 10m 5s\tremaining: 8m 21s\n",
      "547:\tlearn: 0.7935287\ttest: 0.7938861\tbest: 0.7938861 (547)\ttotal: 10m 5s\tremaining: 8m 19s\n",
      "548:\tlearn: 0.7934999\ttest: 0.7938636\tbest: 0.7938861 (547)\ttotal: 10m 6s\tremaining: 8m 18s\n",
      "549:\tlearn: 0.7935886\ttest: 0.7938936\tbest: 0.7938936 (549)\ttotal: 10m 7s\tremaining: 8m 17s\n",
      "550:\tlearn: 0.7938583\ttest: 0.7941724\tbest: 0.7941724 (550)\ttotal: 10m 8s\tremaining: 8m 16s\n",
      "551:\tlearn: 0.7938838\ttest: 0.7942548\tbest: 0.7942548 (551)\ttotal: 10m 9s\tremaining: 8m 15s\n",
      "552:\tlearn: 0.7939443\ttest: 0.7943305\tbest: 0.7943305 (552)\ttotal: 10m 11s\tremaining: 8m 13s\n",
      "553:\tlearn: 0.7940261\ttest: 0.7944055\tbest: 0.7944055 (553)\ttotal: 10m 12s\tremaining: 8m 12s\n",
      "554:\tlearn: 0.7940669\ttest: 0.7944387\tbest: 0.7944387 (554)\ttotal: 10m 13s\tremaining: 8m 11s\n",
      "555:\tlearn: 0.7941549\ttest: 0.7945436\tbest: 0.7945436 (555)\ttotal: 10m 14s\tremaining: 8m 10s\n",
      "556:\tlearn: 0.7943050\ttest: 0.7946968\tbest: 0.7946968 (556)\ttotal: 10m 15s\tremaining: 8m 9s\n",
      "557:\tlearn: 0.7944342\ttest: 0.7947750\tbest: 0.7947750 (557)\ttotal: 10m 16s\tremaining: 8m 8s\n",
      "558:\tlearn: 0.7945094\ttest: 0.7948840\tbest: 0.7948840 (558)\ttotal: 10m 17s\tremaining: 8m 7s\n",
      "559:\tlearn: 0.7945621\ttest: 0.7949573\tbest: 0.7949573 (559)\ttotal: 10m 19s\tremaining: 8m 6s\n",
      "560:\tlearn: 0.7944911\ttest: 0.7948541\tbest: 0.7949573 (559)\ttotal: 10m 20s\tremaining: 8m 5s\n",
      "561:\tlearn: 0.7946251\ttest: 0.7949664\tbest: 0.7949664 (561)\ttotal: 10m 21s\tremaining: 8m 4s\n",
      "562:\tlearn: 0.7948396\ttest: 0.7952136\tbest: 0.7952136 (562)\ttotal: 10m 22s\tremaining: 8m 3s\n",
      "563:\tlearn: 0.7950135\ttest: 0.7953376\tbest: 0.7953376 (563)\ttotal: 10m 23s\tremaining: 8m 2s\n",
      "564:\tlearn: 0.7950665\ttest: 0.7953976\tbest: 0.7953976 (564)\ttotal: 10m 24s\tremaining: 8m\n",
      "565:\tlearn: 0.7951270\ttest: 0.7954775\tbest: 0.7954775 (565)\ttotal: 10m 25s\tremaining: 7m 59s\n",
      "566:\tlearn: 0.7952618\ttest: 0.7955890\tbest: 0.7955890 (566)\ttotal: 10m 26s\tremaining: 7m 58s\n",
      "567:\tlearn: 0.7953639\ttest: 0.7956889\tbest: 0.7956889 (567)\ttotal: 10m 28s\tremaining: 7m 57s\n",
      "568:\tlearn: 0.7953464\ttest: 0.7957138\tbest: 0.7957138 (568)\ttotal: 10m 29s\tremaining: 7m 56s\n",
      "569:\tlearn: 0.7953867\ttest: 0.7957579\tbest: 0.7957579 (569)\ttotal: 10m 30s\tremaining: 7m 55s\n",
      "570:\tlearn: 0.7954902\ttest: 0.7958237\tbest: 0.7958237 (570)\ttotal: 10m 31s\tremaining: 7m 54s\n",
      "571:\tlearn: 0.7956081\ttest: 0.7959610\tbest: 0.7959610 (571)\ttotal: 10m 32s\tremaining: 7m 53s\n",
      "572:\tlearn: 0.7956350\ttest: 0.7959810\tbest: 0.7959810 (572)\ttotal: 10m 33s\tremaining: 7m 52s\n",
      "573:\tlearn: 0.7956547\ttest: 0.7959960\tbest: 0.7959960 (573)\ttotal: 10m 34s\tremaining: 7m 51s\n",
      "574:\tlearn: 0.7958419\ttest: 0.7961699\tbest: 0.7961699 (574)\ttotal: 10m 35s\tremaining: 7m 50s\n",
      "575:\tlearn: 0.7961222\ttest: 0.7964729\tbest: 0.7964729 (575)\ttotal: 10m 37s\tremaining: 7m 49s\n",
      "576:\tlearn: 0.7961516\ttest: 0.7964804\tbest: 0.7964804 (576)\ttotal: 10m 38s\tremaining: 7m 47s\n",
      "577:\tlearn: 0.7961840\ttest: 0.7965644\tbest: 0.7965644 (577)\ttotal: 10m 39s\tremaining: 7m 46s\n",
      "578:\tlearn: 0.7963094\ttest: 0.7966543\tbest: 0.7966543 (578)\ttotal: 10m 40s\tremaining: 7m 45s\n",
      "579:\tlearn: 0.7963915\ttest: 0.7967867\tbest: 0.7967867 (579)\ttotal: 10m 41s\tremaining: 7m 44s\n",
      "580:\tlearn: 0.7964850\ttest: 0.7968757\tbest: 0.7968757 (580)\ttotal: 10m 42s\tremaining: 7m 43s\n",
      "581:\tlearn: 0.7965053\ttest: 0.7968591\tbest: 0.7968757 (580)\ttotal: 10m 43s\tremaining: 7m 42s\n",
      "582:\tlearn: 0.7965968\ttest: 0.7969423\tbest: 0.7969423 (582)\ttotal: 10m 44s\tremaining: 7m 41s\n",
      "583:\tlearn: 0.7968335\ttest: 0.7971662\tbest: 0.7971662 (583)\ttotal: 10m 46s\tremaining: 7m 40s\n",
      "584:\tlearn: 0.7969631\ttest: 0.7972952\tbest: 0.7972952 (584)\ttotal: 10m 47s\tremaining: 7m 39s\n",
      "585:\tlearn: 0.7969567\ttest: 0.7972677\tbest: 0.7972952 (584)\ttotal: 10m 48s\tremaining: 7m 38s\n",
      "586:\tlearn: 0.7971439\ttest: 0.7974550\tbest: 0.7974550 (586)\ttotal: 10m 49s\tremaining: 7m 37s\n",
      "587:\tlearn: 0.7971753\ttest: 0.7975266\tbest: 0.7975266 (587)\ttotal: 10m 50s\tremaining: 7m 35s\n",
      "588:\tlearn: 0.7972646\ttest: 0.7976514\tbest: 0.7976514 (588)\ttotal: 10m 51s\tremaining: 7m 34s\n",
      "589:\tlearn: 0.7972635\ttest: 0.7976473\tbest: 0.7976514 (588)\ttotal: 10m 53s\tremaining: 7m 33s\n",
      "590:\tlearn: 0.7974935\ttest: 0.7978354\tbest: 0.7978354 (590)\ttotal: 10m 54s\tremaining: 7m 32s\n",
      "591:\tlearn: 0.7976869\ttest: 0.7979477\tbest: 0.7979477 (591)\ttotal: 10m 55s\tremaining: 7m 31s\n",
      "592:\tlearn: 0.7976580\ttest: 0.7979544\tbest: 0.7979544 (592)\ttotal: 10m 56s\tremaining: 7m 30s\n",
      "593:\tlearn: 0.7979615\ttest: 0.7983306\tbest: 0.7983306 (593)\ttotal: 10m 57s\tremaining: 7m 29s\n",
      "594:\tlearn: 0.7982922\ttest: 0.7986468\tbest: 0.7986468 (594)\ttotal: 10m 58s\tremaining: 7m 28s\n",
      "595:\tlearn: 0.7985081\ttest: 0.7988125\tbest: 0.7988125 (595)\ttotal: 11m\tremaining: 7m 27s\n",
      "596:\tlearn: 0.7985702\ttest: 0.7988533\tbest: 0.7988533 (596)\ttotal: 11m 1s\tremaining: 7m 26s\n",
      "597:\tlearn: 0.7989411\ttest: 0.7992436\tbest: 0.7992436 (597)\ttotal: 11m 2s\tremaining: 7m 25s\n",
      "598:\tlearn: 0.7990108\ttest: 0.7993077\tbest: 0.7993077 (598)\ttotal: 11m 3s\tremaining: 7m 24s\n",
      "599:\tlearn: 0.7990358\ttest: 0.7993368\tbest: 0.7993368 (599)\ttotal: 11m 4s\tremaining: 7m 23s\n",
      "600:\tlearn: 0.7990962\ttest: 0.7994226\tbest: 0.7994226 (600)\ttotal: 11m 5s\tremaining: 7m 22s\n",
      "601:\tlearn: 0.7992849\ttest: 0.7995840\tbest: 0.7995840 (601)\ttotal: 11m 7s\tremaining: 7m 21s\n",
      "602:\tlearn: 0.7994025\ttest: 0.7996989\tbest: 0.7996989 (602)\ttotal: 11m 8s\tremaining: 7m 19s\n",
      "603:\tlearn: 0.7993995\ttest: 0.7996806\tbest: 0.7996989 (602)\ttotal: 11m 9s\tremaining: 7m 18s\n",
      "604:\tlearn: 0.7994411\ttest: 0.7997297\tbest: 0.7997297 (604)\ttotal: 11m 10s\tremaining: 7m 17s\n",
      "605:\tlearn: 0.7996406\ttest: 0.7999086\tbest: 0.7999086 (605)\ttotal: 11m 11s\tremaining: 7m 16s\n",
      "606:\tlearn: 0.7997277\ttest: 0.8000185\tbest: 0.8000185 (606)\ttotal: 11m 12s\tremaining: 7m 15s\n",
      "607:\tlearn: 0.7997884\ttest: 0.8000942\tbest: 0.8000942 (607)\ttotal: 11m 14s\tremaining: 7m 14s\n",
      "608:\tlearn: 0.7998181\ttest: 0.8000751\tbest: 0.8000942 (607)\ttotal: 11m 15s\tremaining: 7m 13s\n",
      "609:\tlearn: 0.8003106\ttest: 0.8005595\tbest: 0.8005595 (609)\ttotal: 11m 16s\tremaining: 7m 12s\n",
      "610:\tlearn: 0.8004582\ttest: 0.8007226\tbest: 0.8007226 (610)\ttotal: 11m 17s\tremaining: 7m 11s\n",
      "611:\tlearn: 0.8008252\ttest: 0.8010847\tbest: 0.8010847 (611)\ttotal: 11m 18s\tremaining: 7m 10s\n",
      "612:\tlearn: 0.8010369\ttest: 0.8012728\tbest: 0.8012728 (612)\ttotal: 11m 19s\tremaining: 7m 9s\n",
      "613:\tlearn: 0.8011687\ttest: 0.8013993\tbest: 0.8013993 (613)\ttotal: 11m 21s\tremaining: 7m 8s\n",
      "614:\tlearn: 0.8011739\ttest: 0.8014034\tbest: 0.8014034 (614)\ttotal: 11m 22s\tremaining: 7m 7s\n",
      "615:\tlearn: 0.8011417\ttest: 0.8013493\tbest: 0.8014034 (614)\ttotal: 11m 23s\tremaining: 7m 6s\n",
      "616:\tlearn: 0.8011770\ttest: 0.8013693\tbest: 0.8014034 (614)\ttotal: 11m 24s\tremaining: 7m 4s\n",
      "617:\tlearn: 0.8012971\ttest: 0.8014900\tbest: 0.8014900 (617)\ttotal: 11m 25s\tremaining: 7m 3s\n",
      "618:\tlearn: 0.8014544\ttest: 0.8016398\tbest: 0.8016398 (618)\ttotal: 11m 26s\tremaining: 7m 2s\n",
      "619:\tlearn: 0.8015904\ttest: 0.8017954\tbest: 0.8017954 (619)\ttotal: 11m 27s\tremaining: 7m 1s\n",
      "620:\tlearn: 0.8016755\ttest: 0.8018820\tbest: 0.8018820 (620)\ttotal: 11m 29s\tremaining: 7m\n",
      "621:\tlearn: 0.8017493\ttest: 0.8019719\tbest: 0.8019719 (621)\ttotal: 11m 30s\tremaining: 6m 59s\n",
      "622:\tlearn: 0.8017638\ttest: 0.8019819\tbest: 0.8019819 (622)\ttotal: 11m 31s\tremaining: 6m 58s\n",
      "623:\tlearn: 0.8018020\ttest: 0.8020476\tbest: 0.8020476 (623)\ttotal: 11m 32s\tremaining: 6m 57s\n",
      "624:\tlearn: 0.8018528\ttest: 0.8020934\tbest: 0.8020934 (624)\ttotal: 11m 33s\tremaining: 6m 56s\n",
      "625:\tlearn: 0.8019388\ttest: 0.8022091\tbest: 0.8022091 (625)\ttotal: 11m 34s\tremaining: 6m 54s\n",
      "626:\tlearn: 0.8019616\ttest: 0.8022024\tbest: 0.8022091 (625)\ttotal: 11m 35s\tremaining: 6m 53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627:\tlearn: 0.8020581\ttest: 0.8023090\tbest: 0.8023090 (627)\ttotal: 11m 36s\tremaining: 6m 52s\n",
      "628:\tlearn: 0.8022934\ttest: 0.8024837\tbest: 0.8024837 (628)\ttotal: 11m 38s\tremaining: 6m 51s\n",
      "629:\tlearn: 0.8023361\ttest: 0.8025353\tbest: 0.8025353 (629)\ttotal: 11m 39s\tremaining: 6m 50s\n",
      "630:\tlearn: 0.8023802\ttest: 0.8025944\tbest: 0.8025944 (630)\ttotal: 11m 40s\tremaining: 6m 49s\n",
      "631:\tlearn: 0.8024057\ttest: 0.8026411\tbest: 0.8026411 (631)\ttotal: 11m 41s\tremaining: 6m 48s\n",
      "632:\tlearn: 0.8023966\ttest: 0.8026560\tbest: 0.8026560 (632)\ttotal: 11m 42s\tremaining: 6m 47s\n",
      "633:\tlearn: 0.8025286\ttest: 0.8027584\tbest: 0.8027584 (633)\ttotal: 11m 43s\tremaining: 6m 46s\n",
      "634:\tlearn: 0.8025447\ttest: 0.8027967\tbest: 0.8027967 (634)\ttotal: 11m 44s\tremaining: 6m 45s\n",
      "635:\tlearn: 0.8027056\ttest: 0.8029473\tbest: 0.8029473 (635)\ttotal: 11m 46s\tremaining: 6m 44s\n",
      "636:\tlearn: 0.8027991\ttest: 0.8029998\tbest: 0.8029998 (636)\ttotal: 11m 47s\tremaining: 6m 43s\n",
      "637:\tlearn: 0.8028973\ttest: 0.8030947\tbest: 0.8030947 (637)\ttotal: 11m 48s\tremaining: 6m 41s\n",
      "638:\tlearn: 0.8029845\ttest: 0.8031771\tbest: 0.8031771 (638)\ttotal: 11m 49s\tremaining: 6m 40s\n",
      "639:\tlearn: 0.8030300\ttest: 0.8032520\tbest: 0.8032520 (639)\ttotal: 11m 50s\tremaining: 6m 39s\n",
      "640:\tlearn: 0.8031676\ttest: 0.8033502\tbest: 0.8033502 (640)\ttotal: 11m 51s\tremaining: 6m 38s\n",
      "641:\tlearn: 0.8031975\ttest: 0.8034267\tbest: 0.8034267 (641)\ttotal: 11m 53s\tremaining: 6m 37s\n",
      "642:\tlearn: 0.8035418\ttest: 0.8037305\tbest: 0.8037305 (642)\ttotal: 11m 54s\tremaining: 6m 36s\n",
      "643:\tlearn: 0.8035890\ttest: 0.8038004\tbest: 0.8038004 (643)\ttotal: 11m 55s\tremaining: 6m 35s\n",
      "644:\tlearn: 0.8036284\ttest: 0.8038637\tbest: 0.8038637 (644)\ttotal: 11m 56s\tremaining: 6m 34s\n",
      "645:\tlearn: 0.8037879\ttest: 0.8040077\tbest: 0.8040077 (645)\ttotal: 11m 57s\tremaining: 6m 33s\n",
      "646:\tlearn: 0.8037174\ttest: 0.8040210\tbest: 0.8040210 (646)\ttotal: 11m 58s\tremaining: 6m 32s\n",
      "647:\tlearn: 0.8039319\ttest: 0.8041933\tbest: 0.8041933 (647)\ttotal: 11m 59s\tremaining: 6m 31s\n",
      "648:\tlearn: 0.8041899\ttest: 0.8044496\tbest: 0.8044496 (648)\ttotal: 12m 1s\tremaining: 6m 30s\n",
      "649:\tlearn: 0.8042770\ttest: 0.8045229\tbest: 0.8045229 (649)\ttotal: 12m 2s\tremaining: 6m 28s\n",
      "650:\tlearn: 0.8044820\ttest: 0.8047310\tbest: 0.8047310 (650)\ttotal: 12m 3s\tremaining: 6m 27s\n",
      "651:\tlearn: 0.8045170\ttest: 0.8047734\tbest: 0.8047734 (651)\ttotal: 12m 4s\tremaining: 6m 26s\n",
      "652:\tlearn: 0.8045886\ttest: 0.8048292\tbest: 0.8048292 (652)\ttotal: 12m 5s\tremaining: 6m 25s\n",
      "653:\tlearn: 0.8046049\ttest: 0.8048516\tbest: 0.8048516 (653)\ttotal: 12m 6s\tremaining: 6m 24s\n",
      "654:\tlearn: 0.8046837\ttest: 0.8049099\tbest: 0.8049099 (654)\ttotal: 12m 8s\tremaining: 6m 23s\n",
      "655:\tlearn: 0.8047814\ttest: 0.8049965\tbest: 0.8049965 (655)\ttotal: 12m 9s\tremaining: 6m 22s\n",
      "656:\tlearn: 0.8048827\ttest: 0.8050905\tbest: 0.8050905 (656)\ttotal: 12m 10s\tremaining: 6m 21s\n",
      "657:\tlearn: 0.8049232\ttest: 0.8051013\tbest: 0.8051013 (657)\ttotal: 12m 11s\tremaining: 6m 20s\n",
      "658:\tlearn: 0.8050982\ttest: 0.8053119\tbest: 0.8053119 (658)\ttotal: 12m 12s\tremaining: 6m 19s\n",
      "659:\tlearn: 0.8052921\ttest: 0.8054625\tbest: 0.8054625 (659)\ttotal: 12m 13s\tremaining: 6m 18s\n",
      "660:\tlearn: 0.8053693\ttest: 0.8055408\tbest: 0.8055408 (660)\ttotal: 12m 15s\tremaining: 6m 16s\n",
      "661:\tlearn: 0.8054386\ttest: 0.8055990\tbest: 0.8055990 (661)\ttotal: 12m 16s\tremaining: 6m 15s\n",
      "662:\tlearn: 0.8055663\ttest: 0.8056864\tbest: 0.8056864 (662)\ttotal: 12m 17s\tremaining: 6m 14s\n",
      "663:\tlearn: 0.8056151\ttest: 0.8057846\tbest: 0.8057846 (663)\ttotal: 12m 18s\tremaining: 6m 13s\n",
      "664:\tlearn: 0.8058182\ttest: 0.8059644\tbest: 0.8059644 (664)\ttotal: 12m 19s\tremaining: 6m 12s\n",
      "665:\tlearn: 0.8059375\ttest: 0.8061092\tbest: 0.8061092 (665)\ttotal: 12m 20s\tremaining: 6m 11s\n",
      "666:\tlearn: 0.8061056\ttest: 0.8062641\tbest: 0.8062641 (666)\ttotal: 12m 21s\tremaining: 6m 10s\n",
      "667:\tlearn: 0.8061486\ttest: 0.8063231\tbest: 0.8063231 (667)\ttotal: 12m 23s\tremaining: 6m 9s\n",
      "668:\tlearn: 0.8061500\ttest: 0.8063265\tbest: 0.8063265 (668)\ttotal: 12m 24s\tremaining: 6m 8s\n",
      "669:\tlearn: 0.8063178\ttest: 0.8064879\tbest: 0.8064879 (669)\ttotal: 12m 25s\tremaining: 6m 7s\n",
      "670:\tlearn: 0.8066460\ttest: 0.8067842\tbest: 0.8067842 (670)\ttotal: 12m 26s\tremaining: 6m 6s\n",
      "671:\tlearn: 0.8065645\ttest: 0.8066910\tbest: 0.8067842 (670)\ttotal: 12m 27s\tremaining: 6m 4s\n",
      "672:\tlearn: 0.8065936\ttest: 0.8067110\tbest: 0.8067842 (670)\ttotal: 12m 28s\tremaining: 6m 3s\n",
      "673:\tlearn: 0.8067440\ttest: 0.8068941\tbest: 0.8068941 (673)\ttotal: 12m 30s\tremaining: 6m 2s\n",
      "674:\tlearn: 0.8067126\ttest: 0.8068492\tbest: 0.8068941 (673)\ttotal: 12m 31s\tremaining: 6m 1s\n",
      "675:\tlearn: 0.8068394\ttest: 0.8069607\tbest: 0.8069607 (675)\ttotal: 12m 32s\tremaining: 6m\n",
      "676:\tlearn: 0.8069601\ttest: 0.8071072\tbest: 0.8071072 (676)\ttotal: 12m 33s\tremaining: 5m 59s\n",
      "677:\tlearn: 0.8069601\ttest: 0.8070963\tbest: 0.8071072 (676)\ttotal: 12m 34s\tremaining: 5m 58s\n",
      "678:\tlearn: 0.8069648\ttest: 0.8070930\tbest: 0.8071072 (676)\ttotal: 12m 35s\tremaining: 5m 57s\n",
      "679:\tlearn: 0.8070588\ttest: 0.8072062\tbest: 0.8072062 (679)\ttotal: 12m 36s\tremaining: 5m 56s\n",
      "680:\tlearn: 0.8077028\ttest: 0.8077905\tbest: 0.8077905 (680)\ttotal: 12m 38s\tremaining: 5m 55s\n",
      "681:\tlearn: 0.8079783\ttest: 0.8080377\tbest: 0.8080377 (681)\ttotal: 12m 39s\tremaining: 5m 54s\n",
      "682:\tlearn: 0.8081286\ttest: 0.8082915\tbest: 0.8082915 (682)\ttotal: 12m 40s\tremaining: 5m 52s\n",
      "683:\tlearn: 0.8081414\ttest: 0.8083265\tbest: 0.8083265 (683)\ttotal: 12m 41s\tremaining: 5m 51s\n",
      "684:\tlearn: 0.8081855\ttest: 0.8083872\tbest: 0.8083872 (684)\ttotal: 12m 42s\tremaining: 5m 50s\n",
      "685:\tlearn: 0.8086727\ttest: 0.8087901\tbest: 0.8087901 (685)\ttotal: 12m 43s\tremaining: 5m 49s\n",
      "686:\tlearn: 0.8089323\ttest: 0.8090714\tbest: 0.8090714 (686)\ttotal: 12m 45s\tremaining: 5m 48s\n",
      "687:\tlearn: 0.8090270\ttest: 0.8091921\tbest: 0.8091921 (687)\ttotal: 12m 46s\tremaining: 5m 47s\n",
      "688:\tlearn: 0.8090835\ttest: 0.8092262\tbest: 0.8092262 (688)\ttotal: 12m 47s\tremaining: 5m 46s\n",
      "689:\tlearn: 0.8092683\ttest: 0.8094260\tbest: 0.8094260 (689)\ttotal: 12m 48s\tremaining: 5m 45s\n",
      "690:\tlearn: 0.8094398\ttest: 0.8095799\tbest: 0.8095799 (690)\ttotal: 12m 49s\tremaining: 5m 44s\n",
      "691:\tlearn: 0.8095000\ttest: 0.8096340\tbest: 0.8096340 (691)\ttotal: 12m 50s\tremaining: 5m 43s\n",
      "692:\tlearn: 0.8095527\ttest: 0.8096998\tbest: 0.8096998 (692)\ttotal: 12m 52s\tremaining: 5m 42s\n",
      "693:\tlearn: 0.8096146\ttest: 0.8097397\tbest: 0.8097397 (693)\ttotal: 12m 53s\tremaining: 5m 40s\n",
      "694:\tlearn: 0.8097228\ttest: 0.8098146\tbest: 0.8098146 (694)\ttotal: 12m 54s\tremaining: 5m 39s\n",
      "695:\tlearn: 0.8098962\ttest: 0.8100169\tbest: 0.8100169 (695)\ttotal: 12m 55s\tremaining: 5m 38s\n",
      "696:\tlearn: 0.8101497\ttest: 0.8103099\tbest: 0.8103099 (696)\ttotal: 12m 56s\tremaining: 5m 37s\n",
      "697:\tlearn: 0.8101913\ttest: 0.8103423\tbest: 0.8103423 (697)\ttotal: 12m 57s\tremaining: 5m 36s\n",
      "698:\tlearn: 0.8102196\ttest: 0.8103914\tbest: 0.8103914 (698)\ttotal: 12m 58s\tremaining: 5m 35s\n",
      "699:\tlearn: 0.8103439\ttest: 0.8104722\tbest: 0.8104722 (699)\ttotal: 13m\tremaining: 5m 34s\n",
      "700:\tlearn: 0.8105440\ttest: 0.8106586\tbest: 0.8106586 (700)\ttotal: 13m 1s\tremaining: 5m 33s\n",
      "701:\tlearn: 0.8106513\ttest: 0.8107568\tbest: 0.8107568 (701)\ttotal: 13m 2s\tremaining: 5m 32s\n",
      "702:\tlearn: 0.8107040\ttest: 0.8107968\tbest: 0.8107968 (702)\ttotal: 13m 3s\tremaining: 5m 31s\n",
      "703:\tlearn: 0.8108444\ttest: 0.8109183\tbest: 0.8109183 (703)\ttotal: 13m 4s\tremaining: 5m 29s\n",
      "704:\tlearn: 0.8108738\ttest: 0.8109482\tbest: 0.8109482 (704)\ttotal: 13m 5s\tremaining: 5m 28s\n",
      "705:\tlearn: 0.8109412\ttest: 0.8109757\tbest: 0.8109757 (705)\ttotal: 13m 7s\tremaining: 5m 27s\n",
      "706:\tlearn: 0.8110766\ttest: 0.8111405\tbest: 0.8111405 (706)\ttotal: 13m 8s\tremaining: 5m 26s\n",
      "707:\tlearn: 0.8110830\ttest: 0.8111938\tbest: 0.8111938 (707)\ttotal: 13m 9s\tremaining: 5m 25s\n",
      "708:\tlearn: 0.8113857\ttest: 0.8114967\tbest: 0.8114967 (708)\ttotal: 13m 10s\tremaining: 5m 24s\n",
      "709:\tlearn: 0.8115030\ttest: 0.8116291\tbest: 0.8116291 (709)\ttotal: 13m 11s\tremaining: 5m 23s\n",
      "710:\tlearn: 0.8115724\ttest: 0.8116790\tbest: 0.8116790 (710)\ttotal: 13m 12s\tremaining: 5m 22s\n",
      "711:\tlearn: 0.8117020\ttest: 0.8118097\tbest: 0.8118097 (711)\ttotal: 13m 14s\tremaining: 5m 21s\n",
      "712:\tlearn: 0.8117230\ttest: 0.8118346\tbest: 0.8118346 (712)\ttotal: 13m 15s\tremaining: 5m 20s\n",
      "713:\tlearn: 0.8117691\ttest: 0.8118346\tbest: 0.8118346 (712)\ttotal: 13m 16s\tremaining: 5m 18s\n",
      "714:\tlearn: 0.8119381\ttest: 0.8119969\tbest: 0.8119969 (714)\ttotal: 13m 17s\tremaining: 5m 17s\n",
      "715:\tlearn: 0.8120035\ttest: 0.8120610\tbest: 0.8120610 (715)\ttotal: 13m 18s\tremaining: 5m 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716:\tlearn: 0.8123603\ttest: 0.8124023\tbest: 0.8124023 (716)\ttotal: 13m 19s\tremaining: 5m 15s\n",
      "717:\tlearn: 0.8123770\ttest: 0.8123806\tbest: 0.8124023 (716)\ttotal: 13m 21s\tremaining: 5m 14s\n",
      "718:\tlearn: 0.8125110\ttest: 0.8125820\tbest: 0.8125820 (718)\ttotal: 13m 22s\tremaining: 5m 13s\n",
      "719:\tlearn: 0.8126128\ttest: 0.8127110\tbest: 0.8127110 (719)\ttotal: 13m 23s\tremaining: 5m 12s\n",
      "720:\tlearn: 0.8126269\ttest: 0.8127219\tbest: 0.8127219 (720)\ttotal: 13m 24s\tremaining: 5m 11s\n",
      "721:\tlearn: 0.8130764\ttest: 0.8131480\tbest: 0.8131480 (721)\ttotal: 13m 25s\tremaining: 5m 10s\n",
      "722:\tlearn: 0.8131785\ttest: 0.8132262\tbest: 0.8132262 (722)\ttotal: 13m 26s\tremaining: 5m 9s\n",
      "723:\tlearn: 0.8131543\ttest: 0.8132088\tbest: 0.8132262 (722)\ttotal: 13m 28s\tremaining: 5m 8s\n",
      "724:\tlearn: 0.8132858\ttest: 0.8133519\tbest: 0.8133519 (724)\ttotal: 13m 29s\tremaining: 5m 6s\n",
      "725:\tlearn: 0.8134700\ttest: 0.8135334\tbest: 0.8135334 (725)\ttotal: 13m 30s\tremaining: 5m 5s\n",
      "726:\tlearn: 0.8136196\ttest: 0.8136665\tbest: 0.8136665 (726)\ttotal: 13m 31s\tremaining: 5m 4s\n",
      "727:\tlearn: 0.8136973\ttest: 0.8137289\tbest: 0.8137289 (727)\ttotal: 13m 32s\tremaining: 5m 3s\n",
      "728:\tlearn: 0.8136662\ttest: 0.8137522\tbest: 0.8137522 (728)\ttotal: 13m 33s\tremaining: 5m 2s\n",
      "729:\tlearn: 0.8138041\ttest: 0.8139229\tbest: 0.8139229 (729)\ttotal: 13m 35s\tremaining: 5m 1s\n",
      "730:\tlearn: 0.8139098\ttest: 0.8139770\tbest: 0.8139770 (730)\ttotal: 13m 36s\tremaining: 5m\n",
      "731:\tlearn: 0.8140957\ttest: 0.8141434\tbest: 0.8141434 (731)\ttotal: 13m 37s\tremaining: 4m 59s\n",
      "732:\tlearn: 0.8141400\ttest: 0.8142167\tbest: 0.8142167 (732)\ttotal: 13m 38s\tremaining: 4m 58s\n",
      "733:\tlearn: 0.8142000\ttest: 0.8143165\tbest: 0.8143165 (733)\ttotal: 13m 39s\tremaining: 4m 57s\n",
      "734:\tlearn: 0.8145462\ttest: 0.8147677\tbest: 0.8147677 (734)\ttotal: 13m 40s\tremaining: 4m 55s\n",
      "735:\tlearn: 0.8147781\ttest: 0.8149799\tbest: 0.8149799 (735)\ttotal: 13m 42s\tremaining: 4m 54s\n",
      "736:\tlearn: 0.8147892\ttest: 0.8149849\tbest: 0.8149849 (736)\ttotal: 13m 43s\tremaining: 4m 53s\n",
      "737:\tlearn: 0.8147526\ttest: 0.8149674\tbest: 0.8149849 (736)\ttotal: 13m 44s\tremaining: 4m 52s\n",
      "738:\tlearn: 0.8149851\ttest: 0.8152129\tbest: 0.8152129 (738)\ttotal: 13m 45s\tremaining: 4m 51s\n",
      "739:\tlearn: 0.8149787\ttest: 0.8151680\tbest: 0.8152129 (738)\ttotal: 13m 46s\tremaining: 4m 50s\n",
      "740:\tlearn: 0.8150439\ttest: 0.8152304\tbest: 0.8152304 (740)\ttotal: 13m 47s\tremaining: 4m 49s\n",
      "741:\tlearn: 0.8151543\ttest: 0.8153553\tbest: 0.8153553 (741)\ttotal: 13m 48s\tremaining: 4m 48s\n",
      "742:\tlearn: 0.8152390\ttest: 0.8154426\tbest: 0.8154426 (742)\ttotal: 13m 50s\tremaining: 4m 47s\n",
      "743:\tlearn: 0.8152964\ttest: 0.8154876\tbest: 0.8154876 (743)\ttotal: 13m 51s\tremaining: 4m 46s\n",
      "744:\tlearn: 0.8153011\ttest: 0.8154868\tbest: 0.8154876 (743)\ttotal: 13m 52s\tremaining: 4m 44s\n",
      "745:\tlearn: 0.8153574\ttest: 0.8155525\tbest: 0.8155525 (745)\ttotal: 13m 53s\tremaining: 4m 43s\n",
      "746:\tlearn: 0.8154079\ttest: 0.8156024\tbest: 0.8156024 (746)\ttotal: 13m 54s\tremaining: 4m 42s\n",
      "747:\tlearn: 0.8156390\ttest: 0.8157864\tbest: 0.8157864 (747)\ttotal: 13m 55s\tremaining: 4m 41s\n",
      "748:\tlearn: 0.8156740\ttest: 0.8158080\tbest: 0.8158080 (748)\ttotal: 13m 56s\tremaining: 4m 40s\n",
      "749:\tlearn: 0.8157744\ttest: 0.8159154\tbest: 0.8159154 (749)\ttotal: 13m 58s\tremaining: 4m 39s\n",
      "750:\tlearn: 0.8158180\ttest: 0.8159895\tbest: 0.8159895 (750)\ttotal: 13m 59s\tremaining: 4m 38s\n",
      "751:\tlearn: 0.8158357\ttest: 0.8160094\tbest: 0.8160094 (751)\ttotal: 14m\tremaining: 4m 37s\n",
      "752:\tlearn: 0.8159325\ttest: 0.8160960\tbest: 0.8160960 (752)\ttotal: 14m 1s\tremaining: 4m 36s\n",
      "753:\tlearn: 0.8159850\ttest: 0.8161784\tbest: 0.8161784 (753)\ttotal: 14m 2s\tremaining: 4m 34s\n",
      "754:\tlearn: 0.8162671\ttest: 0.8163856\tbest: 0.8163856 (754)\ttotal: 14m 3s\tremaining: 4m 33s\n",
      "755:\tlearn: 0.8164444\ttest: 0.8165962\tbest: 0.8165962 (755)\ttotal: 14m 5s\tremaining: 4m 32s\n",
      "756:\tlearn: 0.8166098\ttest: 0.8167252\tbest: 0.8167252 (756)\ttotal: 14m 6s\tremaining: 4m 31s\n",
      "757:\tlearn: 0.8165975\ttest: 0.8167369\tbest: 0.8167369 (757)\ttotal: 14m 7s\tremaining: 4m 30s\n",
      "758:\tlearn: 0.8167213\ttest: 0.8168343\tbest: 0.8168343 (758)\ttotal: 14m 8s\tremaining: 4m 29s\n",
      "759:\tlearn: 0.8168256\ttest: 0.8169924\tbest: 0.8169924 (759)\ttotal: 14m 9s\tremaining: 4m 28s\n",
      "760:\tlearn: 0.8169277\ttest: 0.8170590\tbest: 0.8170590 (760)\ttotal: 14m 10s\tremaining: 4m 27s\n",
      "761:\tlearn: 0.8170878\ttest: 0.8172904\tbest: 0.8172904 (761)\ttotal: 14m 12s\tremaining: 4m 26s\n",
      "762:\tlearn: 0.8171990\ttest: 0.8173844\tbest: 0.8173844 (762)\ttotal: 14m 13s\tremaining: 4m 25s\n",
      "763:\tlearn: 0.8172806\ttest: 0.8175059\tbest: 0.8175059 (763)\ttotal: 14m 14s\tremaining: 4m 23s\n",
      "764:\tlearn: 0.8173006\ttest: 0.8175334\tbest: 0.8175334 (764)\ttotal: 14m 15s\tremaining: 4m 22s\n",
      "765:\tlearn: 0.8173247\ttest: 0.8175525\tbest: 0.8175525 (765)\ttotal: 14m 16s\tremaining: 4m 21s\n",
      "766:\tlearn: 0.8173616\ttest: 0.8176041\tbest: 0.8176041 (766)\ttotal: 14m 17s\tremaining: 4m 20s\n",
      "767:\tlearn: 0.8177112\ttest: 0.8179021\tbest: 0.8179021 (767)\ttotal: 14m 18s\tremaining: 4m 19s\n",
      "768:\tlearn: 0.8177139\ttest: 0.8179029\tbest: 0.8179029 (768)\ttotal: 14m 20s\tremaining: 4m 18s\n",
      "769:\tlearn: 0.8179056\ttest: 0.8180935\tbest: 0.8180935 (769)\ttotal: 14m 21s\tremaining: 4m 17s\n",
      "770:\tlearn: 0.8179314\ttest: 0.8181351\tbest: 0.8181351 (770)\ttotal: 14m 22s\tremaining: 4m 16s\n",
      "771:\tlearn: 0.8180233\ttest: 0.8182059\tbest: 0.8182059 (771)\ttotal: 14m 23s\tremaining: 4m 15s\n",
      "772:\tlearn: 0.8180788\ttest: 0.8182600\tbest: 0.8182600 (772)\ttotal: 14m 24s\tremaining: 4m 13s\n",
      "773:\tlearn: 0.8180957\ttest: 0.8182758\tbest: 0.8182758 (773)\ttotal: 14m 25s\tremaining: 4m 12s\n",
      "774:\tlearn: 0.8181639\ttest: 0.8183457\tbest: 0.8183457 (774)\ttotal: 14m 27s\tremaining: 4m 11s\n",
      "775:\tlearn: 0.8183429\ttest: 0.8185147\tbest: 0.8185147 (775)\ttotal: 14m 28s\tremaining: 4m 10s\n",
      "776:\tlearn: 0.8183659\ttest: 0.8185380\tbest: 0.8185380 (776)\ttotal: 14m 29s\tremaining: 4m 9s\n",
      "777:\tlearn: 0.8184075\ttest: 0.8185505\tbest: 0.8185505 (777)\ttotal: 14m 30s\tremaining: 4m 8s\n",
      "778:\tlearn: 0.8184636\ttest: 0.8186370\tbest: 0.8186370 (778)\ttotal: 14m 31s\tremaining: 4m 7s\n",
      "779:\tlearn: 0.8184738\ttest: 0.8186670\tbest: 0.8186670 (779)\ttotal: 14m 32s\tremaining: 4m 6s\n",
      "780:\tlearn: 0.8185754\ttest: 0.8187494\tbest: 0.8187494 (780)\ttotal: 14m 33s\tremaining: 4m 5s\n",
      "781:\tlearn: 0.8186708\ttest: 0.8188434\tbest: 0.8188434 (781)\ttotal: 14m 35s\tremaining: 4m 3s\n",
      "782:\tlearn: 0.8187549\ttest: 0.8189325\tbest: 0.8189325 (782)\ttotal: 14m 36s\tremaining: 4m 2s\n",
      "783:\tlearn: 0.8189244\ttest: 0.8191156\tbest: 0.8191156 (783)\ttotal: 14m 37s\tremaining: 4m 1s\n",
      "784:\tlearn: 0.8191996\ttest: 0.8194110\tbest: 0.8194110 (784)\ttotal: 14m 38s\tremaining: 4m\n",
      "785:\tlearn: 0.8192995\ttest: 0.8194851\tbest: 0.8194851 (785)\ttotal: 14m 39s\tremaining: 3m 59s\n",
      "786:\tlearn: 0.8193938\ttest: 0.8196016\tbest: 0.8196016 (786)\ttotal: 14m 40s\tremaining: 3m 58s\n",
      "787:\tlearn: 0.8195758\ttest: 0.8197781\tbest: 0.8197781 (787)\ttotal: 14m 42s\tremaining: 3m 57s\n",
      "788:\tlearn: 0.8197672\ttest: 0.8199712\tbest: 0.8199712 (788)\ttotal: 14m 43s\tremaining: 3m 56s\n",
      "789:\tlearn: 0.8198946\ttest: 0.8201293\tbest: 0.8201293 (789)\ttotal: 14m 44s\tremaining: 3m 55s\n",
      "790:\tlearn: 0.8198907\ttest: 0.8200869\tbest: 0.8201293 (789)\ttotal: 14m 45s\tremaining: 3m 53s\n",
      "791:\tlearn: 0.8199875\ttest: 0.8202209\tbest: 0.8202209 (791)\ttotal: 14m 46s\tremaining: 3m 52s\n",
      "792:\tlearn: 0.8200763\ttest: 0.8202733\tbest: 0.8202733 (792)\ttotal: 14m 47s\tremaining: 3m 51s\n",
      "793:\tlearn: 0.8200865\ttest: 0.8202883\tbest: 0.8202883 (793)\ttotal: 14m 49s\tremaining: 3m 50s\n",
      "794:\tlearn: 0.8203290\ttest: 0.8205405\tbest: 0.8205405 (794)\ttotal: 14m 50s\tremaining: 3m 49s\n",
      "795:\tlearn: 0.8207660\ttest: 0.8209791\tbest: 0.8209791 (795)\ttotal: 14m 51s\tremaining: 3m 48s\n",
      "796:\tlearn: 0.8207740\ttest: 0.8209799\tbest: 0.8209799 (796)\ttotal: 14m 52s\tremaining: 3m 47s\n",
      "797:\tlearn: 0.8207926\ttest: 0.8209999\tbest: 0.8209999 (797)\ttotal: 14m 53s\tremaining: 3m 46s\n",
      "798:\tlearn: 0.8209477\ttest: 0.8211331\tbest: 0.8211331 (798)\ttotal: 14m 54s\tremaining: 3m 45s\n",
      "799:\tlearn: 0.8210750\ttest: 0.8213020\tbest: 0.8213020 (799)\ttotal: 14m 55s\tremaining: 3m 43s\n",
      "800:\tlearn: 0.8211394\ttest: 0.8213436\tbest: 0.8213436 (800)\ttotal: 14m 57s\tremaining: 3m 42s\n",
      "801:\tlearn: 0.8215667\ttest: 0.8217515\tbest: 0.8217515 (801)\ttotal: 14m 57s\tremaining: 3m 41s\n",
      "802:\tlearn: 0.8217068\ttest: 0.8218921\tbest: 0.8218921 (802)\ttotal: 14m 58s\tremaining: 3m 40s\n",
      "803:\tlearn: 0.8217803\ttest: 0.8219687\tbest: 0.8219687 (803)\ttotal: 14m 58s\tremaining: 3m 39s\n",
      "804:\tlearn: 0.8218568\ttest: 0.8220186\tbest: 0.8220186 (804)\ttotal: 14m 58s\tremaining: 3m 37s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "805:\tlearn: 0.8221701\ttest: 0.8222866\tbest: 0.8222866 (805)\ttotal: 14m 59s\tremaining: 3m 36s\n",
      "806:\tlearn: 0.8221620\ttest: 0.8222767\tbest: 0.8222866 (805)\ttotal: 14m 59s\tremaining: 3m 35s\n",
      "807:\tlearn: 0.8224273\ttest: 0.8224980\tbest: 0.8224980 (807)\ttotal: 15m\tremaining: 3m 33s\n",
      "808:\tlearn: 0.8225646\ttest: 0.8226670\tbest: 0.8226670 (808)\ttotal: 15m\tremaining: 3m 32s\n",
      "809:\tlearn: 0.8227563\ttest: 0.8228068\tbest: 0.8228068 (809)\ttotal: 15m 1s\tremaining: 3m 31s\n",
      "810:\tlearn: 0.8227657\ttest: 0.8228102\tbest: 0.8228102 (810)\ttotal: 15m 3s\tremaining: 3m 30s\n",
      "811:\tlearn: 0.8228465\ttest: 0.8228709\tbest: 0.8228709 (811)\ttotal: 15m 4s\tremaining: 3m 29s\n",
      "812:\tlearn: 0.8229111\ttest: 0.8229333\tbest: 0.8229333 (812)\ttotal: 15m 4s\tremaining: 3m 28s\n",
      "813:\tlearn: 0.8230237\ttest: 0.8230041\tbest: 0.8230041 (813)\ttotal: 15m 6s\tremaining: 3m 27s\n",
      "814:\tlearn: 0.8230559\ttest: 0.8230532\tbest: 0.8230532 (814)\ttotal: 15m 6s\tremaining: 3m 25s\n",
      "815:\tlearn: 0.8231713\ttest: 0.8231739\tbest: 0.8231739 (815)\ttotal: 15m 7s\tremaining: 3m 24s\n",
      "816:\tlearn: 0.8232282\ttest: 0.8232396\tbest: 0.8232396 (816)\ttotal: 15m 7s\tremaining: 3m 23s\n",
      "817:\tlearn: 0.8233603\ttest: 0.8233395\tbest: 0.8233395 (817)\ttotal: 15m 8s\tremaining: 3m 22s\n",
      "818:\tlearn: 0.8234549\ttest: 0.8234460\tbest: 0.8234460 (818)\ttotal: 15m 8s\tremaining: 3m 20s\n",
      "819:\tlearn: 0.8235534\ttest: 0.8235276\tbest: 0.8235276 (819)\ttotal: 15m 9s\tremaining: 3m 19s\n",
      "820:\tlearn: 0.8235922\ttest: 0.8235767\tbest: 0.8235767 (820)\ttotal: 15m 9s\tremaining: 3m 18s\n",
      "821:\tlearn: 0.8237612\ttest: 0.8237357\tbest: 0.8237357 (821)\ttotal: 15m 10s\tremaining: 3m 17s\n",
      "822:\tlearn: 0.8239984\ttest: 0.8240486\tbest: 0.8240486 (822)\ttotal: 15m 11s\tremaining: 3m 16s\n",
      "823:\tlearn: 0.8241867\ttest: 0.8242284\tbest: 0.8242284 (823)\ttotal: 15m 12s\tremaining: 3m 14s\n",
      "824:\tlearn: 0.8241834\ttest: 0.8242151\tbest: 0.8242284 (823)\ttotal: 15m 13s\tremaining: 3m 13s\n",
      "825:\tlearn: 0.8242677\ttest: 0.8242908\tbest: 0.8242908 (825)\ttotal: 15m 15s\tremaining: 3m 12s\n",
      "826:\tlearn: 0.8245887\ttest: 0.8246104\tbest: 0.8246104 (826)\ttotal: 15m 16s\tremaining: 3m 11s\n",
      "827:\tlearn: 0.8246573\ttest: 0.8247061\tbest: 0.8247061 (827)\ttotal: 15m 17s\tremaining: 3m 10s\n",
      "828:\tlearn: 0.8248712\ttest: 0.8248701\tbest: 0.8248701 (828)\ttotal: 15m 18s\tremaining: 3m 9s\n",
      "829:\tlearn: 0.8248836\ttest: 0.8248917\tbest: 0.8248917 (829)\ttotal: 15m 19s\tremaining: 3m 8s\n",
      "830:\tlearn: 0.8249053\ttest: 0.8249100\tbest: 0.8249100 (830)\ttotal: 15m 21s\tremaining: 3m 7s\n",
      "831:\tlearn: 0.8249438\ttest: 0.8249458\tbest: 0.8249458 (831)\ttotal: 15m 22s\tremaining: 3m 6s\n",
      "832:\tlearn: 0.8249902\ttest: 0.8250424\tbest: 0.8250424 (832)\ttotal: 15m 23s\tremaining: 3m 5s\n",
      "833:\tlearn: 0.8250110\ttest: 0.8250532\tbest: 0.8250532 (833)\ttotal: 15m 23s\tremaining: 3m 3s\n",
      "834:\tlearn: 0.8250787\ttest: 0.8251223\tbest: 0.8251223 (834)\ttotal: 15m 24s\tremaining: 3m 2s\n",
      "835:\tlearn: 0.8251048\ttest: 0.8251581\tbest: 0.8251581 (835)\ttotal: 15m 24s\tremaining: 3m 1s\n",
      "836:\tlearn: 0.8253198\ttest: 0.8253828\tbest: 0.8253828 (836)\ttotal: 15m 25s\tremaining: 3m\n",
      "837:\tlearn: 0.8253406\ttest: 0.8254003\tbest: 0.8254003 (837)\ttotal: 15m 25s\tremaining: 2m 58s\n",
      "838:\tlearn: 0.8253098\ttest: 0.8253545\tbest: 0.8254003 (837)\ttotal: 15m 27s\tremaining: 2m 57s\n",
      "839:\tlearn: 0.8253461\ttest: 0.8253953\tbest: 0.8254003 (837)\ttotal: 15m 28s\tremaining: 2m 56s\n",
      "840:\tlearn: 0.8254918\ttest: 0.8255334\tbest: 0.8255334 (840)\ttotal: 15m 29s\tremaining: 2m 55s\n",
      "841:\tlearn: 0.8255334\ttest: 0.8255642\tbest: 0.8255642 (841)\ttotal: 15m 30s\tremaining: 2m 54s\n",
      "842:\tlearn: 0.8256821\ttest: 0.8257407\tbest: 0.8257407 (842)\ttotal: 15m 31s\tremaining: 2m 53s\n",
      "843:\tlearn: 0.8257515\ttest: 0.8257881\tbest: 0.8257881 (843)\ttotal: 15m 32s\tremaining: 2m 52s\n",
      "844:\tlearn: 0.8258452\ttest: 0.8259088\tbest: 0.8259088 (844)\ttotal: 15m 33s\tremaining: 2m 51s\n",
      "845:\tlearn: 0.8258655\ttest: 0.8259554\tbest: 0.8259554 (845)\ttotal: 15m 35s\tremaining: 2m 50s\n",
      "846:\tlearn: 0.8258963\ttest: 0.8259587\tbest: 0.8259587 (846)\ttotal: 15m 36s\tremaining: 2m 49s\n",
      "847:\tlearn: 0.8259598\ttest: 0.8260212\tbest: 0.8260212 (847)\ttotal: 15m 37s\tremaining: 2m 48s\n",
      "848:\tlearn: 0.8261343\ttest: 0.8261993\tbest: 0.8261993 (848)\ttotal: 15m 38s\tremaining: 2m 46s\n",
      "849:\tlearn: 0.8263227\ttest: 0.8263191\tbest: 0.8263191 (849)\ttotal: 15m 39s\tremaining: 2m 45s\n",
      "850:\tlearn: 0.8263232\ttest: 0.8263549\tbest: 0.8263549 (850)\ttotal: 15m 40s\tremaining: 2m 44s\n",
      "851:\tlearn: 0.8264622\ttest: 0.8265106\tbest: 0.8265106 (851)\ttotal: 15m 41s\tremaining: 2m 43s\n",
      "852:\tlearn: 0.8264695\ttest: 0.8265414\tbest: 0.8265414 (852)\ttotal: 15m 43s\tremaining: 2m 42s\n",
      "853:\tlearn: 0.8264894\ttest: 0.8265555\tbest: 0.8265555 (853)\ttotal: 15m 44s\tremaining: 2m 41s\n",
      "854:\tlearn: 0.8265108\ttest: 0.8265680\tbest: 0.8265680 (854)\ttotal: 15m 45s\tremaining: 2m 40s\n",
      "855:\tlearn: 0.8265879\ttest: 0.8266337\tbest: 0.8266337 (855)\ttotal: 15m 46s\tremaining: 2m 39s\n",
      "856:\tlearn: 0.8268307\ttest: 0.8268951\tbest: 0.8268951 (856)\ttotal: 15m 47s\tremaining: 2m 38s\n",
      "857:\tlearn: 0.8268265\ttest: 0.8268959\tbest: 0.8268959 (857)\ttotal: 15m 48s\tremaining: 2m 37s\n",
      "858:\tlearn: 0.8269078\ttest: 0.8269658\tbest: 0.8269658 (858)\ttotal: 15m 49s\tremaining: 2m 35s\n",
      "859:\tlearn: 0.8270443\ttest: 0.8270524\tbest: 0.8270524 (859)\ttotal: 15m 51s\tremaining: 2m 34s\n",
      "860:\tlearn: 0.8271245\ttest: 0.8271323\tbest: 0.8271323 (860)\ttotal: 15m 52s\tremaining: 2m 33s\n",
      "861:\tlearn: 0.8272887\ttest: 0.8272854\tbest: 0.8272854 (861)\ttotal: 15m 53s\tremaining: 2m 32s\n",
      "862:\tlearn: 0.8273106\ttest: 0.8273062\tbest: 0.8273062 (862)\ttotal: 15m 54s\tremaining: 2m 31s\n",
      "863:\tlearn: 0.8273001\ttest: 0.8273154\tbest: 0.8273154 (863)\ttotal: 15m 55s\tremaining: 2m 30s\n",
      "864:\tlearn: 0.8273664\ttest: 0.8273628\tbest: 0.8273628 (864)\ttotal: 15m 56s\tremaining: 2m 29s\n",
      "865:\tlearn: 0.8274063\ttest: 0.8273720\tbest: 0.8273720 (865)\ttotal: 15m 57s\tremaining: 2m 28s\n",
      "866:\tlearn: 0.8276347\ttest: 0.8275742\tbest: 0.8275742 (866)\ttotal: 15m 59s\tremaining: 2m 27s\n",
      "867:\tlearn: 0.8276974\ttest: 0.8276250\tbest: 0.8276250 (867)\ttotal: 16m\tremaining: 2m 26s\n",
      "868:\tlearn: 0.8276535\ttest: 0.8276025\tbest: 0.8276250 (867)\ttotal: 16m 1s\tremaining: 2m 24s\n",
      "869:\tlearn: 0.8279326\ttest: 0.8278730\tbest: 0.8278730 (869)\ttotal: 16m 2s\tremaining: 2m 23s\n",
      "870:\tlearn: 0.8278849\ttest: 0.8278722\tbest: 0.8278730 (869)\ttotal: 16m 3s\tremaining: 2m 22s\n",
      "871:\tlearn: 0.8279570\ttest: 0.8279055\tbest: 0.8279055 (871)\ttotal: 16m 4s\tremaining: 2m 21s\n",
      "872:\tlearn: 0.8280683\ttest: 0.8279979\tbest: 0.8279979 (872)\ttotal: 16m 6s\tremaining: 2m 20s\n",
      "873:\tlearn: 0.8282509\ttest: 0.8282209\tbest: 0.8282209 (873)\ttotal: 16m 7s\tremaining: 2m 19s\n",
      "874:\tlearn: 0.8282708\ttest: 0.8282218\tbest: 0.8282218 (874)\ttotal: 16m 8s\tremaining: 2m 18s\n",
      "875:\tlearn: 0.8282728\ttest: 0.8282426\tbest: 0.8282426 (875)\ttotal: 16m 9s\tremaining: 2m 17s\n",
      "876:\tlearn: 0.8283629\ttest: 0.8283142\tbest: 0.8283142 (876)\ttotal: 16m 10s\tremaining: 2m 16s\n",
      "877:\tlearn: 0.8284334\ttest: 0.8283533\tbest: 0.8283533 (877)\ttotal: 16m 11s\tremaining: 2m 15s\n",
      "878:\tlearn: 0.8284262\ttest: 0.8283583\tbest: 0.8283583 (878)\ttotal: 16m 13s\tremaining: 2m 13s\n",
      "879:\tlearn: 0.8284481\ttest: 0.8283749\tbest: 0.8283749 (879)\ttotal: 16m 14s\tremaining: 2m 12s\n",
      "880:\tlearn: 0.8286678\ttest: 0.8285797\tbest: 0.8285797 (880)\ttotal: 16m 15s\tremaining: 2m 11s\n",
      "881:\tlearn: 0.8286723\ttest: 0.8285647\tbest: 0.8285797 (880)\ttotal: 16m 16s\tremaining: 2m 10s\n",
      "882:\tlearn: 0.8286107\ttest: 0.8284981\tbest: 0.8285797 (880)\ttotal: 16m 17s\tremaining: 2m 9s\n",
      "883:\tlearn: 0.8287758\ttest: 0.8286812\tbest: 0.8286812 (883)\ttotal: 16m 18s\tremaining: 2m 8s\n",
      "884:\tlearn: 0.8287716\ttest: 0.8286546\tbest: 0.8286812 (883)\ttotal: 16m 19s\tremaining: 2m 7s\n",
      "885:\tlearn: 0.8288568\ttest: 0.8287752\tbest: 0.8287752 (885)\ttotal: 16m 21s\tremaining: 2m 6s\n",
      "886:\tlearn: 0.8291090\ttest: 0.8290774\tbest: 0.8290774 (886)\ttotal: 16m 22s\tremaining: 2m 5s\n",
      "887:\tlearn: 0.8291109\ttest: 0.8290541\tbest: 0.8290774 (886)\ttotal: 16m 23s\tremaining: 2m 4s\n",
      "888:\tlearn: 0.8291936\ttest: 0.8291531\tbest: 0.8291531 (888)\ttotal: 16m 24s\tremaining: 2m 2s\n",
      "889:\tlearn: 0.8293062\ttest: 0.8291914\tbest: 0.8291914 (889)\ttotal: 16m 25s\tremaining: 2m 1s\n",
      "890:\tlearn: 0.8293953\ttest: 0.8292938\tbest: 0.8292938 (890)\ttotal: 16m 26s\tremaining: 2m\n",
      "891:\tlearn: 0.8295401\ttest: 0.8294536\tbest: 0.8294536 (891)\ttotal: 16m 28s\tremaining: 1m 59s\n",
      "892:\tlearn: 0.8296025\ttest: 0.8294993\tbest: 0.8294993 (892)\ttotal: 16m 29s\tremaining: 1m 58s\n",
      "893:\tlearn: 0.8295617\ttest: 0.8294844\tbest: 0.8294993 (892)\ttotal: 16m 30s\tremaining: 1m 57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894:\tlearn: 0.8296314\ttest: 0.8295418\tbest: 0.8295418 (894)\ttotal: 16m 31s\tremaining: 1m 56s\n",
      "895:\tlearn: 0.8296683\ttest: 0.8295659\tbest: 0.8295659 (895)\ttotal: 16m 32s\tremaining: 1m 55s\n",
      "896:\tlearn: 0.8298045\ttest: 0.8297332\tbest: 0.8297332 (896)\ttotal: 16m 33s\tremaining: 1m 54s\n",
      "897:\tlearn: 0.8300012\ttest: 0.8298622\tbest: 0.8298622 (897)\ttotal: 16m 35s\tremaining: 1m 53s\n",
      "898:\tlearn: 0.8300184\ttest: 0.8298747\tbest: 0.8298747 (898)\ttotal: 16m 36s\tremaining: 1m 51s\n",
      "899:\tlearn: 0.8300400\ttest: 0.8299122\tbest: 0.8299122 (899)\ttotal: 16m 37s\tremaining: 1m 50s\n",
      "900:\tlearn: 0.8301471\ttest: 0.8299729\tbest: 0.8299729 (900)\ttotal: 16m 38s\tremaining: 1m 49s\n",
      "901:\tlearn: 0.8302830\ttest: 0.8301402\tbest: 0.8301402 (901)\ttotal: 16m 39s\tremaining: 1m 48s\n",
      "902:\tlearn: 0.8304279\ttest: 0.8303000\tbest: 0.8303000 (902)\ttotal: 16m 40s\tremaining: 1m 47s\n",
      "903:\tlearn: 0.8304503\ttest: 0.8303258\tbest: 0.8303258 (903)\ttotal: 16m 41s\tremaining: 1m 46s\n",
      "904:\tlearn: 0.8304903\ttest: 0.8303466\tbest: 0.8303466 (904)\ttotal: 16m 43s\tremaining: 1m 45s\n",
      "905:\tlearn: 0.8305136\ttest: 0.8303882\tbest: 0.8303882 (905)\ttotal: 16m 44s\tremaining: 1m 44s\n",
      "906:\tlearn: 0.8305161\ttest: 0.8303583\tbest: 0.8303882 (905)\ttotal: 16m 45s\tremaining: 1m 43s\n",
      "907:\tlearn: 0.8305699\ttest: 0.8303857\tbest: 0.8303882 (905)\ttotal: 16m 46s\tremaining: 1m 41s\n",
      "908:\tlearn: 0.8306687\ttest: 0.8304873\tbest: 0.8304873 (908)\ttotal: 16m 47s\tremaining: 1m 40s\n",
      "909:\tlearn: 0.8306817\ttest: 0.8305472\tbest: 0.8305472 (909)\ttotal: 16m 48s\tremaining: 1m 39s\n",
      "910:\tlearn: 0.8307103\ttest: 0.8305830\tbest: 0.8305830 (910)\ttotal: 16m 50s\tremaining: 1m 38s\n",
      "911:\tlearn: 0.8309014\ttest: 0.8307570\tbest: 0.8307570 (911)\ttotal: 16m 51s\tremaining: 1m 37s\n",
      "912:\tlearn: 0.8310083\ttest: 0.8308643\tbest: 0.8308643 (912)\ttotal: 16m 52s\tremaining: 1m 36s\n",
      "913:\tlearn: 0.8311656\ttest: 0.8310366\tbest: 0.8310366 (913)\ttotal: 16m 53s\tremaining: 1m 35s\n",
      "914:\tlearn: 0.8311514\ttest: 0.8310408\tbest: 0.8310408 (914)\ttotal: 16m 54s\tremaining: 1m 34s\n",
      "915:\tlearn: 0.8312147\ttest: 0.8310990\tbest: 0.8310990 (915)\ttotal: 16m 55s\tremaining: 1m 33s\n",
      "916:\tlearn: 0.8314003\ttest: 0.8312455\tbest: 0.8312455 (916)\ttotal: 16m 56s\tremaining: 1m 32s\n",
      "917:\tlearn: 0.8313839\ttest: 0.8312164\tbest: 0.8312455 (916)\ttotal: 16m 57s\tremaining: 1m 30s\n",
      "918:\tlearn: 0.8315193\ttest: 0.8313254\tbest: 0.8313254 (918)\ttotal: 16m 59s\tremaining: 1m 29s\n",
      "919:\tlearn: 0.8316034\ttest: 0.8313920\tbest: 0.8313920 (919)\ttotal: 17m\tremaining: 1m 28s\n",
      "920:\tlearn: 0.8316391\ttest: 0.8314311\tbest: 0.8314311 (920)\ttotal: 17m 1s\tremaining: 1m 27s\n",
      "921:\tlearn: 0.8316450\ttest: 0.8314428\tbest: 0.8314428 (921)\ttotal: 17m 2s\tremaining: 1m 26s\n",
      "922:\tlearn: 0.8317734\ttest: 0.8315784\tbest: 0.8315784 (922)\ttotal: 17m 3s\tremaining: 1m 25s\n",
      "923:\tlearn: 0.8318186\ttest: 0.8316184\tbest: 0.8316184 (923)\ttotal: 17m 4s\tremaining: 1m 24s\n",
      "924:\tlearn: 0.8318192\ttest: 0.8316550\tbest: 0.8316550 (924)\ttotal: 17m 5s\tremaining: 1m 23s\n",
      "925:\tlearn: 0.8319185\ttest: 0.8317124\tbest: 0.8317124 (925)\ttotal: 17m 6s\tremaining: 1m 22s\n",
      "926:\tlearn: 0.8322600\ttest: 0.8320454\tbest: 0.8320454 (926)\ttotal: 17m 8s\tremaining: 1m 20s\n",
      "927:\tlearn: 0.8322636\ttest: 0.8320570\tbest: 0.8320570 (927)\ttotal: 17m 9s\tremaining: 1m 19s\n",
      "928:\tlearn: 0.8323391\ttest: 0.8321394\tbest: 0.8321394 (928)\ttotal: 17m 10s\tremaining: 1m 18s\n",
      "929:\tlearn: 0.8324168\ttest: 0.8321752\tbest: 0.8321752 (929)\ttotal: 17m 11s\tremaining: 1m 17s\n",
      "930:\tlearn: 0.8323907\ttest: 0.8321644\tbest: 0.8321752 (929)\ttotal: 17m 12s\tremaining: 1m 16s\n",
      "931:\tlearn: 0.8324176\ttest: 0.8321644\tbest: 0.8321752 (929)\ttotal: 17m 13s\tremaining: 1m 15s\n",
      "932:\tlearn: 0.8324173\ttest: 0.8321602\tbest: 0.8321752 (929)\ttotal: 17m 15s\tremaining: 1m 14s\n",
      "933:\tlearn: 0.8324556\ttest: 0.8321960\tbest: 0.8321960 (933)\ttotal: 17m 16s\tremaining: 1m 13s\n",
      "934:\tlearn: 0.8326176\ttest: 0.8323550\tbest: 0.8323550 (934)\ttotal: 17m 17s\tremaining: 1m 12s\n",
      "935:\tlearn: 0.8328540\ttest: 0.8325739\tbest: 0.8325739 (935)\ttotal: 17m 18s\tremaining: 1m 11s\n",
      "936:\tlearn: 0.8328804\ttest: 0.8326404\tbest: 0.8326404 (936)\ttotal: 17m 19s\tremaining: 1m 9s\n",
      "937:\tlearn: 0.8329217\ttest: 0.8327079\tbest: 0.8327079 (937)\ttotal: 17m 20s\tremaining: 1m 8s\n",
      "938:\tlearn: 0.8331248\ttest: 0.8329376\tbest: 0.8329376 (938)\ttotal: 17m 21s\tremaining: 1m 7s\n",
      "939:\tlearn: 0.8331561\ttest: 0.8329401\tbest: 0.8329401 (939)\ttotal: 17m 23s\tremaining: 1m 6s\n",
      "940:\tlearn: 0.8333800\ttest: 0.8331764\tbest: 0.8331764 (940)\ttotal: 17m 24s\tremaining: 1m 5s\n",
      "941:\tlearn: 0.8334577\ttest: 0.8332855\tbest: 0.8332855 (941)\ttotal: 17m 25s\tremaining: 1m 4s\n",
      "942:\tlearn: 0.8335520\ttest: 0.8333604\tbest: 0.8333604 (942)\ttotal: 17m 26s\tremaining: 1m 3s\n",
      "943:\tlearn: 0.8335409\ttest: 0.8333354\tbest: 0.8333604 (942)\ttotal: 17m 27s\tremaining: 1m 2s\n",
      "944:\tlearn: 0.8335507\ttest: 0.8333429\tbest: 0.8333604 (942)\ttotal: 17m 28s\tremaining: 1m 1s\n",
      "945:\tlearn: 0.8336197\ttest: 0.8334211\tbest: 0.8334211 (945)\ttotal: 17m 29s\tremaining: 59.9s\n",
      "946:\tlearn: 0.8337793\ttest: 0.8335651\tbest: 0.8335651 (946)\ttotal: 17m 30s\tremaining: 58.8s\n",
      "947:\tlearn: 0.8339704\ttest: 0.8337815\tbest: 0.8337815 (947)\ttotal: 17m 32s\tremaining: 57.7s\n",
      "948:\tlearn: 0.8339643\ttest: 0.8338157\tbest: 0.8338157 (948)\ttotal: 17m 33s\tremaining: 56.6s\n",
      "949:\tlearn: 0.8341463\ttest: 0.8339730\tbest: 0.8339730 (949)\ttotal: 17m 34s\tremaining: 55.5s\n",
      "950:\tlearn: 0.8341327\ttest: 0.8339413\tbest: 0.8339730 (949)\ttotal: 17m 35s\tremaining: 54.4s\n",
      "951:\tlearn: 0.8342942\ttest: 0.8341186\tbest: 0.8341186 (951)\ttotal: 17m 36s\tremaining: 53.3s\n",
      "952:\tlearn: 0.8343097\ttest: 0.8341511\tbest: 0.8341511 (952)\ttotal: 17m 37s\tremaining: 52.2s\n",
      "953:\tlearn: 0.8344457\ttest: 0.8342817\tbest: 0.8342817 (953)\ttotal: 17m 39s\tremaining: 51.1s\n",
      "954:\tlearn: 0.8344784\ttest: 0.8343575\tbest: 0.8343575 (954)\ttotal: 17m 40s\tremaining: 50s\n",
      "955:\tlearn: 0.8345908\ttest: 0.8344873\tbest: 0.8344873 (955)\ttotal: 17m 41s\tremaining: 48.9s\n",
      "956:\tlearn: 0.8346854\ttest: 0.8345472\tbest: 0.8345472 (956)\ttotal: 17m 42s\tremaining: 47.7s\n",
      "957:\tlearn: 0.8347908\ttest: 0.8346563\tbest: 0.8346563 (957)\ttotal: 17m 43s\tremaining: 46.6s\n",
      "958:\tlearn: 0.8347933\ttest: 0.8346912\tbest: 0.8346912 (958)\ttotal: 17m 44s\tremaining: 45.5s\n",
      "959:\tlearn: 0.8348318\ttest: 0.8347162\tbest: 0.8347162 (959)\ttotal: 17m 45s\tremaining: 44.4s\n",
      "960:\tlearn: 0.8348596\ttest: 0.8347478\tbest: 0.8347478 (960)\ttotal: 17m 47s\tremaining: 43.3s\n",
      "961:\tlearn: 0.8348557\ttest: 0.8346912\tbest: 0.8347478 (960)\ttotal: 17m 48s\tremaining: 42.2s\n",
      "962:\tlearn: 0.8348757\ttest: 0.8347229\tbest: 0.8347478 (960)\ttotal: 17m 49s\tremaining: 41.1s\n",
      "963:\tlearn: 0.8348895\ttest: 0.8347337\tbest: 0.8347478 (960)\ttotal: 17m 50s\tremaining: 40s\n",
      "964:\tlearn: 0.8349270\ttest: 0.8348011\tbest: 0.8348011 (964)\ttotal: 17m 51s\tremaining: 38.9s\n",
      "965:\tlearn: 0.8349597\ttest: 0.8347736\tbest: 0.8348011 (964)\ttotal: 17m 52s\tremaining: 37.8s\n",
      "966:\tlearn: 0.8350058\ttest: 0.8348444\tbest: 0.8348444 (966)\ttotal: 17m 54s\tremaining: 36.7s\n",
      "967:\tlearn: 0.8350832\ttest: 0.8349193\tbest: 0.8349193 (967)\ttotal: 17m 55s\tremaining: 35.5s\n",
      "968:\tlearn: 0.8351487\ttest: 0.8349734\tbest: 0.8349734 (968)\ttotal: 17m 56s\tremaining: 34.4s\n",
      "969:\tlearn: 0.8351675\ttest: 0.8349917\tbest: 0.8349917 (969)\ttotal: 17m 57s\tremaining: 33.3s\n",
      "970:\tlearn: 0.8351800\ttest: 0.8349992\tbest: 0.8349992 (970)\ttotal: 17m 58s\tremaining: 32.2s\n",
      "971:\tlearn: 0.8351720\ttest: 0.8350133\tbest: 0.8350133 (971)\ttotal: 17m 59s\tremaining: 31.1s\n",
      "972:\tlearn: 0.8353193\ttest: 0.8351515\tbest: 0.8351515 (972)\ttotal: 18m\tremaining: 30s\n",
      "973:\tlearn: 0.8353734\ttest: 0.8352056\tbest: 0.8352056 (973)\ttotal: 18m 2s\tremaining: 28.9s\n",
      "974:\tlearn: 0.8354439\ttest: 0.8352788\tbest: 0.8352788 (974)\ttotal: 18m 3s\tremaining: 27.8s\n",
      "975:\tlearn: 0.8356089\ttest: 0.8354553\tbest: 0.8354553 (975)\ttotal: 18m 4s\tremaining: 26.7s\n",
      "976:\tlearn: 0.8358694\ttest: 0.8357383\tbest: 0.8357383 (976)\ttotal: 18m 5s\tremaining: 25.6s\n",
      "977:\tlearn: 0.8360903\ttest: 0.8359372\tbest: 0.8359372 (977)\ttotal: 18m 6s\tremaining: 24.4s\n",
      "978:\tlearn: 0.8362726\ttest: 0.8361061\tbest: 0.8361061 (978)\ttotal: 18m 7s\tremaining: 23.3s\n",
      "979:\tlearn: 0.8363389\ttest: 0.8361461\tbest: 0.8361461 (979)\ttotal: 18m 8s\tremaining: 22.2s\n",
      "980:\tlearn: 0.8363788\ttest: 0.8362243\tbest: 0.8362243 (980)\ttotal: 18m 10s\tremaining: 21.1s\n",
      "981:\tlearn: 0.8365505\ttest: 0.8364341\tbest: 0.8364341 (981)\ttotal: 18m 11s\tremaining: 20s\n",
      "982:\tlearn: 0.8366671\ttest: 0.8365165\tbest: 0.8365165 (982)\ttotal: 18m 12s\tremaining: 18.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983:\tlearn: 0.8366352\ttest: 0.8364657\tbest: 0.8365165 (982)\ttotal: 18m 13s\tremaining: 17.8s\n",
      "984:\tlearn: 0.8368080\ttest: 0.8366654\tbest: 0.8366654 (984)\ttotal: 18m 14s\tremaining: 16.7s\n",
      "985:\tlearn: 0.8368854\ttest: 0.8367270\tbest: 0.8367270 (985)\ttotal: 18m 16s\tremaining: 15.6s\n",
      "986:\tlearn: 0.8371626\ttest: 0.8370350\tbest: 0.8370350 (986)\ttotal: 18m 17s\tremaining: 14.4s\n",
      "987:\tlearn: 0.8372802\ttest: 0.8371948\tbest: 0.8371948 (987)\ttotal: 18m 18s\tremaining: 13.3s\n",
      "988:\tlearn: 0.8377715\ttest: 0.8377782\tbest: 0.8377782 (988)\ttotal: 18m 19s\tremaining: 12.2s\n",
      "989:\tlearn: 0.8378059\ttest: 0.8378107\tbest: 0.8378107 (989)\ttotal: 18m 20s\tremaining: 11.1s\n",
      "990:\tlearn: 0.8377773\ttest: 0.8377907\tbest: 0.8378107 (989)\ttotal: 18m 21s\tremaining: 10s\n",
      "991:\tlearn: 0.8378353\ttest: 0.8378573\tbest: 0.8378573 (991)\ttotal: 18m 22s\tremaining: 8.89s\n",
      "992:\tlearn: 0.8378470\ttest: 0.8378789\tbest: 0.8378789 (992)\ttotal: 18m 23s\tremaining: 7.78s\n",
      "993:\tlearn: 0.8378634\ttest: 0.8378906\tbest: 0.8378906 (993)\ttotal: 18m 24s\tremaining: 6.67s\n",
      "994:\tlearn: 0.8378783\ttest: 0.8379056\tbest: 0.8379056 (994)\ttotal: 18m 26s\tremaining: 5.56s\n",
      "995:\tlearn: 0.8379252\ttest: 0.8379222\tbest: 0.8379222 (995)\ttotal: 18m 27s\tremaining: 4.45s\n",
      "996:\tlearn: 0.8379261\ttest: 0.8379322\tbest: 0.8379322 (996)\ttotal: 18m 28s\tremaining: 3.33s\n",
      "997:\tlearn: 0.8379863\ttest: 0.8379355\tbest: 0.8379355 (997)\ttotal: 18m 29s\tremaining: 2.22s\n",
      "998:\tlearn: 0.8380165\ttest: 0.8379780\tbest: 0.8379780 (998)\ttotal: 18m 30s\tremaining: 1.11s\n",
      "999:\tlearn: 0.8380800\ttest: 0.8380521\tbest: 0.8380521 (999)\ttotal: 18m 31s\tremaining: 0us\n",
      "bestTest = 0.8380520537\n",
      "bestIteration = 999\n",
      "1119.469738960266\n"
     ]
    }
   ],
   "source": [
    "boost_model = catboost.CatBoostClassifier(iterations=1000,\n",
    "                           learning_rate=0.05,\n",
    "                           depth=4,\n",
    "                           task_type='GPU',                                                \n",
    "                           loss_function='MultiClass',\n",
    "                           eval_metric='Accuracy')\n",
    "time_start = time.time()\n",
    "boost_model.fit(train_dataset, eval_set=(X_val, y_val))\n",
    "time_finish = time.time()\n",
    "print(time_finish - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(boost_model, 'CatBoostModel_2grams_v2.sav')\n",
    "boost_model.save_model('CatBoostModel_2grams_v2.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   IEEEannot       0.68      0.57      0.62     13766\n",
      "    IEEEtran       0.70      0.64      0.67     14624\n",
      "   IEEEtranN       0.77      0.84      0.81     14765\n",
      "   IEEEtranS       0.63      0.68      0.65     14383\n",
      "  IEEEtranSA       0.92      0.92      0.92     14937\n",
      "  IEEEtranSN       0.85      0.73      0.78     14727\n",
      "      JHEP-2       0.82      0.83      0.83     14364\n",
      "  aaai-named       0.95      0.97      0.96     14087\n",
      "    abstract       0.99      0.96      0.98     13930\n",
      "    acmtrans       0.88      0.88      0.88     14318\n",
      "      aichej       0.98      0.97      0.98     13565\n",
      "         aip       0.59      0.59      0.59     14162\n",
      "    alphanum       0.71      0.77      0.74     14081\n",
      "         ama       0.95      0.96      0.95     13835\n",
      "    amsalpha       0.98      0.97      0.98     10881\n",
      "    amsplain       0.95      0.95      0.95     10898\n",
      "    annotate       0.75      0.69      0.72     14175\n",
      "  annotation       0.99      0.99      0.99     13011\n",
      "         apa       0.93      0.91      0.92     14310\n",
      "apalike-ejor       0.98      0.96      0.97     13300\n",
      "     apasoft       0.98      0.99      0.98     14280\n",
      "      astron       1.00      0.99      0.99     14237\n",
      "         bbs       0.92      0.92      0.92     14271\n",
      " besjournals       0.99      0.99      0.99     14182\n",
      "  bestpapers       0.96      0.56      0.71       183\n",
      "     biolett       0.94      0.98      0.96     13699\n",
      "      bookdb       0.98      0.97      0.97     10915\n",
      "         cbe       0.93      0.91      0.92     14541\n",
      "     chicago       0.77      0.72      0.74     14284\n",
      "    chicagoa       0.74      0.76      0.75     14443\n",
      "          cj       0.95      0.97      0.96     14288\n",
      "         cpc       0.83      0.82      0.82     14285\n",
      "      decsci       0.98      0.95      0.96     13990\n",
      " development       0.97      0.97      0.97     14136\n",
      "         fbs       0.99      0.98      0.99     14148\n",
      "    finplain       0.81      0.83      0.82     14052\n",
      "    generate       0.99      0.99      0.99      3454\n",
      " h-elsevier3       0.74      0.69      0.71     14393\n",
      "  h-physrev3       0.60      0.50      0.55     14015\n",
      "  h-physrev4       0.65      0.53      0.58     13824\n",
      "  h-physrev5       0.67      0.54      0.60     13778\n",
      "        hum2       0.94      0.95      0.94     14411\n",
      "    humanbio       0.84      0.89      0.86     14235\n",
      "    humannat       0.97      0.99      0.98     14372\n",
      "        iaea       0.74      0.85      0.79     14273\n",
      "       jbact       0.94      0.97      0.96     14398\n",
      "         jcc       0.84      0.86      0.85     14435\n",
      "         jcp       0.60      0.49      0.54     13896\n",
      "         jmb       0.92      0.91      0.91     14099\n",
      "   jneurosci       0.96      0.97      0.97     14392\n",
      "         jpc       0.87      0.84      0.85     14182\n",
      "    jphysiol       0.90      0.94      0.92     14345\n",
      "     jqt1999       0.90      0.86      0.88     14189\n",
      "         jtb       0.99      0.99      0.99     14197\n",
      "      jtbnew       0.97      0.96      0.96     14017\n",
      "         mla       0.77      0.77      0.77     14290\n",
      "        mlaa       0.77      0.77      0.77     14319\n",
      "    namunsrt       1.00      1.00      1.00     13973\n",
      "         nar       0.97      0.95      0.96     14274\n",
      "      natbib       0.97      0.99      0.98     13939\n",
      "      neuron       0.94      0.98      0.96     14051\n",
      "   newcastle       0.99      0.98      0.99     12978\n",
      "          nf       0.72      0.71      0.71     14232\n",
      "       nflet       0.68      0.71      0.70     14474\n",
      "        pccp       0.84      0.86      0.85     14007\n",
      "  perception       1.00      1.00      1.00     13918\n",
      "          pf       0.43      0.60      0.50     13991\n",
      "       phjcp       0.57      0.50      0.54     14125\n",
      "     plainyr       0.78      0.86      0.82     14516\n",
      "        pnas       0.75      0.84      0.79     14360\n",
      "    pnas2009       0.81      0.72      0.76     13997\n",
      "        ppcf       0.83      0.89      0.86     14498\n",
      "      report       0.52      0.71      0.60     13977\n",
      " revcompchem       0.90      0.93      0.91     14345\n",
      "         rmp       0.96      0.98      0.97     13480\n",
      "       these       0.97      0.97      0.97     14203\n",
      "   ugost2003       0.80      0.64      0.71     11092\n",
      "  ugost2003s       0.69      0.83      0.76     10762\n",
      "   ugost2008       0.52      0.49      0.50     11156\n",
      "  ugost2008l       0.47      0.58      0.52     10961\n",
      " ugost2008ls       0.54      0.52      0.53     10762\n",
      "ugost2008mod       0.79      0.61      0.69     11027\n",
      "  ugost2008n       0.29      0.28      0.28        57\n",
      " ugost2008ns       0.31      0.27      0.29        59\n",
      "  ugost2008s       0.49      0.53      0.51     10954\n",
      "      utcaps       0.79      0.74      0.76     14108\n",
      "      utphys       0.78      0.78      0.78     13795\n",
      "         vak       0.99      0.99      0.99     13982\n",
      "   vancouver       0.99      0.99      0.99     13359\n",
      "     wmaainf       0.97      0.96      0.97     14141\n",
      "     zootaxa       0.97      0.96      0.97     14371\n",
      "\n",
      "    accuracy                           0.84   1201491\n",
      "   macro avg       0.83      0.82      0.82   1201491\n",
      "weighted avg       0.84      0.84      0.84   1201491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, boost_model.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
