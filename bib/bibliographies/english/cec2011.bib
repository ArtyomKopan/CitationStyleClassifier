%patch_cec2011.awk Revision: 1.00 $ Sun Jun 26 09:46:08 BST 2011 
%Alice E. Smith 15 June 2011
%WBL 21-06-2011

%WBL 30 Jul 2017 ensure passes bibclean v3.02

% Tutorial: Introduction to Evolutionary Computation

% Tutorial: Parallel and Distributed Evolutionary Algorithms

% Workshop: International Workshop on Distributed Evolutionary Computation in Informal Environments I

% Tutorial: A Survey of Representations for Evolutionary Algorithms

% Tutorial: Applying Computational Intelligence - How to Create Value

% Workshop: International Workshop on Distributed Evolutionary Computation in Informal Environments II

% Tutorial: Molecular Biology for Computational Scientists

% Tutorial: Industrial Applications of Evolutionary Algorithms

% Tutorial: Computational Intelligence and Games

% Workshop: Evolutionary Music I

% Tutorial: Medical  Applications of EC

% Tutorial: Cultural Algorithms : Incorporating Social Intelligence into Virtual Worlds

% Tutorial: The Art of Evolutionary Algorithms Programming

% Workshop: Evolutionary Music II

% Plenary Talk: Darwin's Magic : Evolutionary Computation in Nanoscience, Bioinformatics and Systems Biology

% Special Session: Nature Inspired Techniques for Structural Design, Optimization and Identification Problems 
@InProceedings{Banerjee:2011:EAPIfNDS,
  title     = {Evolutionary Algorithm-based Parameter Identification for Nonlinear Dynamical Systems},
  author    = {Amit Banerjee and Issam Abu-Mahfouz},
  pages     = {1--5},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications},
  abstract  = {
The inverse problem of parameter estimation for Duffing oscillator, a chaotic
dynamical system well known in engineering is solved using quantum-inspired
evolutionary algorithm, differential evolution and genetic algorithms. The
paper focuses on such combination of parameters that produce periodic
responses instead of purely chaotic responses. The feature set used is a set
of displacement values of the first five Poincare points, after ignoring
transient effects. All approaches correctly identify the target set of
parameters as producing the given response; however, depending on the fitness
landscape some parameters are more difficult to identify than others
especially when using the canonical genetic algorithm. This paper is also the
first to investigate the quantum-inspired evolutionary algorithm for such
parameter identification problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Raich:2011:BoIRRGAfCDaDI,
  title     = {Benefits of Implicit Redundant Representation Genetic Algorithms for Conceptual Design and Damage Identification},
  author    = {Anne Raich and Kyle Fritz},
  pages     = {6--13},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Representation and operators},
  abstract  = {
Solving large-scale structural design and damage identification problems using
genetic algorithm optimization methods requires the use of advanced
representations. The implicit redundant representation (IRR) provides
significant benefits for inverse problems in which the solution involves
determining the optimal number of design variables, in addition to their
values. The IRR encodes both variables and redundant segments in each
individual. The encoded variable locations and values dynamically change and
self-organize through crossover and mutation during optimization. In searching
for optimal structural forms in conceptual design, the IRR provides the
flexibility to represent designs having different numbers and locations of
members and nodes, which supports the simultaneous optimization of topology,
geometry, and member sizes. Therefore a broad range of designs can be
evaluated during a single trial. The set of Pareto-optimal designs evolved by
the IRR define the tradeoffs that occur in optimizing the objectives as the
structural topology and geometry changes. In damage detection, optimization is
often used to predict the location and extent of damages based on the
structural response collected from measurement data. The IRR can work with a
small subset of all possible damaged elements during the search process, which
allows the method to scale well with problem size. The IRR genetic algorithm
representation discussed holds significant promise in solving large-scale
inverse problems by providing the benefit of working with a variable number of
design variables. This flexibility is leveraged to reduce the implicit size of
the problem domain searched and to compare designs having markedly different
forms or topologies.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Mirmomeni:2011:CDDMaTDSwtAtFCTS,
  title     = {Co-evolving Data Driven Models and Test Data Sets with the Application to Forecast Chaotic Time Series},
  author    = {Masoud Mirmomeni and William Punch},
  pages     = {14--20},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Coevolutionary systems, Evolved neural networks},
  abstract  = {
Several approaches have been introduced for modeling and prediction of
nonlinear dynamics which have chaotic characteristics. Among these methods,
data driven approaches such as Auto Regressive (AR) models, Nonlinear Auto
Regressive (NAR) models, Radial Basis Function (RBF) networks, and Multi
Layered Perceptron (MLP) neural networks have proven themselves to be powerful
approaches in modeling and prediction of chaotic dynamics. However, the
structure of these models should be known before the training phase, which is
a very complicated problem. In this research, we introduce a co-evolutionary
approach for modeling and system identification of chaotic dynamics. The
proposed algorithm is composed of two co-evolving populations: candidate data
driven models, and test data sets which either extract new information from
the nonlinear chaotic system or elicit desirable behavior from it. The fitness
of candidate models is their ability to explain behavior of the target chaotic
system observed in response to tests carried out so far by predicting the
future values of these data sets; the fitness of candidate test data sets is
their ability to make the models disagree in their predictions. To check the
performance of this algorithm, three case studies are considered. First, we
apply this method to approximate a static function which has complicated
behavior near zero. Then, we use this algorithm to predict two bench mark time
series in chaos literature: Sunspot Number (SSN) and Mackey-Glass (MG) time
series. Simulation results depict the power of proposed method in modeling and
predicting complicated nonlinear systems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Yagoubi:2011:AEMAwHEC,
  title     = {Asynchronous Evolutionary Multi-Objective Algorithms with Heterogenous Evaluation Costs},
  author    = {Mouadh Yagoubi and Ludovic Thobois and Marc Schoenauer},
  pages     = {21--28},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Parallel and distributed algorithms},
  abstract  = {
Master-slave parallelization of Evolutionary Algorithms (EAs) is
straightforward, by distributing all fitness computations to slaves. The
benefits of asynchronous steady-state approaches are well-known when facing a
possible heterogeneity among the evaluation costs in term of runtime, be they
due to heterogeneous hardware or non-linear numerical simulations. However,
when this heterogeneity depends on some characteristics of the individuals
being evaluated, the search might be biased, and some regions of the search
space poorly explored. Motivated by a real-world case study of multi-objective
optimization problem -- the optimization of the combustion in a Diesel Engine
-- the consequences of different components of heterogeneity in the evaluation
costs on the convergence of two Evolutionary Multi-objective Optimization
Algorithms are investigated on artificially-heterogeneous benchmark problems.
In some cases, better spread of the population on the Pareto front seem to
result from the interplay between the heterogeneity at hand and the
evolutionary search.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lemonge:2011:DOoGNTSCCC,
  title     = {Design Optimization of Geometrically Nonlinear Truss Structures Considering Cardinality Constraints},
  author    = {Afonso Lemonge and Michelli Silva and Helio Barbosa},
  pages     = {29--36},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Constraint and uncertainty handling},
  abstract  = {
The structural optimization problem of choosing the profile of each member
belonging to a framed structure in order to minimize its weight while
satisfying stress, displacement, stability, and other applicable constraints
is often complicated by the requirement of considering  non-linear structural
behavior. The problem is further complicated if the members are to be chosen
from a discrete set of commercially available sizes, which is frequently the
case. The solution of the commonly occurring case where the cardinality of the
set of distinct values of the design variables (for instance, cross-sectional
areas) should be smaller than a given value is still an open area for
investigation. In this paper a genetic algorithm encoding, previously proposed
in the literature, is used to directly enforce such cardinality constraint for
design optimization of geometrically nonlinear truss structures. The impact of
performing a more rigorous (geometrically nonlinear) structural analysis, on
both safety and cost of the optimized structure is also pointed out.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Estimation of Distribution Approaches to Complex Problems
@InProceedings{Li:2011:ANEoDAUGCRaRL,
  title     = {A Novel Estimation of Distribution Algorithm Using Graph-based Chromosome Representation and Reinforcement Learning},
  author    = {Xianneng Li and Bing Li and Shingo Mabu and Kotaro Hirasawa},
  pages     = {37--44},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Estimation of distribution algorithms},
  abstract  = {
This paper proposed a novel EDA, where a directed graph network is used to
represent its chromosome. In the proposed algorithm, a probabilistic model is
constructed from the promising individuals of the current generation using
reinforcement learning, and used to produce the new population. The node
connection probability is studied to develop the probabilistic model,
therefore pairwise interactions can be demonstrated to identify and recombine
building blocks in the proposed algorithm. The proposed algorithm is applied
to a problem of agent control, i.e., autonomous robot control. The
experimental results show the superiority of the proposed algorithm comparing
with the conventional algorithms.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chen:2011:BACwGAfSMSPwSST,
  title     = {Bi-Variate Artificial Chromosomes with Genetic Algorithm for Single Machine Scheduling Problems with Sequence-Dependent Setup Times},
  author    = {Shih-Hsin Chen and Min-Chih Chen},
  pages     = {45--53},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Estimation of distribution algorithms, Genetic algorithms, Heuristics, metaheuristics and hyper-heuristics},
  abstract  = {
Artificial chromosomes with genetic algorithm (ACGA) is one of the latest
Estimation of Distribution Algorithms (EDAs). This algorithm has been used to
solve different kinds of scheduling problems successfully. However, due to its
probabilistic model does not consider the variable interactions, ACGA may not
perform well in some scheduling problems, particularly the sequence-dependent
setup times are considered because a former job influences the processing time
of next job. It is not sufficient that probabilistic model just captures the
ordinal information from parental distribution. As a result, this paper
proposes a bi-variate probabilistic model added into the ACGA. The new
algorithm is named extended artificial chromosomes with genetic algorithm
(eACGA) and it is used to solve single machine scheduling problem with
sequence-dependent setup times in a common due-date environment. Some
heuristics are also employed with eACGA. The results indicate that the average
error ratio of eACGA is one-half of the ACGA. In addition, when eACGA works
with other heuristics, the hybrid algorithm achieves the best solution quality
when it is compared with other algorithms in literature. Thus, the proposed
algorithms are effective for solving this scheduling problem with setup
consideration.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Pitangui:2011:ILPTEoDA,
  title     = {Inductive Logic Programming  Through Estimation of Distribution Algorithm},
  author    = {Cristiano Pitangui and Gerson Zaverucha},
  pages     = {54--61},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Estimation of distribution algorithms, Classification, clustering, data analysis and data mining},
  abstract  = {
Genetic Algorithms (GAs) are known for their capacity to explore large search
spaces and due to this ability, they were to some extent applied to Inductive
Logic Programming (ILP) problem. Although Estimation of Distribution
Algorithms (EDAs) perform better in most problems when compared to standard
GAs, this kind of algorithm have not been applied to ILP. This work presents
an ILP system based on EDA. Preliminary results show that the proposed system
is superior when compared to a "standard" GA and it is very competitive when
compared to the state of the art ILP system Aleph.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Goncalves:2011:Olieodafde,
  title     = {Online learning in estimation of distribution algorithms for dynamic environments},
  author    = {Andre R. Goncalves and Fernando J. {Von Zuben}},
  pages     = {62--69},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Estimation of distribution algorithms, Dynamic and uncertain environments.},
  abstract  = {
In this paper, we propose an estimation of distribution algorithm based on an
inexpensive Gaussian mixture model with online learning, which will be
employed in dynamic optimization. Here, the mixture model stores a vector of
sufficient statistics of the best solutions, which is subsequently used to
obtain the parameters of the Gaussian components. This approach is able to
incorporate into the current mixture model potentially relevant information of
the previous and current iterations. The online nature of the proposal is
desirable in the context of dynamic optimization, where prompt reaction to new
scenarios should be promoted. To analyze the performance of our proposal, a
set of dynamic optimization problems in continuous domains was considered with
distinct levels of complexity, and the obtained results were compared to the
results produced by other existing algorithms in the dynamic optimization
literature.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Competition: Ms. Pac-Man vs. Ghost-Team Competition
@InProceedings{Rohlfshagen:2011:MPvGTC2C,
  title     = {Ms Pac-Man versus Ghost Team CEC 2011 Competition},
  author    = {Philipp Rohlfshagen and Simon Lucas},
  pages     = {70--77},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Games provide an ideal test bed for computational intelligence and significant
progress has been made in recent years, most notably in games such as Go,
where the level of play is now competitive with expert human play on smaller
boards. Recently, a significantly more complex class of games has received
increasing attention: real-time video games. These games pose many new
challenges, including strict time constraints, simultaneous moves and
open-endedness. Unlike in traditional board games, computational play is
generally unable to compete with human players.

One driving force in improving the overall performance of artificial
intelligence players are game competitions where practitioners may evaluate
and compare their methods against those submitted by others and possibly human
players as well. In this paper we introduce a new competition based on the
popular arcade video game Ms Pac-Man: Ms Pac-Man versus Ghost Team.

The competition, to be held at the Congress on Evolutionary Computation 2011
for the first time, allows participants to develop controllers for either the
Ms Pac-Man agent or for the Ghost Team and unlike previous Ms Pac-Man
competitions that relied on screen capture, the players now interface directly
with the game engine. In this paper we introduce the competition, including a
review of previous work as well as a discussion of several aspects regarding
the setting up of the game competition itself.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Artificial Bee Colony Algorithm I
@InProceedings{Junqing:2011:FJSSPBAHABCA,
  title     = {Flexible Job Shop Scheduling Problems By A Hybrid Artificial Bee Colony Algorithm},
  author    = {Li Junqing and Pan Quanke and Xie Shengxian},
  pages     = {78--83},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
In this paper, an effective artificial bee colony (ABC) algorithm is proposed
for solving the flexible job shop scheduling problems. The total flow time
criterion was considered. In the proposed algorithm, tabu search (TS)
heuristic is introduced to perform local search for employed bee, onlookers,
and scout bees. Meanwhile, an external Pareto archive set is employed to
record enough non-dominated solutions for the problem considered. Experimental
results on five well-known benchmarks show the efficiency of the proposed
hybrid algorithm. It is concluded that the proposed algorithm is superior to
the very recent algorithms in term of both search quality and computational
efficiency.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ozturk:2011:HABCAfNNT,
  title     = {Hybrid Artificial Bee Colony Algorithm for Neural Network Training},
  author    = {Celal Ozturk and Dervis Karaboga},
  pages     = {84--88},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
A hybrid algorithm combining Artificial Bee Colony (ABC) algorithm with
Levenberq-Marquardt (LM) algorithm is introduced to train artificial neural
networks (ANN). Training an ANN is an optimization task where the goal is to
find optimal weight set of the network in training process. Traditional
training algorithms might get stuck in local minima and the global search
techniques might catch global minima very slow. Therefore, hybrid models
combining global search algorithms and conventional techniques are employed to
train neural networks. In this work, ABC algorithm is hybridized with the LM
algorithm to apply training neural networks.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Akay:2011:WPOuABCA,
  title     = {Wavelet Packets Optimization using Artificial Bee Colony Algorithm},
  author    = {Bahriye Akay and Dervis Karaboga},
  pages     = {89--94},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
The increment in the sizes of the images by the technological advances
accompanies high demand for large capacities, high performance devices, high
bandwidths etc.,. Therefore, image compression techniques are essential to
reduce the computational or transmittal costs. Wavelet transform is one of the
compression techniques especially used for images and multimedia files. In
wavelet transform, approximation and detail coefficients are extracted from
the signal by filtering. Both approximation and detail coefficients are
re-decomposed up to some level to increase frequency resolution. Once
coefficients are generated, the optimum threshold values are determined to
obtain the best reconstructed image, which can be considered as an
optimization task. In this study, Artificial Bee Colony algorithm which is a
recent and successful optimization tool is used to determine the thresholds to
produce the best compressed image in terms of both compression ratio and
quality.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ozcan:2011:AHABoABCAfRSSO,
  title     = {A Heuristic Approach Based on Artificial Bee Colony Algorithm for Retail Shelf Space Optimization},
  author    = {Tuncay Ozcan and Sakir Esnaf},
  pages     = {95--101},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Due to high product variety and changing consumer demands, shelf space is one
of the most scarce resources in retail management. At this point, the
efficient allocation of the limited shelf space carries critical importance
for maximizing the financial performance. On the other hand, because of
NP-Hard nature of the shelf space allocation problem, heuristic approaches are
required to solve real world problems. In this paper, different from existing
studies in the literature, a heuristic approach based on artificial bee colony
algorithm is presented for shelf space allocation problem by using a model
which considers the space and cross elasticity.  In order to demonstrate the
efficiency of the developed approach, another heuristic approach based on
particle swarm optimization is proposed. The performance analysis of these
approaches is realized with problem instances including different number of
products, shelves and categories. Experimental results show that the developed
artificial bee colony algorithm is efficient methodology through near-optimal
solutions and reasonable solving time for large sized shelf space allocation
problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Real World Applications I
@InProceedings{Aldridge:2011:IRoDSIvGA,
  title     = {Improved Reconstruction of Deep Space Images via Genetic Algorithms},
  author    = {Shawn Aldridge and Brendan Babb and Frank Moore and Michael Peterson},
  pages     = {102--109},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Real-world applications, Engineering applications, Genetic algorithms},
  abstract  = {
Most of the images transmitted from deep space probes to Earth are subject to
lossy compression. Recent NASA missions (such as Mars rovers Spirit and
Opportunity) have used the ICER progressive wavelet image compressor to
achieve state-of-the-art compression performance. The purpose of the research
described in this paper was to demonstrate that it is possible to evolve
wavelet and scaling numbers describing novel transforms that outperform the
most commonly used ICER wavelet for the reconstruction of images of the
Martian landscape that had previously been subjected to lossy compression.
Because our technique only modifies the image reconstruction transform, it
requires no modification of deployed mission hardware.  We thus present a
technique to provide improved reconstruction of images received from existing
rover missions.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Yapicioglu:2011:DRUtGCiSFLP,
  title     = {Disservice Representation Using the Gini Coefficient in Semi-desirable Facility Location Problems},
  author    = {Haluk Yapicioglu and Alice E. Smith},
  pages     = {110--114},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Particle swarm optimization, Multiobjective optimization},
  abstract  = {
We consider various bi-objective models for the semi-desirable facility
location problem. In these models, the disservice caused by the facility is
traditionally measured by distance-related objective functions. In this study,
we modify the objective function representing the disservice using the Lorenz
curve and the Gini coefficient. Both of these concepts are widely used in the
economics literature to measure the discrepancy in wealth distribution within
a population. The use of the Gini coefficient enables us to measure how the
disservice caused by the facility varies across different Pareto optimal
solutions. We use a bi-objective particle swarm optimizer (bi-PSO) to compare
how the change in the objective function representing the disservice affects
the recommended location of the facility. Results suggest that some solutions
identified as "Pareto optimal" by traditional formulations are dominated by
other solutions when the Gini coefficient is used. Additionally, the use of
the Gini coefficient causes a change in the "optimal" location of a semi
desirable facility for some other instances. Results are discussed in detail
and directions for future work are provided.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Andres:2011:SFS,
  title     = {Self-Adaptive Fuzzy-Timed Systems},
  author    = {Cesar Andres and Luis Llana and Manuel Nunez},
  pages     = {115--122},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary fuzzy systems, Engineering applications, Evolutionary computation theory},
  abstract  = {
We consider the formal representation and analysis of systems with fuzzy-time
information. First, we present a formalism to represent specifications. This
model exploits the concepts of fuzzy set theory and uses a mathematical
framework to get a more flexible approach.

As it is usually assumed in industrial case studies, we consider that the
original requirements of the specification may change. The implementation is
built with respect to these changes but the specification is not upgraded.
Thus, it may be outdated. In order to continue using the formal framework, the
specification must be adapted with respect to these new requirements. We
consider that this update process should be as non-intrusive as possible, that
is, without using the source-code of the implementation. We present a novel
methodology for self-evolving fuzzy-time systems, without interacting with the
source code.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Evolutionary Robotics
@InProceedings{Espitia:2011:PpomrupfasoBp,
  title     = {Path planning of mobile robots using potential fields and swarms of Brownian particles},
  author    = {Helbert Espitia and Jorge Sofrony},
  pages     = {123--129},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Robotics},
  abstract  = {
This paper proposes an algorithm for trajectory planning based on the motion
of Brownian particles. One of the most popular approaches in path planning is
to use the artificial potential fields method which, due to its easiness in
implementation, might attract the robot towards a local minimum configuration,
thus preventing it from reaching the desired final destination. Although there
are different approaches to deal with this drawback, their modeling lacks the
simplicity of the potential fields, adding thus an extra complexity to the
problem. The solution proposed here combines the strengths of both approaches:
it is easy to analyze and to implement, just like in the potentials method,
while it preserves the robustness against local minima of more complex
particle swarm models. An approximate analysis for the deterministic version
of the selected model was performed and it was observed, via simulations, that
the results obtained after this simplification were consistent with the
behavior of the stochastic system.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Gong:2011:MPSOfOSLoM,
  title     = {Modified Particle Swarm Optimization for Odor Source Localization of Multi-robot},
  author    = {Dun-wei Gong and Cheng-liang Qi and Yong Zhang and Ming Li},
  pages     = {130--136},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Robotics},
  abstract  = {
Odor source localization is very important in real-world applications. We
studied the problem of odor source localization and presented a modified
particle swarm optimization algorithm for odor source localization of multi-
robot. The algorithm dynamically adjusts two learning factors in the velocity
update equation based on the effect of wind on self-cognition and social
cognition of a particle. In addition, an artificial potential field method is
employed to improve the performance of our algorithm. We conducted various
experiments in time-varying environments, and the experimental results confirm
the superiority of our algorithm.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Hiruma:2011:EaERTG,
  title     = {Evolving an Effective Robot Tour Guide},
  author    = {Hideru Hiruma and Alex Fukunaga and Kazuki Komiya and Hitoshi Iba},
  pages     = {137--144},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary Robotics, Robotics, Emerging areas},
  abstract  = {
Guiding visitors through an exhibit space such as a museum is an
  important, early application for mobile robots, and commercial
  robots designed for this purpose have become available.  We consider
  the problem of using a single mobile robot to simultaneously direct
  multiple groups of visitors through a museum or exhibition, and formulate
an objective function for this task.
  We show
  that an evolutionary robotics approach using a simple, low-fidelity simulator
and genetic programming can
  automatically generate robot controllers which can
  perform this task better than hand-coded controllers as well as humans in both
simulation and on a real robot.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Jennings:2011:PBOfVOP,
  title     = {Population Based Optimization for Variable Operating Points},
  author    = {Alan Jennings and Raul Ordonez},
  pages     = {145--151},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Numerical optimization., Intelligent systems applications, Robotics},
  abstract  = {
Finding optimal inputs for a multiple input, single output system is taxing
for an system operator. This work presents a population-based optimization to
create sets of functions to approximate a locally optimal input as an operator
selects an output. Output and cost functions are modeled by neural networks.
Neural network gradients are used to optimize a population of agents by
minimizing the cost for the agent's current output. When an agent reaches an
optimal input for its current output, additional agents are generated to step
in the output gradient directions. The agent then settles to the local optimum
for the new output value. The set of associated optimal points forms a inverse
function, via spline interpolation, from a desired output to an optimal input.
In this manner, a locally optimal function is created for each settled agent.
These functions are naturally clustered in input and output spaces allowing
for a continuous optimal function. The best cluster over the anticipated range
of desired outputs can be chosen and the process optimized on-the-fly to
respond to different set points. Results are shown for a diverse set of
functions.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Jeong:2011:PSOCPGfRFL,
  title     = {Particle Swarm Optimization-based Central Patter Generator for Robotic Fish Locomotion},
  author    = {In-Bae Jeong and Chang-Soo Park and Ki-In Na and Seungbeom Han and Jong-Hwan Kim},
  pages     = {152--157},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary Robotics, Particle swarm optimization, Robotics},
  abstract  = {
This paper proposes particle swarm optimizationbased central pattern generator
(CPG) to generate rhythmic signals for fish-like locomotion of robotic fish.
The robotic fish's wave form approximates fish's traveling wave. Since each
joint angle of the robotic fish is modeled by a periodic function, it can be
easily produced by a CPG. A CPG consists of biological neural oscillators,
which can produce coordinated rhythmic signals by using simple input signals.
The proposed CPG uses a neural oscillator for each joint of a robotic fish. To
optimize the parameters of the CPG which determine the output signals,
particle swam optimization (PSO) is employed. The effectiveness of the
proposed CPG is demonstrated by computer simulation and real experiment with
the robotic fish Fibo, developed in the Robot Intelligence Technology Lab.,
KAIST.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Algorithmic Innovations in Evolution Strategies
@InProceedings{Cuccu:2011:NRfES,
  title     = {Novelty-Based Restarts for Evolution Strategies},
  author    = {Giuseppe Cuccu and Faustino Gomez and Tobias Glasmachers},
  pages     = {158--163},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolution strategies},
  abstract  = {
A major limitation in applying evolution strategies to black box
  optimization is the possibility of convergence into bad local
  optima. Many techniques address this problem, mostly through
  restarting the search. However, deciding the new start location is
  nontrivial since neither a good location nor a good scale for
  sampling a random restart position are known. A black box search
  algorithm can nonetheless obtain some information about this
  location and scale from past exploration.
  The method proposed here makes explicit use of such experience,
  through the construction of an archive of {$\backslash$}emph\{novel solutions\}
  during the run. Upon convergence, the most ``novel'' individual
  found so far is used to position the new start in the least
  explored region of the search space, actively looking for a new
  basin of attraction.
  We demonstrate the working principle of the method on two
  multi-modal test problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Fukushima:2011:PoDENES,
  title     = {Proposal of Distance-weighted Exponential Natural Evolution Strategies},
  author    = {Nobusumi Fukushima and Yuichi Nagata and Shigenobu Kobayashi and Isao Ono},
  pages     = {164--171},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Numerical optimization., Evolution strategies},
  abstract  = {
This paper presents a new evolutionary algorithm for function optimization
named the distance-weighted exponential natural evolution strategies (DX-NES).
DX-NES remedies two problems of a conventional method, the exponential natural
evolution strategies (xNES), that shows good performance when it does not need
to move the distribution for sampling individuals down the slope to the
optimal point. The first problem of xNES is that the search efficiency
deteriorates while the distribution moves down the slope of an ill-scaled
function because it degenerates before reaching the optimal point. The second
problem is that the settings of learning rates are inappropriate because they
do not taking account of some factors affecting the estimate accuracy of the
natural gradient. We compared the performance of DX-NES with that of xNES and
CMA-ES on typical benchmark functions and confirmed that DX-NES outperformed
the xNES on all the benchmark functions and that DX-NES showed better
performance than CMA-ES on the almost all functions except the k-tablet
function.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Parkinson:2011:EtRPoOiEHfCOP,
  title     = {Estimating the Reproductive Potential of Offspring in Evolutionary Heuristics for Combinatorial Optimization Problems},
  author    = {Eddy Parkinson and Adam Ghandar and Zbigniew Michalewicz and Andrew Tuson},
  pages     = {172--178},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Heuristics, metaheuristics and hyper-heuristics, Evolution strategies, Genetic algorithms},
  abstract  = {
This paper proposes a metaheuristic selection technique for controlling the
progress of an evolutionary algorithm (and possibly other heuristic search
techniques) to manipulate and make use of the relationship between runtime and
solution quality. The paper examines the idea that very rapid increases in
initial fitness may lead to premature convergence and a reported solution that
is less than optimal. We examine the advantages provided by this metaheuristic
selection technique in solving two different combinatorial optimization
problems: including a ``toy" problem of finding magic squares and a more
realistic vehicle routing problem (VRP) benchmark. The method is found to be
useful for finding both higher quality solutions with a marginally longer
algorithm run time and for obtaining lower quality solutions in a shorter
time. Furthermore, the impact on the search results is similar for both the
magic square and the VRP problem providing evidence the method is scalable to
other problem domains, and therefore is potentially a relatively straight
forward addition to many heuristic approaches that can add value by improving
both runtime and solution quality.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Uchitane:2011:AEStBLLiR3SS,
  title     = {Applying Evolution Strategies to Biped Locomotion Learning in RoboCup 3D Soccer Simulation},
  author    = {Takeshi Uchitane and Toshiharu Hatanaka},
  pages     = {179--185},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Robotics, Evolution strategies, Evolutionary Robotics},
  abstract  = {
This paper addresses parameter tuning methods for bipedal locomotion of a
humanoid model in the RoboCup 3D Soccer Simulation environment. A gait pattern
of this humanoid is generated by a desired foot trajectory, joint control
systems and nonlinear oscillators. To build a good gait pattern, the
parameters of the walking system should be adjusted suitably. In this paper, a
usage of evolution strategies that is depending on only a performance
evaluation of the robot, is considered  for adjusting the parameters. We apply
two type evolution strategies in order to tune the parameters. The one is an
evolution strategy with mask operation where the portion of individual to
avoid mutation. The other is a covariance matrix adaptation evolution
strategy. Numerical simulation studies are carried out to evaluate the
performance of the proposed approaches by using the RoboCup 3D Soccer
Simulator.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Session: Evolutionary Computation in Finance Decision Making
@InProceedings{Krause:2011:Poetswddf,
  title     = {Performance of evolving trading strategies with different discount factors},
  author    = {Andreas Krause},
  pages     = {186--191},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Finance and economics},
  abstract  = {
We use a model of evolving trading strategies based on the idea of minority
games in which traders continuously evaluate a complete set of trading
strategies with different memory lengths using the strategies' past
performance, weighted by a discount factor, and choose the strategy with the
best past performance. Based on the chosen trading strategy they determine
their prediction of the movement of each individual asset for the following
time period.  We find empirically using stocks from the SP500 that our
prediction model yields a success rate and trading return that is increasing
the smaller the discount factor becomes. We hypothesize that this result is
driven by the existence of complex patterns of returns that are constantly
changing and thus cannot be captured by relying on long-lasting experiences or
static trading strategies.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lohpetch:2011:MAfFTMOS,
  title     = {Multiobjective Algorithms for Financial Trading Multiobjective Out-trades Single-Objective},
  author    = {Dome Lohpetch and David Corne},
  pages     = {192--199},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Finance and economics, Multiobjective optimization},
  abstract  = {
Genetic programming (GP) is increasingly investigated in finance and
economics. One area of study is its use to discover effective rules for
technical trading in the context of a portfolio of equities (or an index).
Early work used GP to find rules that were profitable, but were outperformed
by the simple buy and hold strategy. Attempts since then report similar
findings, except a handful of cases where GP has been found to outperform BH.
Recent work has clarified that robust outperformance of BH depends on, mainly,
the adoption of a relatively infrequent trading strategy (e.g. monthly), as
well as a range of other factors. Here we add a comprehensive study of
multiobjective approaches to this investigation, and find that multiobjective
strategies provide even more robustness in outperforming BH, even in the
context of more frequent (e.g. weekly) trading decisions.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Palotti:2011:ADCwGP,
  title     = {Assessing Documents' Credibility with Genetic Programming},
  author    = {Joao Palotti and Thiago Salles and Gisele L. Pappa and Marcos A. Goncalves and Wagner {Meira, Jr.}},
  pages     = {200--207},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming, Classification, clustering, data analysis and data mining},
  abstract  = {
The concept of example credibility evaluates how much a classifier can trust
an example when building a classification model. It is given by a credibility
function, estimated according to a series of factors that influence the
credibility of the examples, and is context- dependent. Here we deal with
automatic document classification, and study the credibility of a document
according to three factors: content, authorship and citations. We propose a
genetic programming algorithm to estimate the credibility of training
examples, which is then added to a credibility-aware classifier. For that, we
model the authorship and citation data as a complex network, and select a set
of structural metrics that can be used to estimate credibility. These metrics
are then merged with other content-related ones, and used as terminals for the
GP. The GP was tested in a subset of the ACM-DL, and results showed that the
credibility-aware classifier obtained results of micro and macroF\_1 from 5\%
to 8\% better than the traditional classifiers.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Session: Hardware Aspects of Bio-Inspired Architectures and Systems
@InProceedings{Qadir:2011:HafaBHPPAM,
  title     = {Hardware architecture for a Bidirectional Hetero-Associative Protein Processing Associative Memory},
  author    = {Omer Qadir and Jerry Liu and Gianluca Tempesti and Jon Timmis and Andy Tyrrell},
  pages     = {208--215},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolvable hardware and software},
  abstract  = {
This paper details an extension to an architecture for robust bidirectional
hetero-associative recall. Our proposed Protein Processor Associative Memory
(PPAM) is fundamentally different from the traditional processing methods
which use arithmetic operations and consequently Arithmetic and Logic Units
(ALUs). In this paper, we improve on our initial work addressing concerns
surrounding hardware implementation. We present the improved computational
architecture, coupled with a corresponding hardware architecture for
implementation. Results of applying the hardware implementation on a small
dataset are included, along with reports from synthesis tools about hardware
utilisation.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Heinrich:2011:LftBOASABLHA,
  title     = {Learning from the Barn Owl Auditory System: A Bio-Inspired Localization Hardware Architecture},
  author    = {Enrico Heinrich and Ralf Joost and Ralf Salomon},
  pages     = {216--221},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications},
  abstract  = {
Normally, research on evolutionary computation applies its algorithms to the
solution or optimization of some technical or mathematical problems. But for
some technical tasks, such as localization, nature seem to provides optimal
solutions. This paper discusses how the barn owl auditory system can be
conceptually realized on a digital system, such as a fieldprogrammable gate
array. This adapted system yields a time resolution as small as 20 ps, even
though it is clocked at only 85 MHz, which corresponds to a duty cycle of
about 12 ns. The system achieves this result by copying the natural role
model's core principles, i.e., employing a large number of simple, slowly
operating processing elements, which are all connected to two passive wires,
which induce only a very small additional time delay; these properties are the
result of a natural evolutionary process that has taken millions of years.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Papa:2011:OOBSSfSI,
  title     = {Optimal On-Line Built-In Self-Test Structure for System-Reliability Improvement},
  author    = {Gregor Papa and Tomasz Garbolino},
  pages     = {222--229},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
This paper presents a bio-inspired technique for the generation of a
deterministic test pattern generator. In contrast to conventional methods, the
proposed evolutionary-based approach reduces the gate count of a built-in
self-test structure, which is used for the automatic fault detection. The
reduced-gate-count structure is needed to achieve the test structure with a
smaller hardware area overhead, while still satisfying the reliability
constraints. The presented optimization approach searches concurrently for the
optimal combination of the register cells structure, the test patterns order
in the generated test sequence, and the bit order of the test patterns. A
comparison of the results with similar studies shows the efficiency of the
proposed evolutionary approach, which is therefore very useful in the design
of robust and fault-tolerant systems, while maintaining the minimum size of
the hardware overhead.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Gomez-Zamorano:2011:AFDCAoaFPGAfSSS,
  title     = {A Flexible Decentralised Communication Architecture on a Field Programmable Gate Array for Swarm System Simulations},
  author    = {Antonio Gomez Zamorano and Jon Timmis and Andy Tyrrell},
  pages     = {230--237},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolvable hardware and software},
  abstract  = {
Swarm systems consist of a number of relatively simple agents that interact
with each other to afford a complex behaviour. Such swarm systems are
inherently parallel but as yet little work has focussed on the development of
specific hardware platforms that might take advantage of such parallelism.
This paper proposes a hardware platform for the implementation of swarm system
simulations, using a case study of Reynolds' boids. Our platform provides a
flexible decentralised intelligent bus communication architecture designed to
provide effective communication between agents on a hardware platform.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Evolutionary Computer Vision I
@InProceedings{Atkins:2011:ADIGPAtAFEfIC,
  title     = {A Domain Independent Genetic Programming Approach to Automatic Feature Extraction for Image Classification},
  author    = {Daniel Atkins and Kourosh Neshatian and Mengjie Zhang},
  pages     = {238--245},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming},
  abstract  = {
In this paper we explore the application of Genetic Programming (GP) to the
problem of domain-independent image feature extraction and classification. We
propose a new GP-based image classification system that extracts image
features autonomously, and compare its performance against a baseline GP-based
classifier system that uses human-extracted features. We found that the
proposed system has a similar performance to the baseline system, and that GP
is capable of evolving a single program that can both extract useful features
and use those features to classify an image.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Mahdi:2011:EDUCDPSOiNI,
  title     = {Edge Detection Using Constrained Discrete Particle Swarm Optimisation in Noisy Images},
  author    = {Setayesh Mahdi and Zhang Mengjie and Johnston Mark},
  pages     = {246--253},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization},
  abstract  = {
Edge detection algorithms often produce broken edges, especially in noisy
mages. We propose an algorithm based on discrete particle swarm optimisation
(PSO) to detect continuous edges in noisy images. A constrained PSO-based
algorithm with a new objective function is proposed to address noise and
reduce broken edges. The localisation accuracy of the new algorithm is
compared with that of a modified version of the Canny algorithm as a
Gaussian-based edge detector, the robust rank order (RRO)-based algorithm as a
statistical based edge detector, and our previously developed PSO-based
algorithm. Pratt's figure of merit is used as a measure of localisation
accuracy for these edge detection algorithms. Experimental results show that
the performance of the new algorithm is higher than the Canny and RRO
algorithms in the images corrupted by two different types of noise (impulsive
and Gaussian noise). The new algorithm also detects edges more accurately and
smoothly than our previously developed algorithm in noisy images.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Fu:2011:GPFEDAGA,
  title     = {Genetic Programming For Edge Detection: A Global Approach},
  author    = {Wenlong Fu and Mark Johnston and Mengjie Zhang},
  pages     = {254--261},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming},
  abstract  = {
Edge detection is an important task in computer vision.  This paper describes
a global approach to edge detection using genetic programming (GP).  Unlike
most traditional edge detection methods which use local window filters, this
approach directly uses an entire image as input and classifies pixels directly
as edges or non-edges without preprocessing or postprocessing. Shifting
operations and common standard operators are used to form the function set.
Precision, recall and true negative rate are used to construct the fitness
functions.  This approach is examined and compared with the Laplacian and
Sobel edge detectors on three sets of images providing edge detection problems
of varying difficulty. The results suggest that the detectors evolved by GP
outperform the Laplacian detector and compete with the Sobel detector in most
cases.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Wong:2011:ICUPSO,
  title     = {Image Clustering Using Particle Swarm Optimization},
  author    = {Man Wong and Xiangjian He and Wei-chang Yeh},
  pages     = {262--268},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
This paper proposes an image clustering algorithm using particle swarm
optimization (PSO) with two improved fitness functions. The PSO clustering
algorithm can be used to find centroids of a user specified number of
clusters. Two new fitness functions are proposed in this paper. The PSO-based
image clustering algorithm with the proposed fitness functions is compared to
K-means clustering. Experimental results show that the PSO-based image
clustering approach, using the improved fitness functions, can perform better
than K-means by generating more compact clusters and larger inter-cluster
seperation.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Vasicek:2011:EDoRNIF,
  title     = {Evolutionary Design of Robust Noise-Specific Image Filters},
  author    = {Zdenek Vasicek and Michal Bidlo},
  pages     = {269--276},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Evolutionary design has shown as a powerful technique in solving various
engineering problems. One of the areas in which this approach succeeds is
digital image processing. Impulse noise represents a basic type of non-linear
noise typically affecting a single pixel in different regions of the image. In
order to eliminate this type noise median filters have usually been applied.
However, for higher noise intensity or wide range of the noise values this
approach leads to corrupting non-noise pixels as well which results in images
that are smudged or lose some details after the filtering process. Therefore,
advanced filtering techniques have been developed including a concept of noise
detection or iterative filtering algorithms. In case of the high noise
intensity, a single filtering step is insufficient to eliminate the noise and
obtain a reasonable quality of the filtered image. Therefore, iterative
filters have been introduced. In this paper we apply an evolutionary algorithm
combined with Cartesian Genetic Programing representation to design image
filters for the impulse noise that are able to compete with some of the best
conventionally used iterative filters. We consider the concept of noise
detection to be designed together with the filter itself by means of the
evolutionary algorithm. Finally, it will be shown that if the evolved filter
is applied iteratively on the filtered image, a high-quality results can be
obtained utilizing lower computational effort of the filtering process in
comparison with the conventional iterative filters.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Computational Intelligence in Bioinformatics and Computational Biology I
@InProceedings{Kamath:2011:AEAfFGEPR,
  title     = {An Evolutionary-based Approach for Feature Generation:  Eukaryotic Promoter Recognition},
  author    = {Uday Kamath and Kenneth {De Jong} and Amarda Shehu},
  pages     = {277--284},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming, Biometrics, bioinformatics and biomedical applications},
  abstract  = {
Prediction of promoter regions continues to be a challenging subproblem in
mapping out eukaryotic DNA. While this task is key to understanding the
regulation of differential transcription, the gene-specific architecture of
promoter sequences does not readily lend itself to general strategies.

To date, the best approaches are based on Support Vector Machines (SVMs) that
employ standard "spectrum" features and achieve promoter region classification
accuracies from a low of 84\% to a high of 94\% depending on the particular
species involved.  In this paper, we propose a general and powerful
methodology that uses Genetic Programming (GP) techniques to generate more
complex and more gene-specific features to be used with a standard SVM for
promoter region identification.

We evaluate our methodology on three data sets from different species and
observe consistent classification accuracies in the 94-95\% range. In
addition, because the GP-generated features are gene-specific, they can be
used by biologists to advance their understanding of the architecture of
eukaryotic promoter regions.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Becker:2011:DoFTNwASoPP,
  title     = {Design of Fault Tolerant Networks with Agent-based Simulation of Physarum Polycephalum},
  author    = {Matthias Becker},
  pages     = {285--291},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary computation theory, Intelligent systems applications,},
  abstract  = {
In this work we evaluate slime mold inspired algorithms, that gained a lot of
attention in renowned journals recently, for their ability to construct fault
tolerant connection networks. Previous work experiments with a real slime mold
Physarum Polycephalum as well as computer simulations based on a tube model in
order to construct a fault tolerant and efficient transport network for the
Tokyo rail system [1] showed, that networks have been found that are similar
to the existing rail system of Tokyo, however the quality of the solutions of
the real slime mold show big variations, and the tubular computer simulation
does not seem to reproduce the natural slime mold very well, since the
constructed networks of the simulated slime mold show heavy dependence of one
simulation parameter. Thus in our work we present an agent based simulation
approach for construction of fault tolerant connection networks for the Tokyo
rail system using the agent based simulation of Physarum Polycephalum.
Analysis of the results show that the agent based simulation reproduces the
variance in the behavior of the natural slime mold much better. Analysing the
cost benefit ratio of bio-inspired network construction we however conclude
that it might be worth to consider classical efficient computational
algorithms for the problem of constructing minimal fault tolerant networks.
Index Terms--slime mold; physarum polycephalum;nature inspired algorithms
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ghaffarizadeh:2011:SUPbRuMEAwVSI,
  title     = {Sorting Unsigned Permutations by Reversals using Multi-Objective Evolutionary Algorithms with Variable Size Individuals},
  author    = {Ahmadreza Ghaffarizadeh and Kamilia Ahmadi and Nicholas S. Flann},
  pages     = {292--295},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Genetic algorithms},
  abstract  = {
Sorting by reversals is a simplified version of the genome rearrangement
problem that seeks to discover the evolutionary relationship between different
genomes, and is one of the many challenging problems in Bioinformatics.
Solving the problem optimally has been proved to be NP-Hard and so a selection
of approximation algorithms have been developed. In this paper a new mapping
order is introduced to solve the problem of sorting unsigned permutations
using a specialized multi- objective genetic algorithm. Our modified genetic
algorithm uses a population with variable length individuals to maintain a
worst time running time complexity of O(n4 log2 n); where n is the problem
size. The results show that this approach is more effective than the 3=2
heuristic method and previous genetic algorithm approaches.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: EC on Many-core Architecture to Solve Large-scale Problems I
@InProceedings{Sato:2011:GAfSSwGO,
  title     = {GPU Acceleration for Sudoku Solution with Genetic Operations},
  author    = {Yuji Sato and Naohiro Hasegawa and Mikiko Sato},
  pages     = {296--303},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Parallel and distributed algorithms, Real-world applications},
  abstract  = {
In this paper, we use the problem of solving Sudoku puzzles to demonstrate the
possibility of achieving practical processing time through the use of GPUs for
parallel processing in the application of genetic computation to problems for
which the use of genetic computing has not been investigated before because of
the processing time problem. To increase accuracy, we propose a genetic
operation that takes building- block linkage into account. As a parallel
processing model for higher performance, we use a multiple- population
coarse-grained GA model to counter initial value dependence under the
condition of a limited number of individuals. Specifically, we show that it is
possible to reach a solution in a few seconds of processing time with a
correct solution rate of 100\%, even for extremely difficult problems by
parallel processing of genetic computation on a GeForce GTX 460, a commercial
GPU produced by the NVIDIA Corporation.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Garcia-Arenas:2011:Asiccssfdea,
  title     = {Assessing speed-ups in commodity cloud storage services for distributed evolutionary algorithms},
  author    = {Maribel Garcia-Arenas and Juan Julian Merelo and Antonio M. Mora and Pedro Castillo and Gustavo Romero},
  pages     = {304--311},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Parallel and distributed algorithms, Convergence, scalability and complexity analysis},
  abstract  = {
Cloud computing is lately becoming a part of the tool-set that the scientist
uses to perform compute-intensive tasks. In particular, cloud storage is an
easy and convenient way of storing files that will be accessible over the
Internet, but can also be used for distributing those files for performing
computation on them. In this paper we describe how such a service commercial-
ized by Dropbox is used for pool-based evolutionary algorithms. A prototype
system is described and its performance measured over deceptive combinatorial
optimization problems using two different substrates: WiFi and wired, finding
that, for some type of problems and using commodity hardware, cloud storage
systems can profitably be used as a platform for distributed evolutionary
algorithms; however, performance is influenced by the type of underlying
network. After introducing the method in a previous paper, in this paper we
focus on measuring this influence, finding that wired is faster than WiFi for
any number of nodes. We have also performed an experiment with a few more
computers to see whether speedup keeps up with the number of nodes.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Munetomo:2011:RRaSEAtEE,
  title     = {Realizing Robust and Scalable Evolutionary Algorithms toward Exascale Era},
  author    = {Masaharu Munetomo},
  pages     = {312--317},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Future trend of supercomputing goes toward exa flops, which is realized by
millions of cores expected to be installed on around 2018. Such massive
parallelism makes programming difficult. Inherent parallel nature of
evolutionary computation is a promising factor in designing optimization
algorithms that adapt to such massively parallel architecture although there
are some problems to be solved to realize robust algorithm that can analyze
complex interactions among genes. This paper discusses current status and
future trend in realizing robust and scalable evolutionary computation on such
extreme-scale supercomputers.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Munawar:2011:AGAtsMpoG,
  title     = {Advanced Genetic Algorithm to solve MINLP problems over GPU},
  author    = {Asim Munawar and Mohamed Wahib and Masaharu Munetomo and Kiyoshi Akama},
  pages     = {318--325},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
In this paper we propose a many-core implementation of evolutionary
computation for GPGPU (General-Purpose Graphic Processing Unit) to solve
non-convex Mixed Integer Non-Linear Programming (MINLP) and non-convex Non
Linear Programming (NLP) problems using a stochastic algorithm. Stochastic
algorithms being random in their behavior are difficult to implement over GPU
like architectures. In this paper we not only succeed in implementation of a
stochastic algorithm over GPU but show considerable speedups over CPU
implementations. The stochastic algorithm considered for this paper is an
adaptive resolution approach to genetic algorithm (arGA), developed by the
authors of this paper. The technique uses the entropy measure of each variable
to adjust the intensity of the genetic search around promising individuals.
Performance is further improved by hybridization with adaptive resolution
local search (arLS) operator. In this paper, we describe the challenges and
design choices involved in parallelization of this algorithm to solve complex
MINLPs over a commodity GPU using Compute Unified Device Architecture (CUDA)
programming model. Results section shows several numerical tests and
performance measurements obtained by running the algorithm over an nVidia
Fermi GPU. We show that for difficult problems we can obtain a speedup of up
to 20x with double precision and up to 42x with single precision.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Competition: The Physical Travelling Salesperson Problem

% Special Track: Artificial Bee Colony Algorithm II
@InProceedings{Okdem:2011:AAoWSNRboABCA,
  title     = {An Application of Wireless Sensor Network Routing based on Artificial Bee Colony Algorithm},
  author    = {Selcuk Okdem and Dervis Karaboga and Celal Ozturk},
  pages     = {326--330},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Reliable communication and effective routing methods are required for Wireless
Sensor Network (WSN) structures having many application areas such as
military, medical, meteorology, and geology. In this paper, the performance of
Artificial Bee Colony Algorithm (ABC) on routing operations in WSNs is
studied. Obtained performance result shows that the used protocol provides
longer network life time by saving more energy. Complexity analysis of
cluster-based routing strategy using ABC algorithm is made. Performance and
analysis results approve that ABC algorithm presents promising solutions on
WSN routings.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Garro:2011:ANNSbmoABCAA,
  title     = {Artificial Neural Network Synthesis by means of Artificial Bee Colony (ABC) Algorithm},
  author    = {Beatriz A Garro and Humberto Sossa and Roberto A Vazquez},
  pages     = {331--338},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Artificial bee colony (ABC) algorithm has been used in several optimization
problems, including the optimization of synaptic weights from an Artificial
Neural Network (ANN). However, this is not enough to generate a robust ANN.
For that reason, some authors have proposed methodologies based on so-called
metaheuristics that automatically allow designing an ANN, taking into account
not only the optimization of the synaptic weights as well as the ANN's
architecture, and the transfer function of each neuron. However, those
methodologies do not generate a reduced design (synthesis) of the ANN. In this
paper, we present an ABC based methodology, that maximizes its accuracy and
minimizes the number of connections of an ANN by evolving at the same time the
synaptic weights, the ANN's architecture and the transfer functions of each
neuron. The methodology is tested with several pattern recognition problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Oner:2011:Ooucspwahabca,
  title     = {Optimization of university course scheduling problem with a hybrid artificial bee colony algorithm},
  author    = {Adalet Oner and Sel Ozcan and Derya Dengi},
  pages     = {339--346},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Numerical optimization., Discrete and combinatorial optimization.},
  abstract  = {
Course scheduling problem (CSP) is concerned with developing a timetable that
illustrates a number of courses assigned to the classrooms.  In this study, a
hybrid algorithm composed of a heuristic graph node coloring and artificial
bee colony algorithm (ABC) is proposed to solve CSP.  The study is one of the
few applications of ABC on discrete optimization problems and to our best
knowledge it is the first application on CSP.  A basic heuristic algorithm of
node coloring problem takes part initially to develop some feasible solutions
of CSP. Those feasible solutions correspond to the food sources in ABC
algorithm. The ABC is then is used to improve the feasible solutions. The
employed and onlooker bees are directed or controlled in a specific manner in
order to avoid the conflicts in the course timetable. Proposed solution
procedure is tested using real data from a university in Turkey. The
experimental results demonstrate that the proposed hybrid algorithm yields
efficient solutions
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Tasgetiren:2011:ADABCAFtELSP,
  title     = {A Discrete Artificial Bee Colony Algorithm For the Economic Lot Scheduling Problem},
  author    = {M. Fatih Tasgetiren and Onder Bulut and M. Murat Fadiloglu},
  pages     = {347--353},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Finance and economics},
  abstract  = {
In this study we present a discrete artificial bee colony (DABC) algorithm to
solve the economic lot scheduling problem (ELSP) under extended basic period
(EBP) approach and power-of-two (PoT) policy. In specific, our algorithm
provides a cyclic production schedule of n items to be produced on a single
machine such that the production cycle of each item is an integer multiple of
a fundamental cycle. All the integer multipliers are in the form of
power-of-two, and under EBP approach feasibility is guaranteed with a
constraint that checks if the items assigned in each period can be produced
within the length of the period.            For this problem, which is
NP-hard, our DABC algorithm employs a multi-chromosome solution representation
to encode power-of-two multipliers and the production positions separately.
Both feasible and infeasible solutions are maintained in the population
through the use of some sophisticated constraint handling methods. A variable
neighborhood search (VNS) algorithm is also fused into DABC algorithm to
further enhance the solution quality. The experimental results show that the
proposed algorithm is very competitive to the best performing algorithms from
the existing literature under the EBP and PoT policy
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Real World Applications II
@InProceedings{Mohamad-Ayob:2011:SHDOoHSPCfCS,
  title     = {Scenario-based Hydrodynamic Design Optimization of High Speed Planing Craft for Coastal Surveillance},
  author    = {Ahmad Faisal Mohamad Ayob and Tapabrata Ray and Warren Smith},
  pages     = {354--361},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Real-world applications, Engineering applications, Numerical optimization.},
  abstract  = {
In this paper, an optimization framework for the design of hard chine planing
craft is presented. The proposed framework consists of a surface information
retrieval module, a geometry manipulation module and an optimization module
backed by standard naval architectural performance estimation tools. Total
resistance comprising calm water resistance and added resistance in waves is
minimized subject to constraints on displacement and stability requirements.
Infeasibility Driven Evolutionary Algorithm (IDEA) is incorporated in the
optimization module. A scenario-based hydrodynamic optimization problem using
an example of United States Coast Guard (USCG) WPB-110ft vessel is presented
in this work. The concepts presented in this paper is an extension of the
works of [15] [16] where instead of only performing total resistance
minimization of high speed planing craft at a single operational speed, a set
of collective speed spanning over a predefined lifetime is illustrated. The
proposed framework is capable of generating the optimum hull form while at the
same time enabling a provision for ship designers to evaluate the candidate
designs' performance over various operating scenarios.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Wilcox:2011:SVMPwaRGGA,
  title     = {Solving Virtual Machine Packing with a Reordering Grouping Genetic Algorithm},
  author    = {David Wilcox and Andrew McNabb and Kevin Seppi},
  pages     = {362--369},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Real-world applications, Genetic algorithms},
  abstract  = {
We formally define multi-capacity bin packing, a generalization of
conventional bin packing, and develop an algorithm called Reordering Grouping
Genetic Algorithm (RGGA) to assign VMs to servers. We first test RGGA on
conventional bin packing problems and show that it yields excellent results
but much more efficiently. We then generate a multi-constraint test set, and
demonstrate the effectiveness of RGGA in this context. Lastly, we show the
applicability of RGGA in its desired context by using it to develop an
assignment of real virtual machines to servers.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Paiva-Tizzo:2011:ACoSWSUAwGA,
  title     = {Automatic Composition of Semantic Web Services Using A-Teams with Genetic Agents},
  author    = {Neil Paiva Tizzo and Juan Manuel Adan Coello and Eleri Cardozo},
  pages     = {370--377},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Real-world applications},
  abstract  = {
Automation of Web service composition is one of the most important problems in
Web service research area. There are numerous methods to achieve Web service
composition. This paper describes the use of Asynchronous Teams (A-Teams)
algorithm with genetic agents to compose semantic Web services. Specific
agents realize the composition of sequential, parallel and synchronization
control flow patterns. Other agents, based on genetic algorithms, perform the
crossover and mutation over these patterns. The composition is described
through semantic logic rules that take into account the input and output
parameters obtained from OWL-S files. The quality of the composition is also
evaluated. A system was implemented and typical test scenarios are also
presented.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Poladian:2011:AGMFMPOF,
  title     = {A Genotype-To-Phenotype Mapping For Microstructured Polymer Optical Fibres},
  author    = {Leon Poladian},
  pages     = {378--385},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Real-world applications, Multi-objective evolutionary algorithms, Representation and operators},
  abstract  = {
Although glass fibres are standard in long-distance telecommunications;
customised polymer microstructured optical fibres play a more significant role
in many diverse new short-distance applications. Our prototyping process
involves drilling an array of holes in a cylindrical preform. That preform is
subsequently heated and pulled into a narrow fibre. The size and position of
the holes create an effective refractive index profile, which in turn
determines the optical transmission properties of the fibre. In this paper, a
new variable-length genotype is introduced which controls the coordinates of
the centres of `potential' holes. The genotype-to-phenotype mapping carefully
determines which holes are `activated' and the final radius of each hole,
consistent with manufacturing constraints. Two manufacturing constraints are:
a minimum spacing between adjacent holes and that the drill bits are only
available in a discrete range of radii. A cross-over operator is designed that
works with variable-length genotypes and its effect on the distribution of
genome lengths is explored in detail. An implementation of NSGA-II is used to
perform a multi-objective optimisation with four objectives. One of these
objectives (wanting a parabolic index profile) is the same as in our previous
work. Two are new: minimising the deformability of the design and minimising
the detrimental effects of surface roughness. The final objective is not
optical but related to the efficiency of the GA and is to minimise the number
of inactive genes. The behaviour of the genetic algorithm and a number of
interesting designs are discussed.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Clustering and Data Mining I
@InProceedings{Veroneze:2011:AtPoaSBTfDI,
  title     = {Assessing the Performance of a Swarm-based Biclustering Technique for Data Imputation},
  author    = {Rosana Veroneze and Fabricio {de Franca} and Fernando J. {Von Zuben}},
  pages     = {386--393},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining, Data mining},
  abstract  = {
Although the missing data problem has been studied for many years, it is still
a relevant and challenging problem nowadays. Data can be missing for a variety
of reasons, and there are several techniques capable of processing missing
data. A parcel of them tries to estimate the missing values. This technique is
called imputation. Recently, it was proposed a biclustering algorithm, based
on Swarm Intelligence, named SwarmBCluster, to impute missing data. As it is a
novel and promising algorithm, this paper intends to investigate the influence
of its parameters on the performance. To achieve this objective, this paper
will compare SwarmBCluster with other two imputation algorithms and, after
that, it will perform a sensitivity analysis. The quality of the imputations
is measured with the Root Mean Squared Error (RMSE). The experiments showed
that SwarmBCluster presents good results concerning the RMSE metric and that
the proper choice of parameters can considerably improve the performance of
the algorithm.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Zhang:2011:ASSFRFuGC,
  title     = {A Sequential Subspace Face Recognition Framework using Genetic-based Clustering},
  author    = {Deng Zhang and Shingo Mabu and Feng Wen and Kotaro Hirasawa},
  pages     = {394--400},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Intelligent systems applications, Classification, clustering, data analysis and data mining},
  abstract  = {
Different from other classification problems, there are usually a large number
of classes in the face recognition. As a result, the recognition accuracy of
the traditional subspace face recognition algorithm is unsatisfactory. This
paper presents a sequential subspace face recognition framework using an
effective genetic-based clustering algorithm (GCA). Firstly, the facial
database is decomposed into a double layer database using a face recognition
oriented GCA. Then, the face recognition is realized by minimizing the
distance measures in a specific cluster as in the traditional subspace face
recognition algorithms. The contributions of this study are summarized as
follows: 1) The class, i.e., person is regarded as an element in the
clustering rather than an image. 2) The proposed GCA uses a novel distance to
measure the similarity between a class and the cluster centroids of different
clusters. 3) The proposed GCA uses a balance factor to achieve balanced
clustering results. Experimental results on the extended Yale-B database
indicate that the proposed sequential subspace face recognition framework has
higher accuracy compared with the traditional subspace methods and
K-mean+traditional subspace methods.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Dohare:2011:CoSMfTSCuGA,
  title     = {Combination of Similarity Measures for Time Series Classification using Genetic Algorithms},
  author    = {Deepti Dohare and V. Susheela Devi},
  pages     = {401--408},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Classification, clustering, data analysis and data mining, Data mining},
  abstract  = {
Time series classification deals with the problem of classification of data
that is multivariate in nature. This means that one or more of the attributes
is in the form of a sequence. The notion of similarity or distance, used in
time series data, is significant and affects the accuracy, time, and space
complexity of the classification algorithm. There exist numerous similarity
measures for time series data, but each of them has its own disadvantages.
Instead of relying upon a single similarity measure, our aim is to find the
near optimal solution to the classification problem by combining different
similarity measures. In this work, we use genetic algorithms to combine the
similarity measures so as to get the best performance. The weightage given to
different similarity measures evolves over a number of generations so as to
get the best combination. We test our approach on a number of benchmark time
series datasets and present promising results.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ahn:2011:EBFEwDM,
  title     = {Evolutionary Based Feature Extraction with Dynamic Mutation},
  author    = {Eun Yeong Ahn and Tracy Mullen and John Yen},
  pages     = {409--416},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining, Data mining, Genetic algorithms},
  abstract  = {
Determining a good feature set is critical to the performance of learning
algorithms such as classifiers. Recently,researchers have proposed
evolutionary- based feature extraction methods that aim to find a good feature
set by combining the original features with new features generated by
mathematical transformations of the original features. In this paper, we
propose dynamically collecting past performance information on promising
features and operators to use in our mutation method. We consider how to make
our evolutionary algorithm more reliable by reducing overfitting. Preliminary
results using UCI data show that our dynamic mutation method only slightly
enhances the classification accuracy but it produces more reliable results.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Evolvable Hardware and Software
@InProceedings{Gallagher:2011:AIEOfAFMCoaIFMAV,
  title     = {An Improved Evolvable Oscillator for All Flight Mode Control of an Insect-Scale Flapping-Wing Micro Air Vehicle},
  author    = {John Gallagher and Michael Oppenheimer},
  pages     = {417--425},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolvable hardware and software, Robotics, Defense and cyber security},
  abstract  = {
In previous work, we presented an adaptive evolvable oscillator that enables
online, in-flight, adaptation of a rigorous controller for hovering in an
insect-scale flapping- wing micro air vehicle based on the Harvard RoboFly.
That particular evolvable hardware oscillator, however, was a proof-
of-concept prototype and is incapable of supporting the types of signal
adaptation necessary to support on-line correction for other flight modes
(E.G. roll, pitch, forward translation, etc.). This paper introduces a new
oscillator design capable of supporting signal adaptation for all possible
flight modes of the vehicle. It will also present preliminary experimental
results demonstrating the adaptive oscillator to be capable of correcting for
vehicle faults in a two degree of freedom (2DOF) control task requiring
simultaneous regulation of vehicle altitude and roll. The paper will conclude
with discussion of application of this adaptive, evolvable oscillator to full
vehicle control.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Kijowski:2011:ILiaEHHCfaISFMAV,
  title     = {Improved Learning in an Evolvable Hardware Hover Controller for an Insect Scale Flapping-Wing Micro Air Vehicle},
  author    = {Matthew Kijowski and John Gallagher and Laurence Merkle},
  pages     = {426--431},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolvable hardware and software, Evolutionary Robotics, Engineering applications},
  abstract  = {
In previous work, a single Degree Of Freedom (DOF) controller for altitude of
a Flapping-Wing Micro Air Vehicle (FW-MAV) has been presented which meets the
various needs of such a device.  Unique challenges posed by the small size of
such a device include accounting for process variation during the
manufacturing of small scale wings and effectors, damage accumulation during
the operation of the device, as well as weight and power restrictions limiting
the computational power available on-board the device have been overcome with
a cycle-average controller which preserves mathematical rigor while still
allowing computational power for evolvable hardware on-board the device.  
This paper will describe an attempt to optimize altitude control learning
times on a controller which has been shown to support single DOF flight with
the intent to shorten learning times of a multiple DOF flight controller which
is much more computationally intense.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Li:2011:AEMOAtCSAD,
  title     = {An Evolutionary Multiobjective Optimization Approach to Component-Based Software Architecture Design},
  author    = {Rui Li and Ramin Etemaadi and Michael Emmerich and Michel Chaudron},
  pages     = {432--439},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolvable hardware and software, Representation and operators, Multiobjective optimization},
  abstract  = {
The design of software architecture is one of the difficult tasks in the
modern component-based software development which is based on the idea that
develop software systems by assembling appropriate off-the-shelf components
with a well-defined software architecture. Component-based software
development has achieved great success and been extensively applied to a large
range of application domains from realtime embedded systems to online
web-based applications. In contrast to traditional approaches, it requires
software architects to address a large number of non-functional requirements
that can be used to quantify the operation of system. Moreover, these quality
attributes can be in conflict with each other. In practice, software designers
try to come up with a set of different architectural designs and then identify
good architectures among them. With the increasing scale of architecture, this
process becomes time-consuming and error-prone. Consequently architects could
easily end up with some suboptimal designs because of large and combinatorial
search space. In this paper, we introduce AQOSA (Automated Quality-driven
Optimization of Software Architecture) toolkit, which integrates modeling
technologies, performance analysis techniques, and advanced evolutionary
multiobjective optimization algorithms (i.e. NSGA-II, SPEA2, and SMS-EMOA) to
improve non-functional properties of systems in an automated manner.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Bremner:2011:MOoCCE,
  title     = {Multi-Objective Optimisation of Cell-Array Circuit Evolution},
  author    = {Paul Bremner and Mohammad Samie and Anthony Pipe and Andy Tyrrell},
  pages     = {440--446},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Evolvable hardware and software, Genetic programming},
  abstract  = {
In this paper we have investigated the efficacy of applying multi-objective
optimisation to Cartesian genetic programming (CGP) when used for evolution of
cell-array configurations. A cell-array is a proposed type of custom FPGA,
where digital circuits can be formed from interconnected configurable cells;
thus, the CGP nodes are more complex than in its standard implementation. We
have described modifications to a previously described optimisation algorithm
that has led to significant improvements in performance; circuits close to a
hand designed equivalent have been found, in terms of the optimised
objectives. Additionally we have investigated the effect of circuit
decomposition techniques on evolutionary performance. We found that using a
hybrid of input and output decomposition techniques substantial reductions in
evolution time were observed. Further, while the number of circuit inputs is
the key factor for functional evolution time, the number of circuit outputs is
the key factor for optimisation time.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Workshop: Agent-Based Computational Economics and Finance I

% Session: Fitness Landscapes and Learning
@InProceedings{Kimura:2011:CMFOuaSEA,
  title     = {Constrained Multimodal Function Optimization using a Simple Evolutionary Algorithm},
  author    = {Shuhei Kimura and Koki Matsumura},
  pages     = {447--454},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Constraint and uncertainty handling, Genetic algorithms},
  abstract  = {
Practical function optimization problems often contain several constraints.
Although evolutionary algorithms (EAs) have been successfully applied to
unconstrained real-parameter optimization problems, it is sometimes difficult
for these methods even to find feasible solutions in constrained ones. In this
study, we thus propose a technique that makes EAs possible to solve function
optimization problems with several inequality and a single equality
constraints. The proposed technique simply forces individuals newly generated
to satisfy the equality constraint. In order to generate these individuals,
this study utilizes a Markov chain Monte Carlo (MCMC) method and crossover
kernels. While the proposed technique can be applied to any EA, this study
applies it to a relatively simple one, UNDX/MGG. Experimental results show
that UNDX/MGG with the proposed technique has an ability to solve unimodal and
multimodal function optimization problems with constraints. Finally, we show
that, although our approach cannot solve function optimization problems with
multiple equality constraints, we can convert some of them into those with a
single equality constraint.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Dobslaw:2011:IPL,
  title     = {Iteration-wise Parameter Learning},
  author    = {Felix Dobslaw},
  pages     = {455--462},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Self-adaptation in evolutionary computation, Genetic algorithms, Discrete and combinatorial optimization.},
  abstract  = {
Adjusting the control parameters of population-based algorithms is a means for
improving the quality of these algorithms' result when solving optimization
problems. The difficulty lies in determining when to assign individual values
to specific parameters during the run. This paper investigates the possible
implications of a generic and computationally cheap approach towards parameter
analysis for population-based algorithms. The effect of parameter settings was
analyzed in the application of a genetic algorithm to a set of traveling
salesman problem instances. The findings suggest that statistics about local
changes of a search from iteration i to iteration i+1 can provide valuable
insight into the sensitivity of the algorithm to parameter values. A simple
method for choosing static parameter settings has been shown to recommend
settings competitive to those extracted from a state-of-the-art parameter
tuner, paramILS, with major time and setup advantages.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Greenwood:2011:OtVoONiFL,
  title     = {On the Value of Operator-Induced Neighborhoods in Fitness  Landscapes},
  author    = {Garrison Greenwood},
  pages     = {463--467},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Discrete and combinatorial optimization.},
  abstract  = {
All of the solutions to a combinatorial optimization problem can be collected
into a fitness landscape. Often these landscapes are huge, making an
exhaustive search for the best solution impractical. Stochastic search
algorithms work best if the search operators are tailored to the fitness
landscape structure. Some researchers claim this structure is induced by the
search operator itself. In this paper we show structural information obtained
from operator-induced neighborhoods can be completely misleading unless
special ordering has prevailed during the mapping process and appropriate
isomorphic proofs have been made.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Doucette:2011:RtAhtAeoEEPSuaEGST,
  title     = {Revisiting the Acrobot `height' task: An example of Efficient Evolutionary Policy Search under an Episodic Goal Seeking Task},
  author    = {John Doucette and Malcolm Heywood},
  pages     = {468--475},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Adaptive dynamic programming and reinforcement learning, Coevolution and collective behavior, Genetic programming},
  abstract  = {
Evolutionary methods for addressing the temporal sequence learning problem
generally fall into policy search as opposed to value function optimization
approaches. Various recent results have made the claim that the policy search
approach is at best inefficient at solving episodic `goal seeking' tasks i.e.,
tasks under which the reward is limited to describing properties associated
with a successful outcome have no qualification for degrees of failure. This
work demonstrates that such a conclusion is due to a lack of diversity in the
training scenarios. We therefore return to the Acrobot `height' task domain
originally used to demonstrate complete failure in evolutionary policy search.
This time a very simple stochastic sampling heuristic for defining a
population of training configurations is introduced. Benchmarking two recent
evolutionary policy search algorithms -- Neural Evolution of Augmented
Topologies (NEAT) and Symbiotic Bid-Based (SBB) Genetic Programming -- under
this condition demonstrates solutions as effective as those returned by
advanced value function methods. Moreover this is achieved while remaining
within the evaluation limit imposed by the original study.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Mokom:2011:EoAC,
  title     = {Evolution of Artifact Capabilities},
  author    = {Felicitas Mokom and Ziad Kobti},
  pages     = {476--483},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Artificial ecology and artificial life, Autonomous mental and behavior development},
  abstract  = {
The subject of artifact or tool use is considered in many fields to be a vital
area of research in the study of general human competence. Recently in
artificial intelligence, formalizations of the mental attitudes of intentional
agents have been extended to include agent capabilities with respect to
artifacts or tools. We consider understanding how these individual
capabilities are learned and how they evolve as important steps towards
formally defining, representing and implementing complex group capabilities.
In this paper, a theoretical model for artifact capability is extended to
incorporate evolution and learning through exploratory methods. A
representation of artifacts and the cognition of a rational agent that can
learn artifact use are provided. Supervised learning is assumed and combined
with historical knowledge and genetic algorithms to provide an implementation
of a multi-agent simulation. The simulation is built to support an agent with
the ability to learn an artifact capability through observations of its own
behavior, as well as through observations of other agents in a social
environment. Results obtained from the simple yet practical approach, show
that learned use of artifacts outperforms random use and rational agents can
learn artifact use more efficiently as a social species than on their own.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Evolutionary Computer Vision II
@InProceedings{De-la-Fraga:2011:RDoSCoEwH,
  title     = {Robust Detection of Several Circles or Ellipses with Heuristics},
  author    = {Luis Gerardo {De la Fraga} and Gustavo M. Lopez Dominguez},
  pages     = {484--490},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
In this article we present a new approach to extract points that belongs to
several ellipses or circles presented on a same image and with the presence of
outliers. Each geometric form is extracted by means of a robust fitting, that
is a nonlinear optimization problem, solved with two different heuristics:
differential evolution and RANSAC. Once the geometric form is fitted, its
points are extracted by calculating their statistics. Several tests with
synthetic and real images are performed to show its effectiveness.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Nguyen:2011:TPwBFOS,
  title     = {Tracking Pedestrians with Bacterial Foraging Optimization Swarms},
  author    = {Hoang Thanh Nguyen and Bir Bhanu},
  pages     = {491--495},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Pedestrian tracking is an important problem with many practical applications
in fields such as security, animation, and human computer interaction (HCI).
In this paper, we introduce a previously-unexplored swarm intelligence
approach to multi-object monocular tracking by using Bacterial Foraging
Optimization (BFO) swarms to drive a novel part-based pedestrian appearance
tracker. We show that tracking a pedestrian by segmenting the body into parts
outperforms popular blob-based methods and that using BFO can improve
performance over traditional Particle Swarm Optimization and Particle Filter
methods.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Shi:2011:SMDbGP,
  title     = {Selective Motion Detection by Genetic Programming},
  author    = {Qiao Shi and Andy Song},
  pages     = {496--503},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming, Real-world applications},
  abstract  = {
Motion detection is a vital part of vision systems, either biological or
computerized. Conventional motion detection methods in machine vision can
differentiate moving objects from background, but cannot directly handle
different types of motions.  In this paper, we present Genetic Programming
(GP) as a method which not only removes relatively stationary background, but
also can be selective on what kind of motions to capture.  Programs can be
evolved to select a certain type of moving objects and ignore other motions. 
That is to select fast moving target and ignore slowing moving ones. 
Furthermore programs can be evolved to handle these tasks even when the camera
itself is in relatively arbitrary motion.  This general GP method does not
require additional process to differentiate various types of motions.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Geng:2011:ITCuaMGCA,
  title     = {Image Texture Classification using a Multiagent Genetic Clustering Algorithm},
  author    = {Jiulei Geng and Jing Liu},
  pages     = {504--508},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Based on texture features, we propose an unsupervised image classification
method by using a novel evolutionary clustering technique, namely multiagent
genetic clustering algorithm (MAGAc). In MAGAc, the clustering problem is
considered from an optimization viewpoint. Each agent is a matrix of real
numbers representing the cluster centers. Agents interact with others under
the pressure of environment to search the best partition of data. After
extracting texture features from an image, MAGAc determines the partition of
feature vectors using evolutionary search. In experiments, six UCI datasets
and four artificial textural images are used to test the performance of MAGAc.
The experimental results show that in terms of cluster quality, MAGAc
outperforms the K-means algorithm and a genetic algorithm-based clustering
technique.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Plenary Poster Session: Poster Session Monday
@InProceedings{Daneshyari:2011:DOuCbP,
  title     = {Dynamic Optimization using Cultural based PSO},
  author    = {Moayed Daneshyari and Gary Yen},
  pages     = {509--516},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Cultural algorithms, Dynamic and uncertain environments.},
  abstract  = {
Many practical optimization problems are with the existence of uncertainties,
among which a significant number belong to the dynamic optimization problem
(DOP) category in which the fitness function changes through time. In this
study, we propose the cultural based particle swarm optimization (PSO) to
solve DOP problems. A cultural framework is introduced that incorporates the
required information from the PSO into five sections of the belief space,
namely situational knowledge, temporal knowledge, domain knowledge, normative
knowledge and spatial knowledge. The stored information will be adopted to
detect the changes in the environment and assists response to the change
through a diversity based repulsion among particles and migration among swarms
in the population space, also helps in selecting the leading particles in
three different levels, personal, swarm and global level. Comparison of the
proposed cultural based dynamic PSO demonstrates the better or equal
performance with respect to other selected state-of-the-art dynamic PSO
heuristics.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Coelho:2011:Acfaatro,
  title     = {A chaotic firefly algorithm applied to reliability-redundancy optimization},
  author    = {Leandro Coelho and Diego Bernert and Viviana Mariani},
  pages     = {517--521},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Intelligent systems applications, Heuristics, metaheuristics and hyper-heuristics},
  abstract  = {
The reliability-redundancy allocation problem can be approached as a
mixed-integer programming problem. It has been solved by using optimization
techniques such as dynamic programming, integer programming, and mixed-integer
non-linear programming. On the other hand, a broad class of meta-heuristics
has been developed for reliability-redundancy optimization. Recently, a new
meta-heuristics called firefly algorithm (FA) algorithm has emerged. The FA is
a stochastic metaheuristic approach based on the idealized behavior of the
flashing characteristics of fireflies. In FA, the flashing light can be
formulated in such a way that it is associated with the objective function to
be optimized, which makes it possible to formulate the firefly algorithm. This
paper introduces a modified FA approach combined with chaotic sequences (FAC)
applied to reliability-redundancy optimization. In this context, an example of
mixed integer programming in reliability-redundancy design of an overspeed
protection system for a gas turbine is evaluated. In this application domain,
FAC was found to outperform the previously best-known solutions available.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Mariani:2011:Andeafeohtcdftbia,
  title     = {A normative differential evolution approach for estimation of heat transfer coefficient during freezing treatment by inverse analysis},
  author    = {Viviana Mariani and Luiz Guilherme Luvizotto and Carlos Klein and Leandro Coelho},
  pages     = {522--528},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Differential evolution, Engineering applications},
  abstract  = {
Among the existing meta-heuristic optimization algorithms, a well-known branch
is the differential evolution (DE). DE is a powerful population-based
algorithm of evolutionary computation field designed for solving global
optimization problems which only has a few control parameters. With an eye to
improve the performance of DE, in this paper, a DE approach combined with a
cultural algorithm technique based on normative knowledge (NDE) is
investigated to estimate the heat transfer coefficient during freezing
treatment by inverse analysis. Numerical results for inverse heat transfer
problem demonstrate the applicability and efficiency of the NDE algorithm. In
this application, NDE approach outperforms a classical DE approach in terms of
quality of solution.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{de-Armas:2011:TESfaMCSP,
  title     = {Two Encoding Schemes for a Multi-Objective Cutting Stock Problem},
  author    = {Jesica {de Armas} and Gara Miranda and Coromoto Leon},
  pages     = {529--536},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Representation and operators, Real-world applications},
  abstract  = {
This work presents a multi-objective approach to solve a Constrained
Guillotine Two-Dimensional Cutting Stock Problem. The single-objective
formulation of the problem has been widely studied in the related literature,
so a large number of heuristics, meta-heuristics, and exact algorithms have
been proposed in order to optimise the total profit obtainable from the
available surface. However, in some industries, where the material is cheap
enough or easily recycled, a faster generation of pieces and a minimum usage
of the machinery could be more decisive aspects in determining the efficiency
of the production process. For this reason, we have focused on a
multi-objective formulation of the problem which seeks to maximise the total
profit, as well as minimise the number of cuts to achieve the pieces. To solve
this multi-objective problem we have applied Multi-objective Optimisation
Evolutionary Algorithms given its great effectiveness with other types of
real-world multi-objective problems. For the application of this kind of
algorithms it has been necessary to define an encoding scheme which allows to
deal with the problem intrinsic features. In this case, we have defined two
encoding schemes which are based on a post-fix notation, thus simplifying the
representation of guillotine patterns. The first encoding scheme controls the
pieces included in the solution in order to generate valid builds. The second
one generates a full solution, including all the available pieces, although
the final values for the objectives are limited by the available surface. The
computational results demonstrate that, in both cases, the multi-objective
approach provides solutions with good compromise between the two objectives.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Vilela-Neto:2011:APEAtSfGMGoHaiAC,
  title     = {A Parallel Evolutionary Algorithm to Search for Global Minima Geometries of Heterogeneous ab initio Atomic Clusters},
  author    = {Omar Vilela Neto and Marco Aurelio Pacheco and Andre Pimentel and Enio Silveira},
  pages     = {537--543},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Emergent technologies, Real-world applications, Parallel and distributed algorithms},
  abstract  = {
In this work we present a parallel evolutionary algorithm applied to the
search of the lowest-energy structures of heterogeneous atomic clusters. A new
and improved crossover operator is proposed in order to always ensure the
creation of new clusters with the same number of atomic elements. The approach
proposed proved to be efficient and fast as all cluster calculations were
performed by an ab initio quantum mechanics method, which is computationally
expensive. Results of our search, obtained using the proposed approach, have
been compared with previous calculations, and the efficiency has been
confirmed, as we were able to find the global minimum and propose a wide
number of new isomers of low-energy. Specifically, we addressed the problem to
deal with clusters of lithium and fluorine atoms. However, the proposed
algorithm can be extended to all kind of atomic and molecular clusters.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Vilela-Neto:2011:EOoSoBFfFAbUDP,
  title     = {Evolutionary Optimization of Sets of Basis Functions for First-Row Atoms by Using Discretization Process},
  author    = {Omar Vilela Neto and Iury Bezerra and Marco Aurelio Pacheco and Andre Pimentel},
  pages     = {544--549},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Emergent technologies, Real-world applications, Numerical optimization.},
  abstract  = {
A parameter optimization of sets of basis functions by using two different
discretization process (improved generator coordinate Hartree-Fock (IGCHF) and
polynomial expansion) is proposed and evaluated for all first-row atoms. A
Genetic Algorithm is used to vary and find the exponents values for the sets
of basis functions that provide the lowest energies for all first-row atoms.
Most of the difficulties to the development of efficient basis functions are
related to the large number of exponents parameters to be optimized as well as
the nonlinear nature of these functions. Ground state Hartree-Fock
calculations for the first-row atoms using the new generated Gaussian basis
set are carried out to demonstrate the improvement offered by this
optimization technique. An improvement compared to the conventional
optimization was verified when the Genetic Algorithm was applied.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Green-II:2011:CFOoaGACSiHPMUMT,
  title     = {Central Force Optimization on a GPU: A Case Study in High Performance Metaheuristics Using Multiple Topologies},
  author    = {Robert {Green, II} and Lingfeng Wang and Mansoor Alam and Richard Formato},
  pages     = {550--557},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Parallel and distributed algorithms},
  abstract  = {
Central Force Optimization (CFO) is a powerful new metaheuristic algorithm
that has been demonstrated to be competitive with other metaheuristic
algorithms such as Genetic Algorithms (GA), Particle Swarm Optimization (PSO),
and Group Search Optimization (GSO). While CFO often shows superiority in
terms of functional evaluations and solution quality, the algorithm is complex
and often requires increased computational time. In order to decrease CFO's
computational time, we have implemented the concept of local neighborhoods and
implemented CFO on a Graphics Processing Unit (GPU) using the NVIDIA Compute
Unified Device Architecture (CUDA) extensions for C/C++. Two different
versions of CFO, Pseudo-Random CFO (PR-CFO) and Parameter Free CFO (PF-CFO),
are examined using four test problems ranging from 30 to 100 dimensions.
Results are compared and analyzed across four unique implementations of the
PR-CFO and PF-CFO algorithm: Standard, Ring, CUDA, and CUDA-Ring. Decreases in
computational time along with superiority in terms of solution quality are
demonstrated.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Liping:2011:GABoPaDTfSMBLP,
  title     = {Genetic Algorithm Based on Primal and Dual Theory for Solving Multiobjective Bilevel Linear Programming},
  author    = {Jia Liping and Wang Yuping},
  pages     = {558--565},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization},
  abstract  = {
The multiobjective bilevel linear  programming (MBLP) is a hierarchical
optimization problem involving two levels, and at least one level has multiple
objectives. This paper mainly studies a special kind of MBLP with one
objective at the lower level. With primal and dual theory, the lower level
problem is transformed into a part of constraints of the upper level problem,
then by handling the feasible set of the transformed problem, several
equivalent problems of MBLP are obtained. Furthermore, by designing  three
feasible genetic operators, a new genetic algorithm for solving MBLP is
presented. The simulations on several designed multiobjective bilevel linear
programming problems are made, and the performance of the proposed algorithm
is verified by comparing with the existing algorithms. The results show that
the proposed algorithm is effective for MBLP.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Rosberg:2011:StLUwACO,
  title     = {Solving the Light Up with Ant Colony Optimization},
  author    = {Igor Rosberg and Elizabeth Goldbarg and Marco Goldbarg},
  pages     = {566--573},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Ant colony optimization, Games, Discrete and combinatorial optimization.},
  abstract  = {
A number of single-player games have been proven to be computationally
difficult, including the Light Up. Although, recently, such single-player
games have received considerable attention from the scientific community, only
a few papers address the Light Up.  This paper presents a two phase Ant Colony
Optimization algorithm to solve this puzzle. In the first phase, logical rules
are applied to the game grid in order to restrict the space searched by the
algorithm in the second phase. The approach was applied to thirty-two game
instances with grids ranging from 7x7 to 40x30 solving them efficiently.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Rivero:2011:ANSCTbMoGAak,
  title     = {A New Signal Classification Technique by Means of Genetic Algorithms and kNN},
  author    = {Daniel Rivero and Enrique Fernandez-Blanco and Julian Dorado and Alejandro Pazos},
  pages     = {574--579},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining, Real-world applications, Genetic algorithms},
  abstract  = {
Signal classification is based on the extraction of several features that will
be used as inputs of a classifier. The selection of these features is one of
the most crucial parts, because they will design the search space, and,
therefore, will determine the difficult of the classification. Usually, these
features are selected by using some prior knowledge about the signals, but
there is no method that can determine that they are the most appropriate to
solve the problem. This paper proposes a new technique for signal
classification in which a Genetic Algorithm is used in order to automatically
select the best feature set for signal classification, in combination with a
kNN as classifier system. This method was used in a well known problem and its
results improve those already published in other works.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Rivero:2011:URAftDoESiES,
  title     = {Using Recurrent ANNs for the Detection of Epileptic Seizures in EEG Signals},
  author    = {Daniel Rivero and Enrique Fernandez-Blanco and Julian Dorado and Alejandro Pazos},
  pages     = {580--585},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining, Real-world applications},
  abstract  = {
EEG classification is a research topic that has attracted a lot of interest in
recent years, as proven by the large number of papers published. To accomplish
this task, a lot of classification systems such as Support Vector Machines
(SVMs) or Artificial Neural Networks (ANNs) are used. However, Recurrent
Artificial Neural Networks (RANNs) that allow using the previously computed
results to generate the actual output have hardly been used, although
intuitively they may seem to be very useful in this field. This article
proposes the use of RANNs to solve a well-known problem: the detection of
epileptic seizures in EEG signals. The results show that RANNs can work it out
satisfactorily, with a higher accuracy than other techniques previously used.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Asconavieta:2011:EAftCRS,
  title     = {Evolutionary Algorithm for the Car Renter Salesman},
  author    = {Paulo Asconavieta and Marco Goldbarg and Elizabeth Goldbarg},
  pages     = {586--593},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Emerging areas, Discrete and combinatorial optimization.},
  abstract  = {
The Car Renter Salesman is a new variant of the Traveling Salesman Problem
with applications in optimization of scheduling of rental cars and transport
systems in general. This paper defines the problem and proposes a Transgenetic
Algorithm for it. The proposed algorithm is compared to a Memetic Algorithm
presented in a previous work. In order to focus on differences between the
evolutionary strategies of each algorithm, the algorithm proposed here share
several elements with the memetic algorithm. Results of a computational
experiment performed on twenty instances indicate that the cooperative
evolutionary process of the transgenetic algorithm produces high quality
solutions outperforming the comparison algorithm.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Menezes:2011:OEoBGbN,
  title     = {On Ensembles of Biclusters Generated by NichePSO},
  author    = {Lara Menezes and Andre Coelho},
  pages     = {594--600},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining, Particle swarm optimization},
  abstract  = {
Ensemble methods combine multiple models into a single framework for coping
better with Machine Learning tasks. Recently, the well-known Bagging approach
was adapted to solve biclustering problems, where the objective is to find
large sub-groups of samples and attributes of the data matrix with the samples
showing high correlation over the attributes. In this paper, aiming at the
generation of more diverse and high-quality biclusters to be fused through an
ensemble perspective, we have adopted a well-known multimodal Particle Swarm
Optimization algorithm, namely NichePSO. In particular, the study brings a
preliminary comparative assessment of the biclustering results delivered by
NichePSO operating alone and by two ensemble settings (one of which is
Bagging) operating on the biclusters produced by NichePSO. The assessment was
done based on bioinformatics and collaborative filtering datasets, and the
results achieved so far reveal the usefulness of ensembling the repertory of
biclusters produced by NichePSO.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Hijaze:2011:DEATwAMS,
  title     = {Distributed Evolutionary Algorithm Topologies with Adaptive Migration Schemes},
  author    = {Muhannad Hijaze and David Corne},
  pages     = {601--608},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Parallel and distributed algorithms, Numerical optimization., Large-scale problems.},
  abstract  = {
Distributed evolutionary algorithms are of increasing interest and importance
for three main reasons: (i) a well designed dEA can outperform a 'standard' EA
in terms of reliability, solution quality, and speed; (ii) they can (of
course) be implemented on parallel hardware, and hence combine efficient
utilization of parallel resources with very fast and reliable optimization;
(iii) parallel hardware resources are increasingly common. A dEA operates as
separate evolving populations with occasional interaction between them via
'migration'. A specific dEA is characterized by the topology and nature of
these interactions. The performance of alternative topologies and migration
mechanisms in this field remains under-explored. In this paper we continue an
investigation of two simple, novel dEA topologies, comparing with the
cube-based topology that underpins Alba et al's GD-RCGA (a state of the art
dEA). The focus in this paper is on testing a novel adaptive migration scheme,
in which the frequency of migration events adapts dynamically in response to
the current balance between exploration and exploration. We also focus on high
dimensional versions of a selection of hard function optimization problems. We
find that the adaptive migration scheme is promising, and that overall results
marginally favour a simple three-level treebased topology and adaptive
migration with a longer window, especially as dimensionality increases.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lotif:2011:VItSBoHSaiVwV,
  title     = {Visually Inspecting the Search Behavior of Harmony Search and its Variants with Viz3D},
  author    = {Marcelo Lotif and Andre Coelho},
  pages     = {609--616},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Heuristics, metaheuristics and hyper-heuristics, Numerical optimization.},
  abstract  = {
The aim of this study is to assess the Harmony Search (HS) meta-heuristic and
some of its variants when submitted to benchmark continuous optimization
problems to reveal whether and how such variants change the patterns of search
behavior exhibited by the canonical version. For this purpose, a new Visual
Mining tool based on the Viz3D algorithm was developed to aid in the
visualization of how the HS algorithms effectively explore the search space.
The results achieved provide evidence that the gains in performance usually
promoted by the HS variants are indeed related to noticeable modifications in
the search behavior as displayed by the original version.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Cardamone:2011:DSoPIuGP,
  title     = {Dynamic Synthesis of Program Invariants using Genetic Programming},
  author    = {Luigi Cardamone and Andrea Mocci and Carlo Ghezzi},
  pages     = {617--624},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming},
  abstract  = {
In the field of software engineering, invariant detection techniques have been
proposed to overcome the problem of software behavior comprehension. If the
code of a program is available, combining symbolic and concrete execution has
been shown to provide an effective method to derive logic formulae that
describe a program's behavior. However, symbolic execution does not work very
well with loops, and thus such methods are not able to derive useful
descriptions of programs containing loops. In this paper, we present a
preliminary approach that aims to integrate genetic programming to synthesize
a logic formula that describes the behavior of a loop. Such formula could be
integrated in a symbolic execution based approach for invariant detection to
synthesize a complex program behavior. We present a specific representation of
formulae that works well with loops manipulating arrays. The technique has
been validated with a set of relevant examples with increasing complexity. The
preliminary results are promising and show the feasibility of our approach.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{de-Franca:2011:Eaamcbwsi,
  title     = {Extracting additive and multiplicative coherent biclusters with swarm intelligence},
  author    = {Fabricio {de Franca} and Fernando J. {Von Zuben}},
  pages     = {625--631},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining, Data mining},
  abstract  = {
Biclustering is usually referred to as the process of finding subsets of rows
and columns from a given dataset expressing a relationship. Each subset is a
bicluster and corresponds to a sub-matrix whose elements tend to present a
high degree of coherence with each other, that may lead to novel discoveries
regarding the objects in the dataset. This coherence leads to the possibility
of obtaining representative values for rows (subset of objects) and columns
(subset of attributes) of each bicluster. In the literature, it is usually
studied the additive coherence among elements, i.e. each element is
represented by the sum of its respective representative values. But in a given
dataset, it is also possible to find multiplicative relations, i.e. each
element being represented by the multiplication of its respective
representative values, and that may reveal distinct knowledge contained in the
objects of the dataset. So, in this paper, a swarm-based approach, named
SwarmBcluster, is adapted to find both additive and multiplicative coherent
biclusters from a dataset, in an attempt to enrich the amount of information
provided by the biclusters. Experiments are performed considering two
well-known datasets and it is found that the multiplicative coherence
biclusters improve the quality of the data analysis and may contribute to
reduce the influence of noise.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Gonzalez-Pardo:2011:AoGEAtREI,
  title     = {Analysis of Grammatical Evolution Approaches to Regular Expression Induction},
  author    = {Antonio Gonzalez-Pardo and David Camacho},
  pages     = {632--639},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Data mining},
  abstract  = {
Regular expressions, or regexes, have been used traditionally as a pattern
matching tool to search for structures in a set of objects, like files, text
documents or folders. Pattern matching can be used to look for files whose
name contains a given string, to search files that contain a specific pattern
within them, or simply to extract text in a set of documents. It is very
popular to apply regexes to detect and extract patterns that represent phone
numbers, URLs, email addresses, etc. These kind of information can be
characterized because it has a well defined structure. Nevertheless, regexes
are not very frequently used because its high complexity in both, syntax and
grammatical rules, makes regexes difficult to understand. For this reason, the
development of programs able to automatically generate, and evaluate, regexes
has become a valuable task. This work analyzes the performance of different
grammatical evolutionary approaches in the generation of regexes able to
extract URL patterns. Four different types of grammars have been evaluated: a
context-free grammar, a context-free grammar with a penalized fitness
function, an extensible context-free grammar, and a Christiansen grammar. For
the considered problem, the experimental results show that the best
performance of the system, measured as cumulative success rate, is achieved
using Christiansen grammars.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Estevez:2011:UaIRDTfRIiaLCS,
  title     = {Using an Induced Relational Decision Tree for Rule Injection in a Learning Classifier System},
  author    = {Jose Estevez and Pedro Toledo and Silvia Alayon},
  pages     = {640--647},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Learning classifier systems, Hybrid Systems of Computational Intelligence:, Convergence, scalability and complexity analysis},
  abstract  = {
Transfer learning, using systems with rich and general  representations,  to
improve adaptive rule based  systems designed to efficiently react in changing
environments is the idea behind the problem studied in this paper. In this
framework, the aim of this research is studying the benefits of using
relational learning in combination with an evolutionary propositional learning
system as XCS. The  proposed method starts by learning a first order
relational decission tree using a set of simplified instances of a problem.
The learned relational model is then used to help a learning classifier system
to deal with a more complex instance of the task. The researched strategy is
based on injecting rules derived from the relational model in the discovering
subsystem of the XCS. Results show that this method can be used to
automatically adapt the behaviour of a learning rule based system when the
environment increases its complexity.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Khan:2011:ANEAf2SMBoBM,
  title     = {A Novel Evolutionary Approach for 2D Shape Matching Based on B-Spline Modeling},
  author    = {Mohammad Khan and Ahmad Ayob and Amitay Isaacs and Tapabrata Ray},
  pages     = {648--654},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Representation and operators, Memetic, multi-meme and hybrid algorithms},
  abstract  = {
Shape representation plays a vital role in any shape optimization exercise.
The ability to identify a shape with good performance is largely dependent on
the underlying shape representation scheme. In this paper, a novel shape
representation scheme is presented based on B-splines, wherein the control
points representing the shape are repaired and subsequently evolved within the
framework of a memetic algorithm. The underlying memetic algorithm is a
multi-feature hybrid that combines the strength of a real coded genetic
algorithm, differential evolution and a local search. Two test problems on
shape matching are presented and solved using a mere 5000 function evaluations
to illustrate the efficiency of the proposed scheme.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Hamada:2011:OSoAWAfMFO,
  title     = {On Scalability of Adaptive Weighted Aggregation for Multiobjective Function Optimization},
  author    = {Naoki Hamada and Yuichi Nagata and Shigenobu Kobayashi and Isao Ono},
  pages     = {655--664},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Convergence, scalability and complexity analysis, Multiobjective optimization},
  abstract  = {
In our previous study, we have proposed Adaptive Weighted Aggregation (AWA), a
framework of multi-starting optimization methods based on scalarization for
solving multiobjective function optimization problems. The experiments in the
proposal show that AWA outperforms conventional multi-starting descent methods
at coverage of solutions. However, the suitable termination condition for AWA
have not been understood. Coverage of AWA's solutions and computational cost
of AWA strongly depends on the termination condition. In this paper, we derive
the necessary and sufficient iteration count to achieve high coverage and the
number of approximate solutions generated until AWA stops. Numerical
experiments show that AWA still achieves better coverage than the conventional
methods under the derived termination condition.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Vazquez:2011:TSNMuCSA,
  title     = {Training Spiking Neural Models using Cuckoo Search Algorithm},
  author    = {Roberto A Vazquez},
  pages     = {665--672},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolved neural networks},
  abstract  = {
Several meta-heuristic algorithms have been proposed in the last years for
solving a wide range of optimization problems. Cuckoo Search Algorithm (CS) is
a novel meta-heuristic based on the obligate brood parasitic behaviour of some
cuckoo species in combination with the Levy flight behavior of some birds and
fruit flies. This algorithm has been applied in a wide range of optimization
problems; nonetheless, their promising results suggest its application in the
field of artificial neural networks, specially during the adjustment of the
synaptic weights. On the other hand, spiking neurons are neural models that
try to simulate the behavior of biological neurons when they are excited with
an input current (input pattern) during a certain period time. Instead of
generating a response in its output every iteration, as classical neurons do,
this model generates a response (spikes or spike train) only when the model
reaches a specific threshold. This response could be coded into a firing rate
and perform a pattern classification task according to the firing rate
generated with the input current. To perform a classification task the model
ought to exhibit the next behavior: patterns from the same class must generate
similar firing rates and patterns from other classes have to generate firing
rates sufficiently dissimilar to differentiate among the classes. The model
needs of a training phase aimed to adjust their synaptic weights and exhibit
the desired behavior. In this paper, we describe how the CS algorithm can be
useful to train a spiking neuron to be applied in a pattern classification
task. The accuracy of the methodology is tested using several pattern
recognition problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Oiso:2011:ASGAboCA,
  title     = {Accelerating  Steady-State Genetic Algorithms based on CUDA Architecture},
  author    = {Masashi Oiso and Yoshiyuki Matsumura and Toshiyuki Yasuda and Kazuhiro Ohkura},
  pages     = {673--678},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms},
  abstract  = {
Parallel processing using graphic processing units (GPUs) have attracted much
research interest in recent years. Parallel computation can be applied to
genetic algorithms (GAs) in terms of the processes of individuals in a
population. This paper describes the implementation of GAs in the compute
unified device architecture (CUDA) environment. CUDA is a general-purpose
computation environment for GPUs. The major characteristic of this study is
that a steady-state GA is implemented on a GPU based on concurrent kernel
execution.  The proposed implementation is evaluated through four test
functions; we find that the proposed implementation method is 3.0-6.0 times
faster than the corresponding CPU implementation.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Dos-Santos:2011:CEOGbPO,
  title     = {Classifier Ensembles Optimization Guided by Population Oracle},
  author    = {Eulanda M. {Dos Santos} and Robert Sabourin},
  pages     = {679--684},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Learning classifier systems, Classification, clustering, data analysis and data mining, Heuristics, metaheuristics and hyper-heuristics},
  abstract  = {
Dynamic classifier ensemble selection is focused on selecting the most confident
classifier ensemble to predict the class of a particular test pattern. The
overproduce-and-choose strategy is a dynamic classifier ensemble selection
method which is divided into optimization and dynamic selection phases. The
first phase involves the test of different candidate ensembles in order to
produce a population composed of the highest performing candidate ensembles.
Then, the second phase calculates the domain of expertise of each candidate
ensemble to pick up the solution with highest degree of certainty of its
decision to classify the unknown test samples. It has been shown that the
optimization phase decreases oracle, the upper bound of dynamic selection
processes. In this paper we propose a hybrid algorithm to perform the
optimization phase of overproduce-and-choose strategy. The proposed
algorithm combines stochastic initialization of candidate ensembles of different
sizes, with the traditional forward search greedy method. The objective is to
apply oracle as search criterion  during the optimization phase. We show
experimentally that choosing the population of classifier ensembles taking into
account the population oracle leads to increase the upper bound of the dynamic
selection phase. Moreover, experimental results conducted to compare the
proposed method to a multi-objective genetic algorithm (MOGA),
 demonstrate that our method outperforms MOGA on generating population of
candidate ensembles with higher oracle rates.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lee:2011:EaPCfMCL,
  title     = {Evolving a Population Code for Multimodal Concept Learning},
  author    = {Bado Lee and Ho-Sik Seok and Byoung-Tak Zhang},
  pages     = {685--692},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Estimation of distribution algorithms, Learning classifier systems},
  abstract  = {
We describe an evolutionary method for learning concepts of objects from
multimodal data. The proposed method uses a population code (hypernetwork
representation), i.e. a collection of codewords (hyperedges) and associated
weights, which is adapted by evolutionary computation based on observations of
positive and negative examples. The goal of evolution is to find the best
compositions and weights of hyperedges to estimate the underlying distribution
of the target concepts. We discuss the relationship of this method with
estimation of distribution algorithms (EDAs), classifier systems, and \%\%
modif ensemble learning methods. We evaluate the method on a suite of
image/text benchmarks. The experimental results demonstrate that the
evolutionary process successfully discovers salient codewords representing
multi-modal feature combinations for describing and distinguishing different
concepts. We also analyze how the complexity of the population code evolves as
learning proceeds.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Carpentieri:2011:ORoPSOSSoR3bSC,
  title     = {On Robustness of Permutations Sequencing Operators: Solving Satisfiability of Random 3-CNFs by Simple Crossover},
  author    = {Marco Carpentieri},
  pages     = {693--700},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary simulation-based optimization, Discrete and combinatorial optimization., Genetic algorithms},
  abstract  = {
Permutations sequencing operators have been proved to be effective to solve
randomized hard problems such as that of finding Hamiltonian cycles in random
graphs. We introduce a simple polynomial reduction of the problem of computing
satisfiability assignments for random 3-CNFs to a constrained variant of the
problem of computing simple paths in undirected graphs. We provide
experimental results evidencing that the simple crossover technique,
incorporated into the framework of a memetic model, inspired by Sexual
Selection and Elitist/Evolution Strategy principles, is effective in practice
to solve the satisfiability problem (for 3-CNF random instances satisfiable by
hidden assignments).
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lugo-Cordero:2011:PSOfLBiGSH,
  title     = {Particle Swarm Optimization for Load Balancing in Green Smart Homes},
  author    = {Hector Lugo-Cordero and Abigail Fuentes-Rivera and Ratan Guha and Eduardo Ortiz-Rivera},
  pages     = {701--706},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Multiobjective optimization, Particle swarm optimization},
  abstract  = {
Particle Swarm Optimization (PSO) is a promising evolutionary algorithm, which
has been used in a wide range of applications, due to its simple
implementation, fast convergence, parallel behavior, and versatility in
working with continuous and discrete domains. In this paper, we consider its
application to the load balancing problem, in green smart homes. Specifically,
an adapted version of the Binary PSO has been used to determine the optimal
distribution of energy resources, accross different green energy sources in a
green smart home. The case study of interest considers the usage of solar and
wind energy, as green energy sources for the green smart home. Results
demonstrate the effectiveness of the algorithm, in terms of the optimal
outcome (efficient distribution of energy resources), finding installation
material surplus, and the execution speed of the algorithm.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Hassanein:2011:GFCfRMPCbuID,
  title     = {Genetic Fuzzy Controller for Robot Manipulator Position Control based upon Inverse Dynamics},
  author    = {Osama Hassanein and Sreenatha Anavatti and Tapabrata Ray},
  pages     = {707--714},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Evolutionary fuzzy systems},
  abstract  = {
Two link manipulators generalize many of the robotic actions and hence have
been studied over the past decade. The path control of the tip of the two link
manipulator is a challenging problem due to the coupled and non-linear
dynamics.  In addition, parameter variations in terms of moments of inertia/
mass provide additional challenge to control engineers.  This paper considers
the positioning of the end-effector based on inverse dynamics, without
specifying a particular path. Fuzzy Logic Control (FLC) and Genetic Fuzzy
Logic Control (GFLC) based controllers are designed and compared with the
conventional Proportional-Derivative (PD) controller.  Hybrid cost function is
used in the Genetic Algorithm (GA) to achieve better performance.  The
membership functions of the FLC along with the scaling gains of the hybrid
cost function are optimized using the GA algorithm.  Numerical simulations
show the improvements in the performance and robustness to parameter
variations and noise.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Wang:2011:AFACTMwGPfMCSoSB,
  title     = {A Fuzzy Adaptive Comfort Temperature Model with Grey Predictor for Multi-agent Control System of Smart Building},
  author    = {Zhu Wang and Rui Yang and Lingfeng Wang and Robert {Green, II} and Anastasios Dounis},
  pages     = {715--722},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications},
  abstract  = {
In this paper a fuzzy adaptive comfort temperature (FACT) model has been
proposed for the intelligent control of smart buildings. A multi-agent control
system is applied for the energy management and building operation. Particle
Swarm Optimization (PSO) is applied to optimize the set points based on the
comfort zone. Integrating a grey predictor to predict outdoor temperature with
the FACT model shows great promise in systematically determining the customer
temperature comfort zone for smart buildings. With the application of the FACT
model and other intelligent technologies, the multi-agent control system has
successfully provided a high-level of temperature comfort with low power
consumption to customers in smart building environments. Case studies and
corresponding simulation results are presented and discussed in this paper.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ahn:2011:ATEAfFECFaW,
  title     = {A Two-Population Evolutionary Algorithm for Feature Extraction: Combining Filter and Wrapper},
  author    = {Eun Yeong Ahn and Tracy Mullen and John Yen},
  pages     = {723--730},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining, Data mining},
  abstract  = {
Extracting good features is critical to the performance of learning algorithms
such as classifiers. Feature extraction selects and transforms original
features to find information hidden in data. Due to the huge search space of
selection and transformation of features, exhaustive search is computationally
prohibitive and randomized search such as evolutionary algorithms (EA) are
often used. In our prior work on evolutionary-based feature extraction, an
individual, which represents a set of features, is evaluated by estimating the
accuracy of a classifier when the individual's feature set is used for
learning. Although incorporating a learning algorithm during evaluation, which
is called the wrapper approach, generally performs better than evaluating an
individual simply by the statistical properties of data, which is called the
filter appproach, our EA based on a wrapper approach suffers from overfitting,
so that a slight enhancement of fitness in training can dramatically reduce
the classification accuracy for unseen testing data. To cope with this
problem, this paper proposes a two-population EA for feature extraction
(TEAFE) that combines filter and wrapper approaches, and shows the promising
preliminary results.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Goh:2011:ASMCAfECOP,
  title     = {A Surrogate-Assisted Memetic Co-evolutionary Algorithm for Expensive Constrained Optimization Problems},
  author    = {Chi Keong Goh and Dudy Lim and Li Ma and Yew Soon Ong and Partha Dutta},
  pages     = {731--736},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Memetic, multi-meme and hybrid algorithms, Meta-modeling and surrogate models, Coevolutionary systems},
  abstract  = {
Stochastic optimization of computationally expensive problems is a relatively
new field of research in evolutionary computation (EC). At present, few EC
works have been published to handle problems plagued with constraints that are
expensive to compute. This paper presents a surrogate-assisted memetic
co-evolutionary framework to tackle both facets of practical problems, i.e.
the optimization problems having computationally expensive objectives and
constraints. In contrast to existing works, the cooperative coevolutionary
mechanism is adopted as the backbone of the framework to improve the
efficiency of surrogate-assisted evolutionary techniques. The idea of
randomproblem decomposition is introduced to handle interdependencies between
variables, eliminating the need to determine the decomposition in an ad-hoc
manner. Further, a novel multi-objective ranking strategy of constraints is
also proposed. Empirical results are presented for a series of commonly used
benchmark problems to validate the proposed algorithm.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Halder:2011:SACBaWIDEAFRWO,
  title     = {Self Adaptive Cluster Based and Weed Inspired Differential Evolution Algorithm For Real World Optimization},
  author    = {Udit Halder and Swagatam Das and Dipankar Maity and Ajith Abraham and Dasgupta Preetam},
  pages     = {737--743},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems, Real-world applications, Intelligent systems applications},
  abstract  = {
In this paper we propose a Self Adaptive Cluster based and Weed Inspired
Differential Evolution algorithm (SACWIDE), where the cluster number is
dynamically changed by the suitable learning strategy during evolution and
also the algorithm strategically determines whether a particular cluster will
perform Differential Evolution (DE) or new weeds to be generated for avoiding
the shrinking. The performance of SACWIDE is reported on the set of 22
benchmark problems of CEC-2011.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Pradipta:2011:HDNBPSOfGO,
  title     = {Hierarchical Dynamic Neighborhood Based Particle Swarm  Optimization for Global Optimization},
  author    = {Ghosh Pradipta and Zafar Hamim and Swagatam Das and Ajith Abraham},
  pages     = {744--751},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Real-world applications, Heuristics, metaheuristics and hyper-heuristics},
  abstract  = {
Particle Swarm Optimization (PSO) is arguably one of the most popular
nature-inspired algorithms for real parameter optimization at present. In this
article, we introduce a new variant of PSO referred to as Hierarchical D-LPSO
(Dynamic Local Neighborhood based Particle Swarm Optimization). In this new
variant of PSO the particles are arranged following a dynamic hierarchy.
Within each hierarchy the particles search for better solution using
dynamically varying sub-swarms i.e. these sub-swarms are regrouped frequently
and information is exchanged among them. Whether a particle will move up or
down the hierarchy depends on the quality of its sofar best-found result. The
swarm is largely influenced by the good particles that move up in the
hierarchy. The performance of Hierarchical D-LPSO is tested on the set of 25
numerical benchmark functions taken from the competition and special session
on real parameter optimization held under IEEE Congress on Evolutionary
Computation (CEC) 2005. The results have been compared to those obtained with
a few best-known variants of PSO as well as a few significant existing
evolutionary algorithms.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Nasir:2011:AIMEAboDwFD,
  title     = {An Improved Multiobjective Evolutionary Algorithm based on Decomposition with Fuzzy Dominance},
  author    = {Mohammed Nasir and A. Mondal and S. Sengupta and Swagatam Das and Ajith Abraham},
  pages     = {752--759},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Real-world applications, Emerging areas},
  abstract  = {
This paper presents a new Multi-Objective Evolutionary Algorithm (MOEA) based
on decomposition, with fuzzy dominance (MOEA/DFD). The algorithm introduces a
fuzzy Pareto dominance concept to compare two solutions and uses the scalar
decomposition method only when one of the solutions fails to dominate the
other in terms of a fuzzy dominance level. The diversity is maintained through
the uniformly distributed weight vectors. In addition, Dynamic Resource
Allocation (DRA) is used to distribute the computational effort based on the
utilities of the individuals. To assess the performance of the proposed
algorithm, experiments were conducted on two general benchmarks and ten
unconstrained benchmark problems taken from the competition on real parameter
MOEAs held under the 2009 IEEE Congress on Evolutionary Computation (CEC). As
per the IGD metric, MOEA/DFD outperforms other major MOEAs in most cases.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Silva:2011:AEELMBoGSO,
  title     = {An Evolutionary Extreme Learning Machine Based on Group Search Optimization},
  author    = {Danielle Silva and Luciano Pacifico and Teresa Ludermir},
  pages     = {760--766},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization},
  abstract  = {
Extreme learning machine (ELM) was proposed as a new class of learning
algorithm for single-hidden layer feedforward neural network (SLFN) much
faster than the traditional gradient-based learning strategies. However, ELM
random determination of the input weights and hidden biases may lead to
non-optimal performance, and it might suffer from the overfitting as the
learning model will approximate all training samples well. In this paper, a
hybrid approach is proposed based on Group Search Optimizer (GSO) strategy to
select input weights and hidden biases for ELM algorithm, called GSO-ELM. In
addition, we evaluate the influence of different forms of handling members
that fly out of the search space bounds. Experimental results show that
GSO-ELM approach using different forms of dealing with out-bounded members is
able to achieve better generalization performance than traditional ELM in real
benchmark datasets.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


@InProceedings{Haidar:2011:AIPoDCboLM,
  title     = {An Intelligent Placement of Distributed Capacitance based on Loss Minimization},
  author    = {Ahmed Haidar and Khaled Noman and Rashad Al-Jawfi and Hazizulden Abdul Aziz},
  pages     = {767--771},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Optimization:, Particle swarm optimization},
  abstract  = {
Distributed Capacitance (DC) is an electric reactive power source connected
directly to the distribution network or on the customer site of the meter. It
is related with the use of small capacity units installed in strategic points
of electric distribution system and mainly close to the load centres. An
optimal placement of DC can minimize the losses in the system, improve voltage
profiles and increase load factors of distribution system. This paper proposes
an accurate method for optimal allocation of DC in the distribution systems
based on intelligent technique namely particle swarm optimization (PSO). The
system loss of electrical network is used as an indicator to evaluate the
impact of DC location on system reliability and voltage profile. To
demonstrate the global optimization power of the presented techniques, the
IEEE 30-bus test system has been used in this study to evaluate the proper
location of the DC in the electrical network. The results illustrate a high
reduction of system losses when DC is located at the proper location with
suitable size compared with the system loss at the base case.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Computational Intelligence in Bioinformatics and Computational Biology II
@InProceedings{Ross:2011:EoSBUSRS,
  title     = {Evolution of Stochastic Bio-Networks Using Summed Rank Strategies},
  author    = {Brian Ross},
  pages     = {772--779},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications, Genetic programming},
  abstract  = {
Stochastic models defined in the stochastic pi-calculus are evolved using
genetic programming. The interpretation of a stochastic model results in a set
of time series behaviors. Each time series denotes changing quantities of
components within the modeled system. The time series are described by their
statistical features. This paper uses genetic programming to reverse engineer
stochastic pi-calculus models.  Given the statistical characteristics of the
intended model behavior, genetic programming attempts to construct a model
whose statistical features closely match those of the target process. The
feature objectives comprising model behavior are evaluated using a
multi-objective strategy. A contribution of this research is that, rather than
use conventional Pareto ranking, a summed rank scoring strategy is used
instead. Summed rank scoring was originally derived for high-dimensional
search spaces. This paper shows that it is likewise effective for evaluating
stochastic models with  low- to moderate-sized search spaces. Two models with
oscillating behaviors were successfully evolved, and these results are
superior to those obtained from earlier research attempts. Experiments on a
larger-sized model were not successful. Reasons for its poor performance
likely include inappropriate choices in feature selection, and too many
selected features and channels contributing to an overly difficult search
space.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ashlock:2011:CoEENwDC,
  title     = {Comparison of Evolved Epidemic Networks with Diffusion Characters},
  author    = {Daniel Ashlock and Elisabeth Shiller and Colin Lee},
  pages     = {780--787},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Representation and operators},
  abstract  = {
Epidemic models often incorporate contact networks along which the disease can
be passed.  This study uses a recentering-restarting evolutionary algorithm to
locate likely epidemic networks for six different epidemic profiles containing
early peaks, late peaks, and multiple peaks in the number of infected
individuals.  This study demonstrates that the algorithm can fit a broad variety
of epidemic profiles.  The difficulty of finding a network likely to produce a
given epidemic profile varies between profiles, but all six profiles are fitted
well in at least some of the evolutionary runs.  A pseudometric on pairs of
networks based on diffusion characters is used to assess the networks
distribution in the space of networks. Both the scatter of networks evolved to
match a single epidemic profile and the between-profile distances are evaluated.
 The diffusion character based pseudometric separates the networks for some
pairs of profiles neatly while others apparently overlap to some degree.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Vansant:2011:HTCoCDCUGEENNaaCP,
  title     = {High-Throughput Toxicological Classification of Candidate Drug Compounds Using Gene Expression, Evolved Neural Networks, and a Cell-based Platform},
  author    = {Gordon Vansant and Pat Pezzoli and Joseph Monforte and Gary Fogel},
  pages     = {788--794},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications},
  abstract  = {
All new pharmaceutical agents must be screened for potential toxicity in
humans. This process includes a series of genotoxic screens in the discovery
phase, and in the event the drug is designed for chronic use, a 2-year non-
genotoxicity rodent study. Such non-genotoxicity studies are very expensive
because of their duration, the amount of compound required, and the number of
rodents required. Models capable of predicting genotoxicity during discovery
would reduce these costs and increase favorable outcomes for drugs in a
pipeline of development by reducing the rate of attrition. To that end, we
have used gene expression data and evolved neural networks to classify
compounds by their carcinogenicity or genotoxicity. 60 compounds were used for
the training and testing of classifiers relative to gene expression from rat
liver cells. Genes related to xenobiotic metabolism, proliferation, apoptosis,
and DNA damage were identified. Our study demonstrates that evolved neural
networks can be used to classify compounds as carcinogenic or genotoxic with
reasonable accuracy.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: EC on Many-core Architecture to Solve Large-scale Problems II
@InProceedings{Kromer:2011:DEftLOPIoC,
  title     = {Differential Evolution for the Linear Ordering Problem Implemented on CUDA},
  author    = {Pavel Kromer and Jan Platos and Vaclav Snasel},
  pages     = {795--801},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Linear Ordering Problem (LOP) is a well know NP-hard problem combinatorial
optimization problem attractive for its complexity, rich library of test data
and variety of real world applications. In this paper, we use differential
evolution accelerated by the GPU using the nVidia CUDA platform to find good
LOP solutions. The well known LOLIB library was used to evaluate the
efficiency and precision of the approach in solving LOP instances.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Wahib:2011:OoPGAfnG,
  title     = {Optimization of Parallel Genetic Algorithms for nVidia GPUs},
  author    = {Mohamed Wahib and Asim Munawar and Masaharu Munetomo and Kiyoshi Akama},
  pages     = {802--810},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Led by General Purpose computing over Graphical Processing Units (GPGPUs), the
parallel computing area is witnessing a rapid change in dominant parallel
systems. A major hurdle in this switch is the Single Instruction Multiple
Thread (SIMT) architecture of GPUs which is usually not suitable for the
design of legacy parallel algorithms. Genetic Algorithms (GAs) is no exception
for that. GAs are commonly parallelized due to the high demanding
computational needs. Given the performance of GPGPUs, the need to best exploit
them to maximize computing efficiency for parallel GAs is demandingly growing.
The goal of this paper is to shed light on the challenges parallel GAs
designers/programmers will likely face while trying to achieve this, and to
provide some practical advice on how to maximize GPGPU exploitation as a
result. To that end, this paper provides a study on adapting legacy parallel
GAs on GPGPU systems. The paper exposes the design challenges of nVidia's GPU
architecture to the parallel GAs community by: discussing features of GPU,
reviewing design issues in GPU relevant to parallel GAs, the design and
introduction of new techniques to achieve an efficient implementation for
parallel GAs and observing the effect of the pivotal points that both
capitalize on the strengths of GPU and limit the deficiencies/overheads of
GPUs. The paper demonstrates the performance of designed-for-GPGPU parallel
GAs representing the entire spectrum of legacy parallel model of GAs over
nVidia Tesla C1060 workstation showing a significant improvement in
performance after optimizing and tuning the algorithms for GPU.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Tsutsui:2011:FQSbAw2LSoaG,
  title     = {Fast QAP Solving by ACO with 2-opt Local Search on a GPU},
  author    = {Shigeyoshi Tsutsui and Noriyuki Fujimoto},
  pages     = {811--818},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Ant colony optimization, Discrete and combinatorial optimization.},
  abstract  = {
This paper proposes a parallel ant colony optimization (ACO) for solving
quadratic assignment problems (QAPs) on a graphics processing unit (GPU) by
combining fast, 2-opt local search in compute unified device architecture
(CUDA). In 2-opt for QAP, 2-opt moves can be divided into two groups based on
computing cost. In one group, the computing cost is O(1) and in the other
group, the computing cost is O(n). We compute these groups of 2- opt moves in
parallel by assigning the computations to threads of CUDA. In this assignment,
we propose an efficient method that can reduce disabling time in each thread
of CUDA. The results show GPU computation with 2-opt produces a speedup of
x24.6 on average, compared to computation with CPU.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Gong:2011:DIGAUHPS,
  title     = {Distributed Island-Model Genetic Algorithms Using Heterogeneous Parameter Settings},
  author    = {Yiyuan Gong and Alex Fukunaga},
  pages     = {819--826},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Parallel and distributed algorithms, Genetic algorithms},
  abstract  = {
Achieving good performance with a parallel genetic algorithm requires properly
configuring control parameters such as mutation rate, crossover rate, and
population size. We consider the problem of setting control parameter values
in a standard, island-model distributed genetic algorithm. As an alternative
to tuning parameters by hand or using a self-adaptive approach, we propose a
very simple strategy which statically assigns random control parameter values
to each processor. Experiments on benchmark problems show that this simple
approach can yield results which are competitive with homogeneous distributed
genetic algorithm using parameters tuned specifically for each of the
benchmarks.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Computational Intelligence and Games I
@InProceedings{Ashlock:2011:FCotEoAN,
  title     = {Financial Control of the Evolution of Autonomous NPCs},
  author    = {Daniel Ashlock and Sylvia Nguyen},
  pages     = {827--834},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Games, Representation and operators},
  abstract  = {
This study prototypes a method of evolving autonomous agents that can act as
NPCs in a game.  The agents move based on information about their local
environment and have evolved weapons, armor, ability to take damage, and
movement factors.  The creation of the agent is divided into two phases.  In
the first a population of competent movement controllers are evolved.  In the
second, the agents start with a competent movement controller and evolve
weapons, levels of armor, number of hit points, and numbers of movement
factors.  The movement controller continues to evolve in the second phase. 
The evolution of the agents equipment is constrained by a budget together with
a price for each type of object the agent can have.  The gene specifying the
agents equipment is in the form of a ``wish list'' of equipment, traversed
left-to-right, with the agent buying items from the list as long as its budget
suffices.  An agent that is a more dangerous opponent can be evolved by giving
it a larger budget.  A group of experiment were conducted and they demonstrate
that the budget can be used to control an agent's toughness.  Additional
experiments show that changing the price list for different items can also be
used to control the types of agents that evolve.  Pitfalls in the selection of
the fitness function for the agents are discussed.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Piccolo:2011:AOMftIPsD,
  title     = {Adaptive Opponent Modelling for the Iterated Prisoner's Dilemma},
  author    = {Elio Piccolo and Giovanni Squillero},
  pages     = {835--840},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
This paper describes the design of Laran, an intelligent player for the
iterated prisoner's dilemma. Laran is based on an evolutionary algorithm, but
instead of using evolution as a mean to define a suitable strategy, it uses
evolution to model the behavior of its adversary. In some sense, it
understands its opponent, and then exploits such knowledge to devise the best
possible conduct. The internal model of the opponent is continuously adapted
during the game to match the actual outcome of the game, taking into
consideration all played actions. Whether the model is correct, Laran is
likely to gain constant advantages and eventually win. A prototype of the
proposed approach was matched against twenty players implementing state-of-the
art strategies. Results clearly demonstrated the claims.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Vazquez:2011:AEAfTaCEF,
  title     = {An Evolutionary Algorithm for Tuning a Chess Evaluation Function},
  author    = {Eduardo Vazquez and Carlos A. {Coello Coello} and Feliu Sagols},
  pages     = {841--847},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
This paper proposes a method for tuning the weights of the evaluation function
of a chess program whose search engine is based on evolutionary programming.
In our proposed approach, each individual in the population of the
evolutionary algorithm represents a virtual player with specific weights of
its evaluation function. This differs from most of the previous approaches
reported in the literature, in which normally a tournament between virtual
players is held, and the final result (win, loss or draw) is used to decide
which players pass to the following generation. The selection mechanism of our
proposed algorithm uses games from chess grandmasters to decide which virtual
player will pass to the following generation. Our results indicate that the
weight values obtained by our approach are similar to the values known from
chess theory. Additionally, the standard deviation from the different runs
performed, are lower than those reported by authors of previous related
approaches.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ashlock:2011:DtLGPwT,
  title     = {Decomposing the Level Generation Problem with Tiles},
  author    = {Daniel Ashlock and Cameron McGuinness},
  pages     = {848--855},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Representation and operators, Games},
  abstract  = {
Search based procedural content generation uses search techniques to locate
high-quality content elements for use in games.  This study specifies and tests
an evolutionary-computation based system to generate tiles and plans that
decompose the problem of assembling large levels.  Evolutionary computation is
used as an off-line tool to generate libraries of both tiles and assembly plans.
 Systems for rapidly assembling tile libraries can then be used to generate large
levels on demand with combinatorially huge numbers of levels available.  The
study also introduces new fitness functions, generalizing early work on
checkpoint based fitness for the evolution of mazes, that is especially well
suited for tile creation.  Tiles are generated using two different
representations that yield tiles with very different appearances.  The study
demonstrates assemblies of large levels and outlines several directions for
extending the work.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Session: Nature-inspired Constrained Optimization
@InProceedings{Elsayed:2011:GwaNMCfCO,
  title     = {GA with a New Multi-Parent Crossover for Constrained Optimization},
  author    = {Saber Elsayed and Ruhul Sarker and Daryl Essam},
  pages     = {856--863},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Over the last two decades, many Genetic Algorithms have been introduced for
solving Constrained Optimization Problems (COPs). Due to the variability of
the characteristics in different COPs, none of these algorithms performs
consistently over a range of problems. In this paper, we introduce a Genetic
Algorithm with a new multi-parent crossover for solving a variety of COPs. The
proposed algorithm also uses a randomized operator instead of mutation and
maintains an archive of good solutions. The algorithm has been tested by
solving the 36 test instances, introduced in the CEC2010 constrained
optimization competition session. The results show that the proposed algorithm
performs better than the state-of-the-art algorithms
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Hamza:2011:DECwCCfCO,
  title     = {Differential Evolution Combined with Constraint Consensus for Constrained Optimization},
  author    = {Noha Hamza and Saber Elsayed and Ruhul Sarker and Daryl Essam},
  pages     = {864--871},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Solving a Constrained Optimization Problem (COP) is much more challenging than
its unconstrained counterpart. In solving COPs, the feasibility of a solution
is a prime condition that requires the conversion of one or more infeasible
individuals to feasible individuals. In this paper, to encourage the effective
movement of infeasible individuals towards a feasible region, we introduce a
Constraint Consensus (CC) method within the Differential Evolution (DE)
algorithm for solving COPs. The algorithm has been tested by solving 13
well-known benchmark problems. The experimental results show that the
solutions are competitive, if not better, as compared to the state of the art
algorithms
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Perez:2011:NBftRTTPuaAIA,
  title     = {New Bounds for the Relaxed Traveling Tournament Problems using an Artificial Immune Algorithm},
  author    = {Leslie Perez and Maria-Cristina Riff},
  pages     = {872--878},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
In this paper we tackle the Relaxed Traveling Tournament Problem by an
artificial immune algorithm. We have tested the algorithm in the recently
proposed instances of the problem, the results obtained are very encouraging.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Real World Applications III
@InProceedings{Clancey:2011:AMAfDOiCRRTP,
  title     = {A Memetic Algorithm for Dosimetric Optimization in CyberKnife Robotic Radiosurgical Treatment Planning},
  author    = {Owen Clancey and Matthew Witten},
  pages     = {879--884},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Real-world applications},
  abstract  = {
A memetic algorithm is proposed for optimizing beam weights for robotic
radiosurgical treatments delivered via the CyberKnife (Accuray, Inc.,
Sunnyvale, CA) system. The fitness function includes terms representing the
tumor as well as terms representing organs-at-risk, and is of a quadratic
form. Optimization involves inverse treatment planning, during which a set of
beam weights is sought such that the user-specified radiation dose
distribution is produced by the optimized ensemble of beam weights; the dose
to the tumor is maximized, while the doses to the critical structures are
minimized. In the present study, four distinct CT data sets for patients with
carcinoma of the prostate were used to generate eight treatment plans, so that
for each data set, a hypofractionated treatment plan (5 fractions) was
created, as well as a treatment plan for a standard protracted dose
fractionation schedule (38 fractions). In all cases, the memetic algorithm
produced a treatment plan satisfying all clinical criteria in optimization
times of 22-46 minutes.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{U:2011:GAGAbRTSS,
  title     = {GART: A Genetic Algorithm based Real Time System Scheduler},
  author    = {ManChon U and Chiahsun Ho and Shelby Funk and Khaled Rasheed},
  pages     = {885--892},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Real-world applications, Learning classifier systems},
  abstract  = {
Hard real-time systems require that all jobs are assigned a deadline and the
system is deemed to be correct only if all jobs complete execution at or
before their deadlines. Such strict timing requirements add to the complexity
of the scheduling problem. This complexity is exacerbated when the system is
executed on a multiprocessor platform. Even so, scheduling overheads must be
kept to a minimum in order for the runtime behavior to be predictable. Thus,
real-time scheduling algorithms have the dual requirement of satisfying
complex requirements while using fairly simple and straightforward logic. One
way an algorithm may achieve this goal is to reduce the overhead due to
preemption and migration by rearranging the schedule so as to increase the
duration between preemptions. Unfortunately, determining how best to rearrange
the jobs is an NP- Complete problem. Hence, we need to use heuristics when
scheduling such systems. This leads us to ask a couple of questions. First,
what is the best heuristic? Second, is the same heuristic best for all
real-time systems? This paper uses a Genetic Algorithm to help us answer these
questions. Our genetic algorithm based real-time system scheduler (GART) is
based on the DP-Wrap scheduling algorithm. The genetic algorithm searches
through a variety of candidate heuristics to determine the best heuristic for
a given task set. Experimental results demonstrate that this approach is able
to efficiently identify the best heuristic for all the systems we consider.
Moreover, we find that the "best" heuristic does, in fact, depend of various
system parameters.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Reynolds:2011:APBHAfHM,
  title     = {A Parallel BOA-PSO Hybrid Algorithm for History Matching},
  author    = {Alan Reynolds and Asaad Abdollahzadeh and David Corne and Mike Christie and Brian Davies and Glyn Williams},
  pages     = {893--900},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Real-world applications, Estimation of distribution algorithms, Particle swarm optimization},
  abstract  = {
In order to make effective decisions regarding the exploitation of oil
reservoirs, it is necessary to create and update reservoir models using
observations collected over time in a process known as history matching. This
is an inverse problem: it requires the optimization of reservoir model
parameters so that reservoir simulation produces response data similar to that
observed. Since reservoir simulations are computationally expensive, it makes
sense to use relatively sophisticated algorithms. This led to the use of the
Bayesian Optimization Algorithm (BOA). However, the high performance of a much
simpler algorithm - Particle Swarm Optimization (PSO) - led to the development
of a BOA-PSO hybrid that outperformed both BOA and PSO on their own.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Tutum:2011:MLSoMDUMC,
  title     = {Multi-Criteria Layout Synthesis of MEMS Devices Using Memetic Computing},
  author    = {Cem Celal Tutum and Zhun Fan},
  pages     = {901--907},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Memetic, multi-meme and hybrid algorithms, Multiobjective optimization, Engineering applications},
  abstract  = {
This paper introduces a multi-objective optimization approach for layout
synthesis of MEMS components. A case study of layout synthesis of a
comb-driven micro-resonator shows that the approach proposed in this paper can
lead to design results accommodating two design objectives, i.e. simultaneous
minimization of size and power input of a MEMS device, while investigating
optimum geometrical configuration as the main concern. The major contribution
of this paper is the application of memetic computing in MEMS design. An
evolutionary multi-objective optimization (EMO) technique, in particular non-
dominated sorting genetic algorithm (NSGA-II), has been applied to find
multiple trade-off solutions followed by a gradient-based local search, i.e.
sequential quadratic programming (SQP), to improve the convergence of the
obtained Pareto-optimal front. In order to reduce the number of function
evaluations in the local search procedure, the obtained non-dominated
solutions are clustered in the objective space and consequently, a
post-optimality study is manually performed to find out some common design
principles among those solutions. Finally, two reasonable design choices have
been offered based on manufacturability issues.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Clustering and Data Mining II
@InProceedings{Menezes:2011:EMoaBN,
  title     = {Evolutionary Modeling of a Blog Network},
  author    = {Telmo Menezes},
  pages     = {908--915},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining, Genetic programming, Coevolution and collective behavior},
  abstract  = {
A common approach to produce theory to explain the genesis and dynamics of
complex networks is to create multi-agent simulations that output networks
with similar characteristics to the ones derived from real data. For example,
a well know explanation for the power law degree distributions found in blog
(and other) networks is the agent-level endogenous mechanism of preferential
attachment. However, once simplifying assumptions are dropped, finding lower
level behaviors that explain global network features can become difficult. One
case, explored in this paper, is that of modeling a blog network generated by
human agents with heterogeneous behaviors and a priori diversity. We propose
an approach based on an hybrid strategy, combining a generic behavioral
template created by a human designer with a set of programs evolved using
genetic programming. We present experimental results that illustrate how this
approach can be successfully used to discover a set of non-trivial agent-level
behaviors that generate a network that fits observed data. We then use the
model to make successful testable predictions about the real data. We analyze
the diversity of behaviors found in the evolved model by clustering the agents
according to the execution paths their programs take during the simulation. We
show that these clusters map to different behaviors, giving credence to the
need for exogenous, in addition to the more conventional endogenous
explanations, for the dynamics of blog networks.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Wang:2011:AMGPwDTLSfCP,
  title     = {A Memetic Genetic Programming with Decision Tree-based Local Search for Classification Problems},
  author    = {Pu Wang and Ke Tang and Edward Tsang and Xin Yao},
  pages     = {916--923},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming, Classification, clustering, data analysis and data mining, Data mining},
  abstract  = {
In this work, we propose a new genetic programming algorithm with local search
strategies, named Memetic Genetic Programming(MGP), for classification
problems. MGP aims to acquire a classifier with large Area Under the ROC Curve
(AUC), which has been proved to be a better performance metric for
traditionally used metrics (e.g., classification accuracy). Three new ideas
are presented in our new algorithm. First, a new representation called
statistical genetic decision tree (SGDT) for GP is proposed on the basis of
Genetic Decision Tree (GDT). Second, a new fitness function is designed by
using statistic information from SGDT. Third, the concept of memetic computing
is introduced into SGDT. As a result, the MGP is equipped with a local search
method based on the training algorithms for decision trees. The efficacy of
the MGP is empirically justified against a number of relevant approaches.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Cordeiro-Junior:2011:APafIMC,
  title     = {A PSO algorithm for Improving Multi-View Classification},
  author    = {Zilton Cordeiro Junior and Gisele L. Pappa},
  pages     = {924--931},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Data mining, Classification, clustering, data analysis and data mining},
  abstract  = {
The Multi-view or multi-modality learning approach is becoming popular for
providing different representations of a problem from which classifiers can
learn from. Examples of these representations are, for instance, sound and
image for the case of the video classification problem. The main idea behind
multi-view learning is that learning from these representations separately can
lead to better gains than merging them into a single dataset. In the same way
as ensembles combine results from different classifiers, the outputs given by
classifiers in different views have to be combined in order to provide a final
class for an example. This paper proposes a PSO algorithm to combine the
outputs coming from different views. It also considers that some views may be
better at classifying specific classes, and provides weighting schemes for
both views and classes. Experiments were performed in two datasets with three
views each, and compared with all views in a single dataset, a majority voting
scheme and a scheme based on the Dempster-Shafer theory. Experimental results
show that the PSO obtains statistically better results than the other
approaches evaluated.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Carvalho:2011:HAGAfHC,
  title     = {HCGA: A Genetic Algorithm for Hierarchical Classification},
  author    = {Rafael Carvalho and Gustavo Brunoro and Gisele L. Pappa},
  pages     = {932--939},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Data mining, Genetic algorithms},
  abstract  = {
Hierarchical classification (HC) is a specialization of the well-known flat
classification task. The main difference among them is that in HC examples
have to be assigned to classes organized in a previously defined class
hierarchy, while in traditional flat classification no class order is imposed.
There are two main approaches commonly used to tackle HC: the top-down or
local approach, which is classifier independent, and the big-bang or global
approach, which usually is the product of a modification of a well-known flat
classifier. Although evolutionary algorithms have been successfully applied to
flat classification, they are underexplored in HC. In this direction, this
paper proposes HCGA (Hierarchical Classification Genetic Algorithm), a method
that takes both local and global information into account. HCGA uses a
top-down approach for building a classification model and also for classifying
new examples. This is in contrast with current top-down methods, which make
use of this strategy only for test, using flat classifiers for training
models. The method was applied to four GPCR (G protein-coupled receptor)
activity datasets, obtaining results statistically equal or better than five
baseline classifiers run using a top-down approach.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Friedlander:2011:MaFRUGPfCVTW,
  title     = {Meta-Learning and Feature Ranking Using Genetic Programming for Classification: Variable Terminal Weighting},
  author    = {Anna Friedlander and Kourosh Neshatian and Mengjie Zhang},
  pages     = {940--947},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming, Classification, clustering, data analysis and data mining},
  abstract  = {
We propose an online  feature weighting method for classification by  genetic
programming  (GP). GP's implicit feature  selection was used  to construct  a
feature  weighting vector, based  on the  fitness of  solutions  in which  the
features  were found  and the  frequency at  which  they were  found.  The
vector  was used  to perform  feature  ranking and  to perform meta-learning by
 biasing terminal selection  in  mutation.  The  proposed  meta-learning
mechanism  significantly  improved  the  quality  of  solutions  in  terms  of
classification  accuracy  on an unseen  test set.  The probability  of
success---the  probability of finding the desired solution within a given number
of  generations (fitness  evaluations)---was also higher  than canonical  GP.
The ranking obtained  by using the GP-provided feature weighting  was   very
highly   correlated   with  the   ranking  obtained   by  commonly-used  feature
 ranking  algorithms. Population  information  during evolution can help shape
search behaviour (meta-learning) and  obtain  useful information  about  the
problem  domain  such as  the  importance of input features with respect to each
other.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Emerging Approaches to Large Scale Optimization Problems
@InProceedings{Malago':2011:SNGDbEoEC,
  title     = {Stochastic Natural Gradient Descent by Estimation of Empirical Covariances},
  author    = {Luigi Malago' and Matteo Matteucci and Giovanni Pistone},
  pages     = {948--955},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Heuristics, metaheuristics and hyper-heuristics, Discrete and combinatorial optimization., Estimation of distribution algorithms},
  abstract  = {
Stochastic relaxation aims at finding the minimum of a fitness function by
identifying a proper sequence of distributions, in a given model, that
minimize the expected value of the fitness function. Different algorithms fit
this framework, and they differ according to the policy they implement to
identify the next distribution in the model. In this paper we present two
algorithms, in the stochastic relaxation framework, for the optimization of
real-valued functions defined over binary variables: Stochastic Gradient
Descent (SGD) and Stochastic Natural Gradient Descent (SNDG). These algorithms
use a stochastic model to sample from as it happens for Estimation of
Distribution Algorithms (EDAs), but the estimation of the model from the
population is substituted by the direct update of model parameter through
stochastic gradient descent. The two algorithms, SGD and SNDG, both use
statistical models in the exponential family, but they differ in the use of
the natural gradient, first proposed in the literature by Amari, in the
context of Information Geometry. Due to the properties of the exponential
family, both gradient and natural gradient can be evaluated in terms of
covariances between the fitness function and the sufficient statistics of the
exponential family. As the computation of the exact gradient is unfeasible, we
approximate the gradient by evaluating empirical covariances. We test the
performance of our algorithm over different standard benchmarks, and we
compare the results with other well-known meta-heuristics in the framework of
EDAs.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Marti:2011:IMACSoSwRtDSD,
  title     = {Indicator-based MONEDA: A Comparative Study of Scalability with Respect to Decision Space Dimensions},
  author    = {Luis Marti and Jesus Garcia and Antonio Berlanga and Jose M. Molina},
  pages     = {956--963},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Multiobjective optimization, Estimation of distribution algorithms},
  abstract  = {
The multi-objective neural EDA (MONEDA) was proposed with the aim of
overcoming some difficulties of cur- rent MOEDAs. MONEDA has been shown to
yield relevant results when confronted with complex problems. Furthermore, its
performance has been shown to adequately adapt to problems with many
objectives. Nevertheless, one key issue remains to be studied: MONEDA
scalability with regard to the number of decision variables.

In this paper has a two-fold purpose. On one hand we propose a modification of
MONEDA that incorporates an indicator-based selection mechanism based on the
HypE algorithm, while, on the other, we assess the indicator-based MONEDA when
solving some complex two-objective problems, in particular problems UF1 to UF7
of the CEC 2009 MOP competition, configured with a progressively-increasing
number of decision variables.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Leal:2011:AHABoGFSfWSN,
  title     = {A Hybrid Approach Based on Genetic Fuzzy Systems for Wireless Sensor Networks},
  author    = {Liliam Leal and Marcus Lemos and Raimir Holanda and Ricardo Rabelo and Fabbio Borges},
  pages     = {964--971},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Hybrid Systems of Computational Intelligence:, Algorithms:},
  abstract  = {
Wireless sensor networks (WSNs) are composed of sensor nodes in order to
detect and transmit features from the physical environment. Generally, the
sensor nodes transmit informations to a special node, called sink.  The use of
an unique sink represents a bottleneck in a network, especially for
applications in real time. In this sense, some researches have directed
studies to the use of multiple sinks. The approach proposed by this paper
presents the application of Genetic Fuzzy System (GFS) for the selection of
routes in WNSs, in order to make the communication between multiple sensor
nodes and multiple sink nodes. Fuzzy Inference System of Mamdani are used to
determine the most appropriate sink node through consideration of some
characterstics of the sensors network, such as energy and number of hops. 
Genetic Algorithms are employed to obtain the optimal adjustment of Mandani's
fuzzy inference system parameters. By applying GAs, we intend to achieve both
a fuzzy database and a fuzzy rules base to maximize performance of the
application of Mamdani's inference system in the selection of routes in
Wireless Sensor Networks. The proposed route selection was applied by means of
computer simulations todemonstrate the feasibility of the approach
implemented. The results obtained through simulations demonstrated a sensor
network with a longer lifetime, through the choice of the adequate sink used
for sending packets through the network in order to find the best routes.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Li:2011:VSGNPwBD,
  title     = {Variable Size Genetic Network Programming with Binomial Distribution},
  author    = {Bing Li and Xianneng Li and Shingo Mabu and Kotaro Hirasawa},
  pages     = {972--979},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Algorithms:},
  abstract  = {
This paper proposes a different type of Genetic Network Programming (GNP) --
Variable Size Genetic Network Programming (GNPvs) with Binomial Distribution.
In contrast to the individuals with fixed size in Standard GNP, GNPvs will
change the size of the individuals and obtain the optimal size of them during
evolution. The proposed method defines a new type of crossover to implement
the new feature of GNP. The new crossover will select the number of nodes to
move from each parent GNP to another parent GNP. The probability of selecting
the number of nodes to move satisfies the  binomial probability distribution.
The proposed method can keep the effectiveness of crossover and improve the
performance of GNP. In order to verify the performance of the proposed method,
a well-known benchmark problem - - Tile-world is used in the simulations. The
simulation results show the effectiveness of the proposed method.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Workshop: Agent-Based Computational Economics and Finance II

% Session: Ant Approaches to Complex Problems
@InProceedings{Wu:2011:FLAoBNSL,
  title     = {Fitness Landscape Analysis of Bayesian Network Structure Learning},
  author    = {Yanghui Wu and John McCall and David Corne},
  pages     = {980--987},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Data mining, Ant colony optimization, Genetic algorithms},
  abstract  = {
Algorithms for learning the structure of Bayesian Networks (BN) from data are
the focus of intense research interest. Search and score algorithms using
nature-inspired metaheuristics are an important strand of this research,
however performance is variable and strongly problem-dependent. In this paper
we use fitness landscape analysis to explain empirically-observed performance
differences between particular search and score algorithms on two well-studied
benchmark problems. We investigate the average landscape discovered by random
walks around optimal points in the space of BN node orderings. Differences in
algorithm performance are explained in terms of these landscapes, which in
turn are related to properties of the BN structures. These initial findings
suggest that fitness landscape analysis is a promising approach for explaining
existing empirical performance comparisons with further potential for
understanding the relative difficulty of benchmark problems and the robustness
of particular algorithms.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Muehleisen:2011:MIiaDSSS,
  title     = {Multi-Level Indexing in a Distributed Self-Organized Storage System},
  author    = {Hannes Muehleisen and Tilman Walther and Robert Tolksdorf},
  pages     = {988--993},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Parallel and distributed algorithms, Ant colony optimization, Dynamic and uncertain environments.},
  abstract  = {
In many systems providing storage and retrieval operations on data, indices
are used to make these operations more efficient. Distributed storage systems
provide means to distribute the burden of storing and retrieving data onto
multiple different computers. Routing indices can answer the central question
in these systems: Where should one look for a specified data item? To be able
to query for different columns in a relation or different entries in tuples,
indexing for multiple dimensions is necessary. Our group applies a swarm-based
approach to distributed storage leading to a new class of distributed systems,
which are fully self-organized in their behavior and lack any shared global
data structures. In this paper, we research whether multiple levels of routing
indices can be maintained and used in such a distributed and self-organized
storage service. To achieve this, we look into different types of indices and
evaluate them in an experiment.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Peterson:2011:WA,
  title     = {WoLF Ant},
  author    = {Gilbert Peterson and Christopher Mayer and Kevin Cousin},
  pages     = {994--1001},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Ant colony optimization, Adaptive dynamic programming and reinforcement learning},
  abstract  = {
Ant colony optimization (ACO) algorithms can generate quality solutions to
combinatorial optimization problems. However, like many stochastic algorithms,
the quality of solutions worsen as problem sizes grow. In an effort to
increase performance, we added the variable step size off-policy hill-climbing
algorithm called PDWoLF (Policy Dynamics Win or Learn Fast) to several ant
colony algorithms: Ant System, Ant Colony System, Elitist-Ant System,
Rank-based Ant System, and Max-Min Ant System. Easily integrated into each ACO
algorithm, the PDWoLF component maintains a set of policies separate from the
ant colony's pheromone. Similar to pheromone but with different update rules,
the PDWoLF policies provide a second estimation of solution quality and guide
the construction of solutions. Experiments on large traveling salesman
problems (TSPs) show that incorporating PDWoLF with the aforementioned ACO
algorithms that do not make use of local optimizations produces shorter tours
than the ACO algorithms alone.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Plenary Talk: Computer Aided Algorithm Design :  Automated Tuning, Configuration, Selection and Beyond 

% Special Track: Computational Intelligence in Bioinformatics and Computational Biology III
@InProceedings{Islam:2011:NLITiCMAfPSP,
  title     = {Novel Local Improvement Techniques in Clustered Memetic Algorithm for Protein Structure Prediction},
  author    = {Md Kamrul Islam and Madhu Chetty and Manzur Murshed},
  pages     = {1002--1010},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Memetic, multi-meme and hybrid algorithms},
  abstract  = {
Evolutionary algorithms (EAs) often fail to find the global optimum due to
genetic drift. As the protein structure prediction problem is multimodal
having several global optima, EAs empowered with combined application of local
and global search e.g., memetic algorithms, can be more effective. This paper
introduces two novel local improvement techniques for the clustered memetic
algorithm to incorporate both problem specific and search-space specific
knowledge to find one of the optimum structures of a hydrophobic-polar protein
sequence on lattice models. Experimental results show the superiority of the
proposed techniques against existing EAs on benchmark sequences.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chowdhury:2011:AIMtIGRNuS,
  title     = {An Improved Method to Infer Gene Regulatory Network using S-System},
  author    = {Ahsan Raja Chowdhury and Madhu Chetty},
  pages     = {1011--1018},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Gene Regulatory Network (GRN) plays an important role in the understanding of
complex biological systems. In most cases, high throughput microarray gene
expression data is used for finding these regulatory relationships among
genes. In this paper, we present a novel approach, based on decoupled S-System
model, for reverse engineering GRNs. In the proposed method, the genetic
algorithm used for scoring the networks contains several useful features for
accurate network inference, namely a Prediction Initialization (PI) algorithm
to initialize the individuals, a Flip Operation (FO) for better mating of
values and a restricted execution of Hill Climbing Local Search over few
individuals. It also includes a novel refinement technique which utilizes the
fit solutions of the genetic algorithm for optimizing sensitivity and
specificity of the inferred network. Comparative studies and robustness
analysis using standard benchmark data set show the superiority of the
proposed method.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Corns:2011:OtEoGBEAfTFSC,
  title     = {On the Effects of Graph Based Evolutionary Algorithms for Training Finite State Classifiers},
  author    = {Steven Corns},
  pages     = {1019--1025},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary computation theory},
  abstract  = {
This work presents a method for evolving finite state machines for the
classification of polymerase chain reaction primers in mice using graph based
evolutionary algorithms. Using these machine learning tools we can compensate
for many lab, organism, and chemical specific factors that can cause these
primers to fail. Using Finite State Classifiers can help to decrease the
number of primers that fail to amplify correctly. For training these
classifiers, fifteen different graph based evolutionary algorithms were used
in two different experiments to explore the effects of diversity preservation
on the development of these classifiers. By controlling the rate at which
information is shared in the evolving population, classifiers with a high
likelihood of not accepting bad primers were found. This proposed tool can act
as a post-production add-on to the standard primer picking algorithm for gene
expression detection in mice to compensate for local factors that may induce
errors.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Competition: Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems I
@InProceedings{LaTorre:2011:BaHDAoRWP,
  title     = {Benchmarking a Hybrid DE-RHC Algorithm on Real World Problems},
  author    = {Antonio LaTorre and Santiago Muelas and Jose-Maria Pena},
  pages     = {1026--1032},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems},
  abstract  = {
Continuous optimization is one of the most active research lines in
evolutionary and metaheuristic algorithms. Since CEC 2005 and CEC 2008
competitions, many different algorithms have been proposed to solve continuous
problems. The advances on this type of problems are of capital importance as
many real- world problems from very different domains (biology, engineering,
data mining, etc.) can be formulated as the optimization of a continuous
function. For this reason, we have proposed a hybrid DE-RHC algorithm that
combines the search strength of Differential Evolution with the explorative
ability of a Random Hill Climber, which can help the Differential Evolution
algorithm to reach new promising areas in difficult fitness landscapes, such
as those than can be found on real-world problems. To evaluate this approach,
the benchmark problems proposed in the "Testing Evolutionary Algorithms on
Real-world Numerical Optimization Problems" CEC 2011 special session have been
considered.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Elsayed:2011:GwaNMCfSICP,
  title     = {GA with a New Multi-Parent Crossover for Solving IEEE-CEC2011 Competition Problems},
  author    = {Saber Elsayed and Ruhul Sarker and Daryl Essam},
  pages     = {1033--1039},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems},
  abstract  = {
Over the last two decades, many Genetic Algorithms have been introduced for
solving optimization problems. Due to the variability of the characteristics
in different optimization problems, none of these algorithms performs
consistently over a range of problems. In this paper, we introduce a GA with a
new multi-parent crossover for solving a variety of optimization problems. The
proposed algorithm also uses both a randomized operator as mutation and
maintains an archive of good solutions. The algorithm has been applied to
solve the set of real world problems proposed for the IEEE-CEC2011
evolutionary algorithm competition.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Elsayed:2011:DEwMSfSCRNOP,
  title     = {Differential Evolution with Multiple Strategies for Solving CEC2011  Real-world Numerical Optimization Problems},
  author    = {Saber Elsayed and Ruhul Sarker and Daryl Essam},
  pages     = {1040--1047},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems},
  abstract  = {
Over the last two decades, many Differential Evolution (DE) strategies have
been introduced for solving Optimization Problems. Due to the variability of
the characteristics in optimization problems, no single DE algorithm performs
consistently over a range of problems. In this paper, for a better coverage of
problem characteristics, we introduce a DE algorithm framework that uses
multiple search operators in each generation. The appropriate mix of the
search operators, for any given problem, is determined adaptively. The
proposed algorithm has been applied to solve the set of real world numerical
optimization problems introduced for a special session of CEC2011
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Saha:2011:HdtgoGAfaRWO,
  title     = {How does the good old Genetic Algorithm fare at Real World Optimization?},
  author    = {Amit Saha and Tapabrata Ray},
  pages     = {1048--1055},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems},
  abstract  = {
Genetic Algorithms (GAs) have been studied for more than three decades now.
Their application in optimization problems is well understood and significant
amount of research has gone into the development of efficient GA operators.
Besides GAs, a number of other Evolutionary Algorithms (EAs) and their
performance-enhancing variations have been proposed. However, this upgraded
performance is often achieved at the undesirable cost of introducing
additional user-defined parameters. In an attempt to put forward a case for GA
even when a plethora of other EAs are available, we present the results
obtained by using a Real-Coded, Elite preserving GA on the Real World
optimization problems of IEEE CEC-2011. Based on our preliminary
investigations, we would like to stress that the current work shall help bring
forth the need to take a step back to re-assess the applicability of basic GAs
to practical optimization before yet another Bio- inspired algorithm is
introduced.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Asafuddoula:2011:AADEAaiPoRWOP,
  title     = {An Adaptive Differential Evolution Algorithm and its Performance on Real World Optimization Problems},
  author    = {Md. Asafuddoula and Tapabrata Ray and Ruhul Sarker},
  pages     = {1056--1061},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems},
  abstract  = {
Real world optimization problems are challenging as they often involve a large
number of variables and highly nonlinear constraints and objective functions.
While a number of efficient optimization algorithms and numerous mathematical
benchmark test functions have been introduced in recent years, the performance
of such algorithms have rarely been studied across a range of real world
optimization problems. In this paper, we introduce an improved adaptive
differential evolution (DE) algorithm and report its performance on the newly
proposed real world optimization problems. The proposed differential evolution
algorithm incorporates adaptive parameter control strategies; a center based
differential exponential crossover and hybridization with local search to
improve its efficiency. While comprehensive results of other algorithms on the
test problems are unavailable at this stage, our preliminary comparison with
published results indicates promising performance of the proposed DE across
the range of problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Computational Intelligence and Games II
@InProceedings{Ashlock:2011:SSitIPsD,
  title     = {Shopkeeper Strategies in the Iterated Prisoner's Dilemma},
  author    = {Daniel Ashlock and Christopher Kuusela and Monica Cojocaru},
  pages     = {1062--1069},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Games, Coevolution and collective behavior},
  abstract  = {
A large number of studies have evolved agents to play the iterated prisoner's
dilemma.  This study models a different situation, called the Shopkeeper model
of interaction, in which a state conditioned agent interacts with a series of
other agents without resetting its internal state. This is intended to
simulate the situation in which a shopkeeper interacts with a series of
customers. In a majority of other studies agents either reset their internal
state information before each new encounter or have relatively little internal
state information.  This means they cannot model situations such as being the
customer after the customer from hell.  We train shopkeeper prisoner's dilemma
agents against a variety of distributions of possible customers.  The
shopkeepers specialize their behavior to their customers but sometimes fail to
discover maximally exploitative behaviors.  The evolved shopkeeper agents are
subject to fingerprint analysis and are shown to differ substantially from
agents evolved with a round-robin fitness functions.  Evaluation of the
behavior of the shopkeeper agents with customers they did not encounter during
evolution provides additional evidence that shopkeepers specialized to the
customers, but did so incompletely for the more complex sets of customers.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Parker:2011:FBfEaXCA,
  title     = {Fitness Biasing for Evolving an Xpilot Combat Agent},
  author    = {Gary Parker and Phil Fritzsche},
  pages     = {1070--1075},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
In this paper we present an application of Fitness Biasing, a type of
Punctuated Anytime Learning, for learning autonomous agents in the space
combat game Xpilot. Fitness Biasing was originally developed as a means of
linking the model to the actual robot in evolutionary robotics. We use fitness
biasing with a standard genetic algorithm to learn control programs for a
video game agent in real-time. Xpilot-AI, an Xpilot add-on designed for
testing learning systems, is used to evolve the controller in the background
while periodic checks in normal game play are used to compensate for errors
produced by running the system at a high frame rate. The resultant learned
controllers are comparable to our best hand-coded Xpilot-AI bots, display
complex behavior that resemble human strategies, and are capable of adapting
to a changing enemy in real-time.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Dziuk:2011:CIAtSoC,
  title     = {Creating Intelligent Agents through Shaping of Coevolution},
  author    = {Adam Dziuk and Risto Miikkulainen},
  pages     = {1076--1082},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Creating agents that behave in complex and believable ways in video games and
virtual environments is a difficult task. One solution, shaping, has worked
well in evolution of neural networks for agent control in relatively
straightforward environments such as the NERO video game, but is very
labor-intensive. Another solution, coevolution, promises to establish shaping
automatically, but it is difficult to control. Although these two approaches
have been used separately in the past, they are compatible in principle. This
paper shows how shaping can be applied to coevolution to guide it towards more
effective behaviors, thus enhancing the power of coevolution in competitive
environments. Several automated shaping methods, based on manipulating the
fitness function and the game rules, are introduced and tested in a
"capture-the-flag"-like environment, where the controller networks for two
populations of agents are evolved using the rtNEAT neuroevolution method. Each
of these shaping methods as well as their combinations are superior to a
control, i.e. direct evolution without shaping. They are effective in
different and sometimes incompatible ways, suggesting that different methods
may work best in different environments. Using shaping, it should thus be
possible to employ coevolution to create intelligent agents for a variety of
games.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Avery:2011:CIaTDG,
  title     = {Computational Intelligence and Tower Defence Games},
  author    = {Phillipa Avery and Julian Togelius and Alistar Elvis and  Robert Pieter {van Leeuwen}},
  pages     = {1083--1090},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
The aim of this paper is to introduce the use of Tower Defence (TD) games in
Computational Intelligence (CI) research. We show how TD games can provide an
important test-bed for the often under-represented casual games research area.
Additionally, the use of CI in the TD games has the potential to create a more
interesting, interactive and ongoing game experience for casual gamers. We
present a definition of the current state and development of TD games, and
include a classification of TD game components. We then describe some
potential ways CI can be used to augment the TD experience. Finally, a
prototype TD game based on experience-driven procedural content generation is
presented.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Liang:2011:THSMwMA,
  title     = {Towards Human-like Social Multi-agents with Memetic Automaton},
  author    = {Feng Liang and Ong Yew-Soon and Tan Ah-Hwee and Chen Xian-Shun},
  pages     = {1091--1098},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Memetic, multi-meme and hybrid algorithms, Cultural algorithms, Evolutionary games and multi-agent systems},
  abstract  = {
Memetics is a new science that has attracted increasing attentions in the
recent decades. Beyond the formalism of simple hybrids, adaptive hybrids and
memetic algorithms, the notion of memetic automaton as an adaptive entity that
is self-contained and uses memes as building blocks of information is recently
conceptualized in the context of computational intelligence as potential tools
for effective problem-solving. Taking this cue, this paper embarks a study on
Memetic Multiagent system (MeM) towards human-like social agents with memetic
automaton. Particularly, we introduce a potentially rich meme-inspired design
and operational model, with Darwin's theory of natural selections and Dawkins'
notion of a meme as the principal driving forces behind interactions among
agents, whereby memes formed the fundamental building blocks of the agents'
mind universe. Experimental studies on a Mine Navigation Task indicates the
modeling of memetic agents that resemble the natural way of human interaction
can lead to greater level of adaptivity and effective problem-solving.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Art and Music
@InProceedings{Carina:2011:EoaFD,
  title     = {Evolution of a Fictional Dialogue},
  author    = {Viljoen Carina and Nitschke Geoff and Willem {van Heerden}},
  pages     = {1099--1106},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Art and music, Genetic algorithms, Representation and operators},
  abstract  = {
This paper describes user-supervised Evolutionary Algorithm (EA) experiments
that investigate the evolution of a sensible fictional dialogue. A
user-supervised EA was used given the difficulty of defining a fitness
function for evolving art tasks. Two EAs were tested for the task of evolving
dialogue given an English word population. The EAs required user-assigned
fitness values to be given as input with varying degrees of frequency during
the evolutionary process. The success of the EAs were comparatively evaluated
with respect to two-point recombination and a novel complement gene scan
operator. Task performance was evaluated according to average fitness, word
and genotype diversity, and the number of words used in the fittest evolved
dialogue. Results indicated that for both EAs, complement gene scan was more
effective for evolving complex, sensible and grammatically correct dialogue,
comparative to sentences evolved by the EAs using two-point recombination.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ashlock:2011:FFfStMS,
  title     = {Fitness Functions for Searching the Mandelbrot Set},
  author    = {Daniel Ashlock and Joseph Brown},
  pages     = {1107--1114},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Art and music, Representation and operators},
  abstract  = {
The Mandelbrot set is a famous fractal.  It serves as the source of a large
number of complex mathematical images.  Evolutionary computation can be used
to search the Mandelbrot set for interesting views.  This study compares the
results of using several different fitness functions for this search.  Some of
the fitness functions give substantial control over the appearance of the
resulting views while others simply locate parts of the Mandelbrot set in
which there are complicated structures.  All of the fitness functions are
based on finding desirable patterns in the number of iterations of the basic
Mandelbrot formula to diverge on a set of points arranged in a regular grid
near the boundary of the set.  It is shown that using different fitness
functions causes an evolutionary algorithm to locate difference types of views
into the Mandelbrot set.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Brown:2011:AoFPMI,
  title     = {Autogeneration of Fractal Photographic Mosaic Images},
  author    = {Joseph Alexander Brown and Daniel Ashlock and Sheridan Houghten and John Orth},
  pages     = {1115--1122},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Art and music, Genetic algorithms},
  abstract  = {
We present a novel method for the creation of photographic mosaic images using
fractals generated via evolutionary techniques.  A photomosaic is a rendering
of an image performed by placing a grid of smaller images that permit the
original image to be visible when viewed from a distance.  The problem of
selecting the smaller images is a computationally intensive one. In this study
we use an evolutionary algorithm to create fractal images on demand to
generate tiles of the photomosaic.  A number of images and tile resolutions
are tested yielding acceptable results.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Fernandes:2011:FPtCPCSwAA,
  title     = {From Pherographia to Color Pherographia - Color Sketching with Artificial Ants},
  author    = {Carlos M. Fernandes and Carlos Isidoro and Fabio Barata and Agostinho C. Rosa and Juan Julian Merelo},
  pages     = {1123--1130},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Art and music, Coevolution and collective behavior},
  abstract  = {
Ant algorithms are known to return effective results in those problems that
may be reduced to finding paths through a graph. However, this class of
bio-inspired heuristics have raised the interest of the artistic community as
well, namely of the artists that work on the blurred border between art and
science. This paper describes an extension of an ant algorithm that, although
has been designed as an edge detection tool and a model for collective
perception, has also been used for creating artworks that were exhibited to a
heterogeneous audience. The algorithm is a self-organized and stigmergic
social insects' model that is able to evolve lines along the contours of an
image, in a decentralized and local manner. The result is the emergence of
global patterns called pheromone maps. These maps - which were later named
with the term pherographia - are grayscale sketches of the original
black-and-white image on top of which the model evolves. This work goes beyond
grayscale images and addresses colored pherographia, by proposing several
image transformation and border selection methods based on behavioral
variations of the basic algorithm.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Nairat:2011:CEAtGS,
  title     = {Character Evolution Approach to Generative Storytelling},
  author    = {Malik Nairat and Palle Dahlstedt and Mats Nordahl},
  pages     = {1131--1136},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Art and music, Evolutionary games and multi-agent systems},
  abstract  = {
In storytelling authors need efficient tools to inspire them in their creation
process. We propose a generative drama approach that integrates human
creativity by using an agent-based system where the characters are developed
using interactive evolution. The author can then create a scenario from the
agents' interaction which provides a foundation for the desired story, which
is given its final artistic form through a mapping to a visual representation.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Real World  Applications IV
@InProceedings{Segredo:2011:AMMAftFAP,
  title     = {A Multiobjectivised Memetic Algorithm for the Frequency Assignment Problem},
  author    = {Eduardo Segredo and Carlos Segura and Coromoto Leon},
  pages     = {1137--1144},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Memetic, multi-meme and hybrid algorithms, Real-world applications, Multiobjective optimization},
  abstract  = {
This work presents a set of approaches used to deal with the Frequency
Assignment Problem (FAP), which is one of the key issues in the design of
Global System for Mobile Communications (GSM) networks. The used formulation
of the FAP is focused on aspects which are relevant for real-world GSM
networks. The best up to date frequency plans for the considered version of
the FAP had been obtained by using parallel memetic algorithms. However, such
approaches suffer from premature convergence with some real world instances.
Multiobjectivisation is a technique which transforms a mono-objective
optimisation problem into a multi-objective one with the aim of avoiding
stagnation. A Multiobjectivised Memetic Algorithm, based on the well-known
Non-Dominated Sorting Genetic Algorithm II (NSGA-II) together with its
required operators, is presented in this paper. Several multiobjectivised
schemes, based on the addition of an artificial objective, are analysed. They
have been combined with a novel crossover operator. Computational results
obtained for two different real-world instances of the FAP demonstrate the
validity of the proposed model. The new model provides benefits in terms of
solution quality, and in terms of time saving. The previously known best
frequency plans for both tested real-world networks have been improved.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Coia:2011:AEoCBA,
  title     = {Automatic Evolution of Conceptual Building Architectures},
  author    = {Corrado Coia and Brian Ross},
  pages     = {1145--1152},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming, Real-world applications, Art and music},
  abstract  = {
An evolutionary approach to the automatic generation of 3D building topologies
is presented. Genetic programming is used to evolve shape grammars. When
interpreted, the shape grammars generate 3D models of buildings. Fitness
evaluation considers user-specified criteria that evaluate different aspects
of the model geometry. Such criteria might include maximizing the number of
unique normals, satisfying target height requirements, and conforming to
supplied shape contours. Multi-objective evaluation is used to analyze and
rank model fitness, based on the varied user-supplied criteria. A number of
interesting models complying to given geometric specifications have been
successfully evolved with the approach. A motivation for this research
application is that it can be used as a generator of conceptual designs, to be
used as inspirations for refinement or further exploration.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Thillainathan:2011:LfSPbGSPiCE,
  title     = {LRGA for Solving Profit based Generation Scheduling Problem in Competitive Environment},
  author    = {Logenthiran Thillainathan and Dipti Srinivasan},
  pages     = {1153--1159},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Real-world applications, Hybrid Systems of Computational Intelligence:},
  abstract  = {
Deregulated power industries increase the efficiency of electricity production
and distribution, and offer higher quality, secure, and more reliable
electricity at low prices. In a deregulated environment, utilities are not
required to meet the total load demand. Generation companies (GENCOs) schedule
the generators that produce less than the predicted load demand and reserve,
but aim to deliver maximum profits. The scheduling of generators depends on
the market price. More number of generating units are committed when the
market price is higher. When more number of generating units are brought in
the deregulated market, more profit can be achieved by producing higher amount
of power. This paper present an algorithm to solve a profit based unit
commitment problem in a deregulated environment. The proposed algorithm has
been developed from generation company's point of view. It maximizes the
profit of  the generation company in the deregulated power and reserve
markets. A hybrid methodology between Lagrangian Relaxation and Generic
Algorithm (LRGA) is used to solve generation scheduling in a day-ahead
competitive electricity market. The results obtained are quite encouraging and
useful in deregulated market optimization.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Hingston:2011:RTwC,
  title     = {Red Teaming with Coevolution},
  author    = {Philip Hingston and Mike Preuss},
  pages     = {1160--1168},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Coevolutionary systems, Evolutionary simulation-based optimization, Real-world applications},
  abstract  = {
In this paper we present a coevolutionary algorithm designed to be used as a
computational tool to assist in red teaming studies. In these applications,
analysts seek to understand the strategic and tactical options available to
each side in a conflict situation. Combining scenario simulations with a
coevolutionary search of parameter space is an approach that has many
attractions. We argue that red teaming applications are sufficiently different
from many others where coevolution is used so that specially designed
algorithms can bring advantages. We illustrate by presenting a new algorithm
that simultaneously evolves strong strategies along with dangerous
counter-strategies. We test the new algorithm on two example problems: an
abstract problem with some difficult characteristics; and a practical red
teaming scenario. Experiments show that the new algorithm is able to solve the
abstract problem well, and that it is able to provide useful insights on the
red teaming scenario.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Algorithmic Evaluations of Genetic Programming
@InProceedings{Barrero:2011:AESotAoCEiGP,
  title     = {An Empirical Study on the Accuracy of  Computational Effort in Genetic Programming},
  author    = {David F. Barrero and Maria R-Moreno and Bonifacio Castano and David Camacho},
  pages     = {1169--1176},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming},
  abstract  = {
Some commonly used performance measures in Genetic Programming are those
defined by John Koza in his first book. These measures, mainly computational
effort and number of individuals to be processed, estimate the performance of
the algorithm as well as the difficulty of a problem. Although Koza's
performance measures have been widely used in the literature, their behaviour
is not well known. In this paper we try to study the accuracy of these
measures and advance in the understanding of the factors that influence them.
In order to achieve this goal, we report an empirical study that attempts to
systematically measure the effects of two variability sources in the
estimation of the number of individuals to be processed and the computational
effort. The results obtained in those experiments suggests that these
measures, in common experimental setups, and under certain circumstances,
might have a high relative error.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Aleshunas:2011:CAoUHiA,
  title     = {Cost-benefit Analysis of Using Heuristics in ACGP},
  author    = {John Aleshunas and Cezary Janikow},
  pages     = {1177--1183},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming},
  abstract  = {
Constrained Genetic Programming (CGP) is a method of searching the Genetic
Programming search space non-uniformly, giving preferences to certain
subspaces according to some heuristics. Adaptable CGP (ACGP) is a method for
discovery of the heuristics. CGP and ACGP have previously demonstrated their
capabilities using first-order heuristics: parent-child probabilities.
Recently, the same advantage has been shown for second-order heuristics:
parent- children probabilities. A natural question to ask is whether we can
benefit from extending ACGP with deeper-order heuristics. This paper attempts
to answer this question by performing cost-benefit analysis while simulating
the higher- order heuristics environment. We show that this method cannot be
extended beyond the current second or possibly third-order heuristics without
a new method to deal with the sheer number of such deeper-order heuristics.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Nguyen:2011:ASoGPwLLaIS,
  title     = {A Study on Genetic Programming with Layered Learning and Incremental Sampling},
  author    = {Thi Hien Nguyen and Xuan Hoai Nguyen and Robert Ian McKay},
  pages     = {1184--1190},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming},
  abstract  = {
In this paper, we investigate the impact of a layered learning approach with
incremental sampling on Genetic Programming (GP). The new system, called GPLL,
is tested and compared with standard GP on twelve symbolic regression
problems. While GPLL does not differ from standard GP on univariate target
functions, it has better training efficiency on problems with bivariate
targets. This indicates the potential usefulness of layered learning with
incremental sampling in improving the efficiency of GP evolutionary learning.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Downey:2011:ETCfLGP,
  title     = {Execution Trace Caching for Linear Genetic Programming},
  author    = {Carlton Downey and Mengjie Zhang},
  pages     = {1191--1198},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming},
  abstract  = {
In this paper we propose a new caching algorithm for LGP based on exploiting
inter-generation program relationships. For each program we cache a partial
summary of program execution, and use this summary to expedite the execution
of all progeny. We study the theory behind our new caching algorithm and
derive equations for optimizing algorithm performance. Through both
theoretical and empirical results we demonstrate that our caching algorithm
can decrease LGP execution time by up to 50\%
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Memetic Algorithms for Complex Problems
@InProceedings{Toledo:2011:AHHAtStMLCLSP,
  title     = {A Hybrid Heuristic Approach to Solve the Multi Level Capacitated Lot Sizing Problem},
  author    = {Claudio Toledo and Renato Oliveira and Paulo Franca},
  pages     = {1199--1206},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Memetic, multi-meme and hybrid algorithms, Genetic algorithms},
  abstract  = {
This paper presents preliminary results found by a hybrid heuristic applied to
solve the Multi-Level Capacitated Lot Sizing Problem (MLCLSP). The proposed
method combines a multi-population genetic algorithm and fix-and-optimize
heuristic. These methods are also integrated to a mathematical programming
approach. For this, a mathematical reformulation of MLCLDP model is proposed
to embed the exact solution of the model in the heuristic approaches. The
hybrid heuristic is evaluated in two sets of benchmark instances. The
solutions found are compared with those reached by other methods from
literature. The preliminary results obtained indicate that the hybrid
heuristic outperforms other approaches in the majority of problems solved.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Pilat:2011:AMMAwASM,
  title     = {ASM-MOMA: Multiobjective Memetic Algorithm with Aggregate Surrogate Model},
  author    = {Martin Pilat and Roman Neruda},
  pages     = {1207--1213},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Memetic, multi-meme and hybrid algorithms, Multiobjective optimization, Multi-objective evolutionary algorithms},
  abstract  = {
Evolutionary algorithms generally require a large number of objective function
evaluations which can be costly in practice. These evaluations can be replaced
by evaluations of a cheaper meta-model (surrogate model) of the objective
functions. In this paper we present a novel distance based aggregate surrogate
model for multiobjective optimization and describe a memetic multiobjective
algorithm based on this model. Various variants of the models are tested and
discussed and the algorithm is compared to standard multiobjective
evolutionary algorithms. We show that our algorithm greatly reduces the number
of required objective function evaluations.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Handoko:2011:CMAfSOPwRECFM,
  title     = {Classification-assisted Memetic Algorithms for Solving Optimization Problems with Restricted Equality Constraint Function Mapping},
  author    = {Stephanus Daniel Handoko and Chee Keong Kwoh and Yew Soon Ong and Jonathan Chan},
  pages     = {1214--1221},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Memetic, multi-meme and hybrid algorithms, Numerical optimization., Meta-modeling and surrogate models},
  abstract  = {
The success of Memetic Algorithms (MAs) has driven many researchers to be more
focused on the efficiency aspect of the algorithms such that it would be
possible to effectively employ MAs to solve computationally expensive
optimization problems where single evaluation of the objective and constraint
functions may require minutes to hours of CPU time. One of the important
design issues in MAs is the choice of the individuals upon which local search
procedure should be applied. Selecting only some potential individuals lessens
the demand for functional evaluations hence accelerates convergence to the
global optimum. In recent years, advances have been made targeting
optimization problems with single equality constraint h(x) = 0. The presence
of previously evaluated candidate solutions with different signs of constraint
values within some localities thus allows the estimation of the constraint
boundary. An individual will undergo local search only if it is sufficiently
close to the approximated boundary. Elegant as it may seem, the approach had
unfortunately assumed that every constraint function maps the design variables
to optimize into unbounded real values. This, however, may not always be the
case in practice. In this paper, we present a strategy to efficiently solve
constrained problems with a single equality constraint; the function of which
maps the design variables into restricted (either strictly non-negative or
strictly non-positive) real values only.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Cruz:2011:UCQAaaLSOiEMA,
  title     = {Using Convex Quadratic Approximation as a Local Search Operator in Evolutionary Multiobjective Algorithms},
  author    = {Andre Cruz and Rodrigo Cardoso and Elizabeth Wanner and Ricardo Takahashi},
  pages     = {1222--1229},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Memetic, multi-meme and hybrid algorithms, Multi-objective evolutionary algorithms, Genetic algorithms},
  abstract  = {
Local search techniques based on Convex Quadratic Approximation (CQA) of
functions are studied here, in order to speed up the convergence and the
quality of solutions in evolutionary multiobjective algorithms. The hybrid
methods studied here pick up points from the nondominated population and
determine a CQA for each objective function. Since the CQA of the functions
and the respective weighted sums are convex, fast deterministic methods can be
used in order to generate approximated Pareto-optimal solutions from the
approximated functions. A new scheme is proposed in this paper, using a CQA
model that represents a lower bound for the function points, which can be
solved via linear programming. This scheme and also another one using the
methodology of linear matrix inequality (LMI) for CQA are coupled with a
canonical implementation of the NSGA-II. Comparison tests are performed, using
Monte Carlo simulations, considering the S-metric with an equivalent final
number of evaluated objective functions and the algorithm execution time. The
results indicate that the proposed scheme is promising.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Cultural and Immune Approaches to Complex Problems
@InProceedings{Ali:2011:BCAwaILSFIF,
  title     = {Boosting Cultural Algorithms with an Incongruous Layered Social Fabric Influence Function},
  author    = {Mostafa Ali and Ayad Salhieh and Randa Abu Snaineh and Robert Reynolds},
  pages     = {1230--1237},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Cultural algorithms, Evolutionary computation theory, Numerical optimization.},
  abstract  = {
In this paper we investigate the emergence and power of a complex social
system based upon principles of cultural evolution. Cultural Algorithms employ
a basic set of knowledge sources, each related to knowledge observed in
various social species. Here we extend the influence and integration function
in Cultural Algorithms by adding a mechanism by which knowledge sources can
spread their influence throughout a population in the presence of
heterogeneous layered social network. The interaction (overlapping) of the
knowledge sources, represented as bounding boxes on the landscape, at the
right level projects how efficient the cooperation is between the agents in
the resultant "Social Network". The inter-related structures that emerge with
this approach are critical to the effective functioning of the approach. We
view these structures as constituting a "normal form" for Cultures within
these real-valued optimization landscapes. Our goal will be to identify the
minimum social structure needed to solve problems of certain complexities. If
this can be accomplished, it means that there will be a correspondence between
the social structure and the problem environment in which it emerged. An
escalating sequence of complex benchmark problems to our system will be
presented. We conclude by suggesting the emergent features are what give
cultural systems their power to learn and adapt.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Reynolds:2011:MCA,
  title     = {Multi-Objective Cultural Algorithms},
  author    = {Robert Reynolds and Dapeng Liu},
  pages     = {1238--1246},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Cultural algorithms, Multi-objective evolutionary algorithms, Multiobjective optimization},
  abstract  = {
Within a cultural context we constantly deal effectively with multiple
objectives. A computational version of cultural systems, Cultural Algorithms,
has been extended to deal with multi-objective optimization problems. These
approaches while employing the basic framework have used only a subset of the
available knowledge sources. In this paper we present an extension of Cultural
Algorithms for Multi-Objective optimization, MOCAT, the fully utilizes all of
the available categories of knowledge sources. The synergy of this ensemble is
demonstrated through the application to an example problem and the results
compared with that of other approaches in metric terms.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Coelho:2011:ACAINfCO,
  title     = {A Concentration-based Artificial Immune Network for Combinatorial Optimization},
  author    = {Guilherme Coelho and Fabricio {de Franca} and Fernando J. {Von Zuben}},
  pages     = {1247--1254},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Artificial immune systems, Discrete and combinatorial optimization.},
  abstract  = {
Diversity maintenance is an important aspect in population-based
metaheuristics for optimization, as it tends to allow a better exploration of
the search space, thus reducing the susceptibility to local optima in
multimodal optimization problems. In this context, metaheuristics based on the
Artificial Immune System (AIS) framework, especially those inspired by the
Immune Network theory, are known to be capable of stimulating the generation
of diverse sets of solutions for a given problem, even though generally
implementing very simple mechanisms to control the dynamics of the network. To
increase such diversity maintenance capability even further, a new
immune-inspired algorithm was recently proposed, which adopted a novel
concentration-based model of immune network. This new algorithm, named
cob-aiNet (Concentration-based Artificial Immune Network), was originally
developed to solve real-parameter single-objective optimization problems, and
it was later extended (with cob-aiNet[MO]) to deal with real- parameter
multi-objective optimization. Given that both cob-aiNet and cob- aiNet[MO]
obtained competitive results when compared to state-of-the-art algorithms for
continuous optimization and also presented significantly improved diversity
maintenance mechanisms, in this work the same concentration-based paradigm was
further explored, in an extension of such algorithms to deal with
single-objective combinatorial optimization problems. This new algorithm,
named cob-aiNet[C], was evaluated here in a series of experiments based on
four Traveling Salesman Problems (TSPs), in which it was verified not only the
diversity maintenance capabilities of the algorithm, but also its overall
optimization performance.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Castro:2011:TMPwaGAIS,
  title     = {Training Multilayer Perceptrons with a  Gaussian Artificial Immune System},
  author    = {Pablo Castro and Fernando J. {Von Zuben}},
  pages     = {1255--1262},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolved neural networks, Artificial immune systems, Estimation of distribution algorithms},
  abstract  = {
In this paper we apply an immune-inspired approach to train  Multilayer
Perceptrons (MLPs)  for classification problems. Our proposal, called Gaussian
Artificial Immune System (GAIS), is an estimation of distribution algorithm that
replaces the traditional mutation and cloning operators with a probabilistic
model, more specifically a Gaussian network, representing the joint distribution
of promising solutions.
Subsequently, GAIS utilizes this probabilistic model for sampling new solutions.
Thus, the algorithm takes into account the relationships among the variables of
the problem, avoiding the disruption of already obtained high-quality partial
solutions (building blocks).
Besides the capability to identify and manipulate building blocks, the algorithm
maintains diversity in the population, performs multimodal optimization and
adjusts the size of the population automatically according to the problem.
 These attributes are generally absent from alternative algorithms, and all were
shown to be useful attributes when optimizing the weights of MLPs, thus guiding
to high-performance classifiers.  GAIS was evaluated in six well-known
classification problems and its performance compares favorably with that
produced by contenders, such as opt-aiNet, IDEA and PSO.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Session: Evolution of Developmental and Generative Systems
@InProceedings{Antonakopoulos:2011:Acgrcoddca,
  title     = {A common genetic representation capable of developing distinct computational architectures},
  author    = {Konstantinos Antonakopoulos and Gunnar Tufte},
  pages     = {1263--1270},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
A big challenge in the area of developmental and generative systems, is the
design of a method for building complex systems with specific structural
and/or functional properties. Most developmental models target specific
computational architectures or structures of strictly defined building blocks,
in both cases developmental models have strong connection to the target
computational architecture/phenotype structure. In this work we seek a common
developmental model that can target different architectures but also to find a
common genetic representation that can include information that enables such a
developmental model. The computational architectures with sparsely connected
computational elements considered herein are cellular automata and boolean
networks. The experiments study the evolvability of the genetic representation
and prove that it is able to build stable structures for distinct
computational architectures.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Steiner:2011:EoGaVFER,
  title     = {Evolvability of Graph- and Vector Field Embryogeny Representations},
  author    = {Till Steiner and Bernhard Sendhoff},
  pages     = {1271--1278},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Most developmental representations for design optimization with evolutionary
computation that have been described in the literature are graph-based
mimicking the interactions observed in biological gene regulatory networks.
Alternative methods that directly manipulate the dynamical control system for
developmental processes have been termed Vector Field Embryogeny (VFE) and
have been applied successfully to cell differentiation. In this paper, we
compare the evolvability of graph-based and vector field representations for
controlling developmental processes. Inspired by the notion of strong
causality in evolutionary strategies, we measure the covariance between
genotype and phenotype changes for both representations. Furthermore, we
propose a measure to characterize the representational power of both methods.
If we compare VFE and graph-based representations with similar
representational power, we notice that the covariance measure and therefore,
the expected evolvability of VFE is higher. We also observe that the
representational power of both methods decreases with increasing degree of
freedom. We speculate that the reason for this could be the increased
probability of the occurrence of strong point attractors.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Eskridge:2011:EoRUIE,
  title     = {Extrapolation of Regularity Using Indirect Encodings},
  author    = {Brent Eskridge},
  pages     = {1279--1286},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
The choice of training data used in evolution can have a significant impact on
the generalized performance of the evolved solutions.  Historically, if the
training set was not representative of the problem's overall state space, the
evolved solutions could not practically be applied to the problem in general.
However, generative systems and indirect encodings are able to identify and
leverage regularities in and the geometry of the state space to produce
effective solutions to complex problems.  This ability presents the
possibility of using the regularity of a problem to effectively extrapolate
evolved solutions to areas of the state space for which the training set was
not representative.  In this work, two different experiments are performed
involving pattern reproduction and robot control to explicitly evaluate this
extrapolation ability.  Results show that an indirect encoding is able to
extrapolate performance in one area of a problem's state space to a new area
in which it has no experience with little to no loss of performance, depending
on the regularities of the problem's state space.  If the regularities were
consistent through the entire state space and across the boundary between
areas in which there was experience and no experience, extrapolation
performance was high, but if the regularities were not consistent, there was a
loss of performance.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Computational Intelligence in Bioinformatics and Computational Biology IV
@InProceedings{Tsang:2011:RAAfCRSSBoIPT,
  title     = {RNADPCompare: An Algorithm for Comparing RNA Secondary Structures Based on Image Processing Techniques},
  author    = {Herbert H. Tsang and Christian Jacob},
  pages     = {1287--1294},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining},
  abstract  = {
In structural biology, structural chemistry, and bioinformatics, Ribonucleic
Acid (RNA) structure comparison is a fundamental problem. It is because
structural comparison can facilitate RNA structure prediction and studies in
RNA energy landscapes and conformational switches as well. There are many
different tools have been proposed for RNA secondary structure comparison.
This paper describes and presents a novel algorithm, RNADPCompare, for
computing similarity measure of RNA secondary structures. The main idea for
this algorithm is to represent the RNA secondary structure as a dot plot, and
then process the dot plot as an image. The algorithm will utilize image
processing techniques and heuristic understanding of the image properties to
compute similarity measure of RNA secondary structures. Since many
evolutionary and machine learning algorithms for RNA secondary structure
design and prediction rely on good metric for examining structural
similarities, therefore this novel metric will make significant contribution
to the advances to these algorithms. An evaluation of the algorithm in terms
of correlation to the native structure is made. The results from the six
sequences of RNA from a variety of sequence lengths and organisms were tested.
When comparing with Sfold, the prediction accuracy of RNADPCompare seems to be
very promising. These results demonstrated that RNADPCompare is highly
competitive in terms of the processing speed and accuracy when compare to
other methods. This supports the use of this algorithm on other research in
RNA secondary structure design and prediction.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Marco:2011:OoPAMUEC,
  title     = {Optimisation of Process Algebra Models Using Evolutionary Computation},
  author    = {David Marco and David Cairns and Carron Shankland},
  pages     = {1295--1300},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
We propose that process algebras and evolutionary algorithms have
complementary strengths for developing models of complex systems. Evolutionary
algorithms are powerful meth- ods for finding solutions to optimisation
problems with large search spaces but require an accurately defined fitness
function to provide valid results. Process algebras are an effective method
for defining models of complex interacting processes, but tuning parameters to
allow model outputs to match experimental data can be difficult. Defining
models in the first place can also be problematic. Our long term goal is to
build a framework to synthesise process algebra models. Here we present a
first step in that development: combining process algebra with an evolutionary
approach to fine tune the numeric parameters of predefined models. The
Evolving Process Algebra (EPA) framework is demonstrated through examples from
epidemiology and computer science.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Yazdani-Salekdeh:2011:ISCeaNESaD,
  title     = {Improving Splice-Junctions Classification employing a Novel Encoding Schema and Decision-Tree},
  author    = {Amin Yazdani Salekdeh and Kay C. Wiese},
  pages     = {1301--1306},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Splice junction sites are important regions in genes, which have been studied
in many DNA related studies in Genetics. Recently some attempts in computer
science have been made to use computational power to distinguish the different
splice junction and non-junction regions in genes. Ambiguity in identifying
nucleotides is an important issue when dealing with splice junction regions,
which has been ignored in many approached toward this problem up to this date.
In this paper a novel method is proposed along with an encoding schema which
take ambiguities into account using intuitions from probability. The method is
based on Decision Trees, using K-Nearest Negihbours classifier, and Support
Vector Machines. The results have shown the significance of using the proposed
encoding schema and classification method in improving splice junction
classification.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Amaral:2011:TaofEA,
  title     = {Transgenic, an operator for Evolutionary Algorithms},
  author    = {Laurence Amaral and Estevam Hruschka},
  pages     = {1307--1313},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Data mining},
  abstract  = {
In the 1950s and the 1960s several computer scientists independently studied
evolutionary systems with the idea that evolution could be used as an
optimization tool for engineering problems. For these evolutionary-computation
researchers, the mechanisms of evolution seem well suited for some of the most
pressing computational problems in many fields. Ideas from Genetics are
usually incorporated into evolutionary algorithms, such as: haploid crossover,
mutation, diploid, inversion, gene doubling, deletion, and others. In the
present study, we proposed an operator, named transgenic, for evolutionary
algorithms, especially designed for Genetic Algorithms (GA). This operator is
inspired in genetically modified organisms (GMOs), where important features
are introduced into their genome artificially. The transgenic operator uses
historical information to choose the best attributes, converging to the better
results faster than traditional GAs. The GA, used in this study, allow the
discovery of concise, yet accurate, high-level rules (from a biological and
synthetic database) which can be used as a classification system. The obtained
results show that transgenic operator is promising, obtaining better or the
same results with a low number of generations and smaller populations.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Competition: Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems II
@InProceedings{Wang:2011:EoDaDECfRNOP,
  title     = {Estimation of Distribution and Differential Evolution Cooperation for Real-world Numerical Optimization Problems},
  author    = {Yu Wang and Bin Li and Kaibo Zhang},
  pages     = {1314--1320},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems},
  abstract  = {
During the last decade, a large number of evolutionary algorithmic variants
have been proposed for diverse optimization tasks, most of which are practical
engineering applications. In the previous research, one variant is always
designed for one specific engineering application. In IEEE Congress on
Evolutionary Competition, the numerical optimization competition is held to
benchmark different optimization algorithms for more general applications. In
this paper, we conduct the optimization method estimation of distribution and
differential evolution (ED-DE) by implementing a two-stage ensemble idea,
whose effectiveness and efficiency has been experimentally verified.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Singh:2011:PoaHEAoC2RWOP,
  title     = {Performance of a Hybrid EA-DE-Memetic Algorithm on CEC 2011 Real World Optimization Problems},
  author    = {Hemant Kumar Singh and Tapabrata Ray},
  pages     = {1321--1325},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems},
  abstract  = {
Evolutionary Algorithms (EAs), in their traditional form or in combination as
in Memetic Algorithms (MAs), have been quite successful in solving a variety
of optimization problems in the past. More recently, several excellent
Differential Evolution (DE) based algorithms have been proposed which have had
outstanding success in IEEE Congress on Evolutionary Computation (CEC)
competition problems. Inspired by previous studies, we propose an algorithm
combining the strengths of EA, DE and MA in this paper. The algorithm utilizes
a population of random solutions to start with and generates a child
population either through EA or DE based evolution with equal probability.
Local search is then performed from one of the solutions in the population for
further improvement objective value. To avoid stagnation, re-initialization of
the population is performed whenever the local search is unable to improve the
values consecutively for a prescribed number of generations. The performance
of the proposed algorithm is presented in this paper for the newly introduced
real world optimization problems for CEC 2011 competition.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Korosec:2011:TCDAAAtROP,
  title     = {The Continuous Differential Ant-Stigmergy Algorithm Applied to Real-World Optimization Problems},
  author    = {Peter Korosec and Jurij Silc},
  pages     = {1326--1333},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems},
  abstract  = {
In this paper, an optimization algorithm is proposed and its performance
assessment for bound and equality/inequality constrained numerical
optimization is presented. The proposed algorithm is called Continuous
Differential Ant-Stigmergy Algorithm and is derived from the Differential
Ant-Stigmergy Algorithm, which transforms a real-parameter optimization
problem into a graph-search problem. The original algorithm is extended to use
arbitrary real offsets to navigate through the search space. Experimental
results are given for the Real World Optimization Problems proposed for the
Special Session on Testing Evolutionary Algorithms on Real-world Numerical
Optimization Problems at 2011 IEEE Congress on Evolutionary Computation.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Bandaru:2011:MSaAMfRWSOO,
  title     = {Modified SBX and Adaptive Mutation for Real World Single Objective Optimization},
  author    = {Sunith Bandaru and Rupesh Tulshyan and Kalyanmoy Deb},
  pages     = {1334--1341},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems},
  abstract  = {
Real-world optimization problems often involve highly non-linear objectives
and constraints. From an application point of view, it is usually desirable
that the global optimum be achieved in such cases. Among selection, crossover
and mutation operators of a genetic algorithm, the last two are responsible
for search and diversity maintenance. By improving these operators, the
efficiency of GAs can be improved. In this paper, we solve the problems
specified in "CEC 2011 Competition on Testing Evolution Algorithms on Real
World Optimization Problems" using a variation of the Simulated Binary
Crossover (SBX) which adaptively shifts between parent-centric and
mean-centric recombinations. The shift occurs automatically during program
execution through the use of current population statistics and is expected to
improve the performance of GA. Further, we also employ a self- adaptive
mutation strategy developed earlier.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Competition: Human-like Bot: A competition for CEC2011

% Special Session: Meta-heuristic Approaches for Global Continuous Optimization
@InProceedings{Schaul:2011:CO,
  title     = {Curiosity-Driven Optimization},
  author    = {Tom Schaul and Yi Sun and Daan Wierstra and Faustino Gomez and Juergen Schmidhuber},
  pages     = {1342--1348},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Meta-modeling and surrogate models, Multi-objective evolutionary algorithms},
  abstract  = {
The principle of artificial curiosity directs active exploration towards the
most informative or most interesting data.  We show its usefulness for global
black box optimization when data point evaluations are expensive. Gaussian
process regression is used to model the fitness function based on all
available observations so far. For each candidate point this model estimates
expected fitness reduction, and yields a novel closed-form expression of
expected information gain. A new type of Pareto-front algorithm continually
pushes the boundary of candidates not dominated by any other known data
according to both criteria, using multi-objective evolutionary search. This
makes the exploration-exploitation trade-off explicit, and permits maximally
informed data selection.  We illustrate the robustness of our approach in a
number of experimental scenarios.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Cobos:2011:AHATDATHMFWDC,
  title     = {A Hyper-Heuristic Approach To Design And Tuning Heuristic Methods For Web Document Clustering},
  author    = {Carlos Cobos and Martha Mendoza and Elizabeth Leon},
  pages     = {1349--1357},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Heuristics, metaheuristics and hyper-heuristics, Classification, clustering, data analysis and data mining},
  abstract  = {
This paper introduces a new description-centric algorithm for web document
clustering called HHWDC. The HHWDC algorithm has been designed from a hyper-
heuristic approach and allows defining the best algorithm for web document
clustering. HHWDC uses as heuristic selection methodology two options, namely:
random selection and roulette wheel selection based on performance of
low-level heuristics (harmony search, an improved harmony search, a novel
global harmony search, global-best harmony search, restrictive mating,
roulette wheel selection, and particle swarm optimization). HHWDC uses the
k-means algorithm for local solution improvement strategy, and based on the
Bayesian Information Criteria is able to automatically define the number of
clusters. HHWDC uses two acceptance/replace strategies, namely: Replace the
worst and Restricted Competition Replacement. HHWDC was tested with data sets
based on Reuters-21578 and DMOZ, obtaining promising results (better precision
results than a Singular Value Decomposition algorithm)
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Real World Applications V
@InProceedings{Falcon:2011:FIwBAFiPaDS,
  title     = {Fault Identification with Binary Adaptive Fireflies in Parallel and Distributed Systems},
  author    = {Rafael Falcon and Marcio Almeida and Amiya Nayak},
  pages     = {1358--1365},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Heuristics, metaheuristics and hyper-heuristics, Real-world applications, Discrete and combinatorial optimization.},
  abstract  = {
The efficient identification of hardware and software faults in parallel and
distributed systems still remains a serious challenge in today's most prolific
decentralized environments. System-level fault diagnosis is concerned with the
detection of all faulty nodes in a set of interconnected units. This is
accomplished by thoroughly examining the collection of outcomes of all tests
carried out by the nodes under a particular test model. Such task has
non-polynomial complexity and can be posed as a combinatorial optimization
problem, whose optimal solution has been sought through bio-inspired methods
like genetic algorithms, ant colonies and artificial immune systems.

In this paper, we employ a swarm of artificial fireflies to quickly and
reliably navigate across the search space of all feasible sets of faulty units
under the invalidation and comparison test models. Our approach uses a binary
encoding of the potential solutions (fireflies), an adaptive light absorption
coefficient to accelerate the search and problem-specific knowledge to handle
infeasible solutions. The empirical analysis confirms that the proposed
algorithm outperforms existing techniques in terms of convergence speed and
memory requirements, thus becoming a viable approach for real-time fault
diagnosis in large-size systems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chica:2011:Tt13VotTaSALBPbMoaMGA,
  title     = {Tackling the 1/3 Variant of the Time and Space Assembly Line Balancing Problem by Means of a Multiobjective Genetic Algorithm},
  author    = {Manuel Chica and Oscar Cordon and Sergio Damas},
  pages     = {1366--1373},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Real-world applications},
  abstract  = {
The time and space assembly line balancing problem (TSALBP) considers
realistic multiobjective versions of the classical assembly line balancing
involving the joint optimization of conflicting criteria such as the cycle
time, the number of stations, and/or the area of these stations. This
industrial problem is very difficult to solve and of crucial importance in the
manufacturing context. As TSALBP-1/3 contains a set of hard constraints like
precedences or cycle time limits for each station it has been mainly tackled
using multiobjective constructive metaheuristics (e.g. ant colony
optimization). Global search algorithms in general --and multiobjective
genetic algorithms in particular-- have shown to be ineffective to solve this
family of problems up to now. The goal of this contribution is to present a
new multiobjective genetic algorithm design, taking the well known NSGA-II
algorithm as a base and new coding scheme and specific operators, to properly
tackle with the TSALBP. An experimental study on six different problem
instances is used to compare the proposal with the state-of-the-art methods.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Abegaz:2011:SaEBFSaWfFR,
  title     = {SSGA and EDA Based Feature Selection and Weighting for Face Recognition},
  author    = {Tamirat Abegaz and Gerry Dozier and Kelvin Bryant and Joshua Adams and Joseph Shelton and Ricanek Karl and Damon Woodard},
  pages     = {1374--1380},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications, Real-world applications},
  abstract  = {
In this paper, we compare genetic and evolutionary feature selection (GEFeS)
and weighting (GEFeW) using a number of biometric datasets. GEFeS and GEFeW
have been implemented as instances of Steady-State Genetic and Estimation of
Distribution Algorithms. Our results show that GEFeS and GEFeW dramatically
improve recognition accuracy as well as reduce the number of features needed
for facial recognition. Our results also show that the Estimation of
Distribution Algorithm implementation of GEFeW has the best overall
performance.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Costa:2011:TLTIMSUMO,
  title     = {Traffic Lights Timing Inside Microregion Simulator Using Multiobjective Optimization},
  author    = {Breno C. Costa and Paulo E. M. Almeida and Evandro Caldeira},
  pages     = {1381--1386},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Real-world applications, Multi-objective evolutionary algorithms},
  abstract  = {
The growing number of vehicles and pedestrians in the cities increases
difficulties for traffic control. Nowadays application of computational
techniques helps traffic engineers, giving more efficiency, security and
agility to decision making tasks. In this context, a good traffic lights
management improves vehicles flow, decreasing traffic jams and delays. This
paper applies a multiobjective technique to traffic lights timing using Non
Dominated Sorting Genetic Algorithm (NSGA-II) and aggregates the proposed
algorithm to a microregion traffic simulator coupled into Geographic
Information System (GIS). Experiments performed in Porto Alegre area (Brazil)
validate the applied technique, comparing obtained results with similar ones
from earlier reports.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Representation and Operators
@InProceedings{Menzel:2011:EFDCVfEDO,
  title     = {Evolvable Free-Form Deformation Control Volumes for Evolutionary Design Optimization},
  author    = {Stefan Menzel},
  pages     = {1387--1394},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Representation and operators},
  abstract  = {
Evolutionary design optimization for improving the performance of real world
objects, like e.g. car shapes in the context of aerodynamic efficiency,
usually depends on a well-balanced combination of representation, optimizer
and design evaluation method. Shape representation requires a fair trade-off
between minimum number of design parameters and design flexibility which
likewise guarantees a good optimization convergence while allowing manifold
design variations. Recently, shape morphing methods have gained increased
attention because of their capability to represent complex shapes with a
reasonable number of parameters, especially powerful if coupled with numerical
simulations for measuring design performance. Free-form deformation, as
prominent shape morphing representative, relies on an initial grid of control
points, the control volume, which allows the modification of the embedded
shape. The set-up of the control volume is a crucial process which in practice
is done manually based on the experience of the human user. Here, a method for
the automated construction of control volumes is suggested based on a proposed
measure ECV which relies on the concept of evolvability as a potential
capacity of representations to produce successful designs in a reasonable
time. It is shown for target shape matching experiments that optimizations
based on ECV-tuned control volumes provide a significantly better performance
in design optimization.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Moritz:2011:MOCELaB,
  title     = {Mutation Operator Characterization: Exhaustiveness, Locality, and Bias},
  author    = {Ralph Moritz and Tamara Ulrich and Lothar Thiele and Susanne Buerklen},
  pages     = {1395--1402},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Representation and operators},
  abstract  = {
When designing an evolutionary algorithm, one question which arises is what a
good mutation operator should look like. In order to be able to anticipate
which operators may perform well and which may perform poorly, knowledge about
the behavior of the mutation operator is necessary. This paper therefore
presents measures to characterize mutation operators. To this end, we formally
define three operator properties: Exhaustiveness, locality and unbiasedness.
Furthermore, we provide statistical measures with which operators that work on
the same optimization problem can be compared according to each property. The
novelty of our approach is that the properties are formally defined in a
unified manner, and that the measures can be calculated on arbitrary decision
spaces, only assuming that a distance measure between solutions in decision
space is given.

Tests on a binary decision space using several mutation operators with known
properties show that the statistical measures presented in this paper are able
to reflect the properties well. Also, the measures are calculated for mutation
operators of a more complex problem, namely the cluster partitioning problem.
To test the validity of our measures, we introduce an exploration benchmark
that measures how well the solutions can move across the decision space when
applying a mutation operator to them. Tests on both the binary and the
partitioning problem show that our measures reflect the operator behavior
well.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Hill:2011:EtuoaNFGMiGAtIPVoDUL,
  title     = {Examining the use of a Non-Trivial Fixed Genotype-Phenotype Mapping in Genetic Algorithms to Induce Phenotypic Variability over Deceptive Uncertain Landscapes},
  author    = {Seamus Hill and Colm O'Riordan},
  pages     = {1403--1410},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Representation and operators},
  abstract  = {
In nature, living organisms can be viewed as the product of their
genotype-phenotype mapping (GP-map).  This paper presents a GP-map loosely
based on the biological phenomena of transcription and translation, to create
a multi-layered GP-map which increases the level of phenotypic variability. 
The aim of the paper is to examine through the use of a fixed non-trivial
GP-map, the impact of increased phenotypic variability, on search over a set
of deceptive landscapes. The GP-map allows for a  non-injective
genotype-phenotype relationship, and the phenotypic variability of a number of
phenotypes, introduced by the GP-map, are advanced from the genotypes used to
encode them through a basic interpretation of transcription and translation. 
We attempt to analyse the level of variability by measuring diversity, both at
a genotypic and phenotypic level.   The multi-layered GP-map is incorporated
into a Genetic Algorithm, the multi-layered mapping GA (MMGA), and runs over a
number of GA-Hard landscapes.  Initial empirical results appear to indicate
that over deceptive landscapes, as the level of problem difficulty increases,
so too does the benefit of using the proposed GP-map to probe the search
space.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Dymond:2011:Tsosooacpvudcc,
  title     = {The sensitivity of single objective optimization algorithm control parameter values under different computational constraints},
  author    = {Antoine Dymond and Andries P. Engelbrecht and Stephan Heyns},
  pages     = {1411--1418},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Real-world applications, Differential evolution, Particle swarm optimization},
  abstract  = {
When solving a single objective optimization problem, a user desires an
accurate solution, but may be computationally constrained in terms of the
number of objective function evaluations (OFEs) that can be afforded. The OFE
budget is application specific, varying depending on the time, computing
resources, and the nature of the optimization problem. Control parameter value
sensitivity to this OFE budget constraint is investigated for the particle
swarm- and differential evolution optimization algorithms. The algorithms are
tuned to selected testing problems under different OFE budget constraints, and
then their performance is assessed at different OFE budgets from what they
were tuned for. The results give evidence that combinations of optimization
algorithm control parameter values which perform well for high OFE budgets do
not perform well for low OFE budgets and vice versa. This indicates that when
selecting control parameter values for these two algorithms, not only should
the optimization problem characteristics be taken into account, but also the
computational constraints.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Learning Classifier Systems
@InProceedings{Ioannides:2011:IXPoOBP,
  title     = {Improving XCS Performance on Overlapping Binary Problems},
  author    = {Charalambos Ioannides and Kerstin Eder and Geoff Barrett},
  pages     = {1419--1426},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Learning classifier systems},
  abstract  = {
Extended classifier systems (XCS) suffer from suboptimal performance when the
optimal classifiers of the functions they deal with overlap. As this overlap
is the property of Boolean functions and the generalization capabilities of
the ternary alphabet \{0,1,X\}, it is necessary to improve XCSs to better deal
with those functions that make up most of the possible Boolean functions. This
paper proposes two techniques that improve XCS performance, both in terms of
system and population state metrics. The first technique, termed Essentiality
Assessment, alters the current fitness update mechanism by disallowing
competition between potentially essential classifiers. The second technique,
named Individualized Learning Rate, proposes an individually computed learning
rate for each classifier based on the level of generality of each classifier.
The results obtained show improvement and significance both in absolute and
statistical terms, for the vast majority of system and population state
metrics. This paper is a contribution toward improving XCS performance when
dealing with single-step problems that necessarily require overlapping
classifiers for their optimal solution.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Preen:2011:ADGPitXLCS,
  title     = {Arithmetic Dynamical Genetic Programming in the XCSF Learning Classifier System},
  author    = {Richard J. Preen and Larry Bull},
  pages     = {1427--1434},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Learning classifier systems},
  abstract  = {
This paper presents results from an investigation into using a
continuous-valued dynamical system representation within the XCSF Learning
Classifier System. In particular, dynamical arithmetic genetic networks are
used to represent the traditional condition-action production system rules. It
is shown possible to use self-adaptive, open-ended evolution to design an
ensemble of such dynamical systems within XCSF. The results presented herein
show that the collective emergent behaviour of the evolved systems exhibits
competitive performance with those previously reported on a non-linear
continuous-valued reinforcement learning problem. In addition, the introduced
system is shown to provide superior approximations to a number of composite
polynomial regression tasks when compared with conventional tree-based genetic
programming.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Sonstrod:2011:EAaCCR,
  title     = {Evolving Accurate and Comprehensible Classification Rules},
  author    = {Cecilia Sonstrod and Ulf Johansson and Rikard Konig},
  pages     = {1435--1442},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining, Learning classifier systems, Genetic programming},
  abstract  = {
In this paper, Genetic Programming is used to evolve ordered rule sets (also
called decision lists) for a number of benchmark classification problems, with
evaluation of both predictive performance and comprehensibility. The main
purpose is to compare this approach to the standard decision list algorithm
JRip and also to evaluate the use of different length penalties and fitness
functions for evolving this type of model. The results, using 25 data sets
from the UCI repository, show that genetic decision lists with accuracy-based
fitness functions outperform JRip regarding accuracy. Indeed, the best setup
was significantly better than JRip. JRip, however, held a slight advantage
over these models when evaluating AUC. Furthermore, all genetic decision list
setups produced models that were more compact than JRip models, and thus more
readily comprehensible. The effect of using different fitness functions was
very clear; in essence, models performed best on the evaluation criterion that
was used in the fitness function, with a worsening of the performance for
other criteria. Brier score fitness provided a middle ground, with acceptable
performance on both accuracy and AUC. The main conclusion is that genetic
programming solves the task of evolving decision lists very well, but that
different length penalties and fitness functions have immediate effects on the
results. Thus, these parameters can be used to control the trade-off between
different aspects of predictive performance and comprehensibility.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Johansson:2011:OTtETA,
  title     = {One Tree to Explain Them All},
  author    = {Ulf Johansson and Cecilia Sonstrod and Tuve Lofstrom},
  pages     = {1443--1450},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining, Learning classifier systems, Genetic programming},
  abstract  = {
Random forest is an often used ensemble technique, renowned for its high
predictive performance. Random forests models are, however, due to their sheer
complexity inherently opaque, making human interpretation and analysis
impossible. This paper presents a method of approximating the random forest
with just one decision tree. The approach uses oracle coaching, a recently
suggested technique where a weaker but transparent model is generated using
combinations of regular training data and test data initially labeled by a
strong classifier, called the oracle. In this study, the random forest plays
the part of the oracle, while the transparent models are decision trees
generated by either the standard tree inducer J48, or by evolving genetic
programs. Evaluation on 30 data sets from the UCI repository shows that oracle
coaching significantly improves both accuracy and area under ROC curve,
compared to using training data only. As a matter of fact, resulting single
tree models are as accurate as the random forest, on the specific test
instances. Most importantly, this is not achieved by inducing or evolving huge
trees having perfect fidelity; a large majority of all trees are instead
rather compact and clearly comprehensible. The experiments also show that the
evolution outperformed J48, with regard to accuracy, but that this came at the
expense of slightly larger trees.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: TSP and Other Routing Problems
@InProceedings{Yoon:2011:AEGAwFcCfTSP,
  title     = {An Efficient Genetic Algorithm with Fuzzy c-Means Clustering for Traveling Salesman Problem},
  author    = {Jong-Won Yoon and Sung-Bae Cho},
  pages     = {1451--1455},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms},
  abstract  = {
Genetic algorithms (GA) are one of effective approaches to solve the traveling
salesman problem (TSP). When applying GA to the TSP, it is necessary to use a
large number of individuals in order to increase the chance of finding optimal
solutions. However, this incurs high evaluation costs which make it difficult
to obtain fitness values of all the individuals. To overcome this limitation
we propose an efficient genetic algorithm based on fuzzy clustering which
reduces evaluation costs with minimizing loss of performance. It works by
evaluating only one representative individual for each cluster of a given
population, and estimating the fitness values of the others from the
representatives indirectly. A fuzzy c-means algorithm is used for grouping the
individuals and the fitness of each individual is estimated according to
membership values. The experiments were conducted with randomly generated
cities, and the performance of the method was evaluated by comparing to other
GAs. The results showed the usefulness of the proposed method on the TSP.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Azuma:2011:EMOftVIRP,
  title     = {Evolutionary Multi-Objective Optimization for the Vendor-Managed Inventory Routing Problem},
  author    = {Regina M. Azuma and Guilherme Coelho and Fernando J. {Von Zuben}},
  pages     = {1456--1463},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Multiobjective optimization, Discrete and combinatorial optimization.},
  abstract  = {
The class of inventory routing problems (IRPs) is present in several areas,
including automotive industry and cash management for ATM networks. In the
specific case of vendor-managed IRPs, in which the supplier is responsible for
managing the product inventory in each client and for properly providing
replenishments, the challenge is to determine which retailers should be
served, the amount of product that should be delivered to each of these
retailers, and which routes the distribution vehicles should follow, so that
the associated costs are minimized. Although this is clearly a multi-objective
optimization problem, in the literature it has been generally modeled as a
single-objective problem, which limits the scope of the obtained results.
Therefore, this work presents a multi-objective approach to solve one version
of the IRP usually found in the scientific literature, by simultaneously
minimizing both the inventory and transportation costs. The method proposed in
this work is based on the well-known SPEA2 (Strength Pareto Evolutionary
Algorithm) and includes innovative aspects mainly associated with the
representation of candidate solutions, genetic operators and local search. The
experiments were performed on a set of known benchmark IRPs from the
literature, so that the obtained results could be properly compared to the
best solution found for the single-objective version of each problem.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Multi-objective Optimization I
@InProceedings{Ishibuchi:2011:BoEAoMOPwCO,
  title     = {Behavior of EMO Algorithms on Many-Objective Optimization Problems with Correlated Objectives},
  author    = {Hisao Ishibuchi and Naoya Akedo and Hiroyuki Ohyanagi and Yusuke Nojima},
  pages     = {1464--1471},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms},
  abstract  = {
Recently it has been pointed out in many studies that evolutionary multi-
objective optimization (EMO) algorithms with Pareto dominance-based fitness
evaluation do not work well on many-objective problems with four or more
objectives. In this paper, we examine the behavior of well-known and
frequently- used EMO algorithms such as NSGA-II, SPEA2 and MOEA/D on
many-objective problems with correlated or dependent objectives. First we show
that good results on many-objective 0/1 knapsack problems with randomly
generated objectives are not obtained by Pareto dominance-based EMO algorithms
(i.e., NSGA-II and SPEA2). Next we show that the search ability of NSGA-II and
SPEA2 is not degraded by the increase in the number of objectives when they
are highly correlated or dependent. In this case, the performance of MOEA/D is
deteriorated. As a result, NSGA-II and SPEA2 outperform MOEA/D with respect to
the convergence of solutions toward the Pareto front for some many-objective
problems. Finally we show that the addition of highly correlated or dependent
objectives can improve the performance of EMO algorithms on two-objective
problems in some cases.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chiang:2011:MDIMDbaAMSM,
  title     = {MOEA/D-AMS: Improving MOEA/D by an Adaptive Mating Selection Mechanism},
  author    = {Tsung-Che Chiang and Yung-Pin Lai},
  pages     = {1472--1479},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Multiobjective optimization, Numerical optimization.},
  abstract  = {
In this paper we propose a multiobjective evolutionary algorithm based on
MOEA/D for solving multiobjective optimization problems. MOEA/D decomposes a
multiobjective optimization problem into many single-objective subproblems.
The objective of each subproblem is a weighted aggregation of the original
objectives. Using evenly distributed weight vectors on subproblems, solutions
to subproblems form a set of well-spread approximated Pareto optimal solutions
to the original problem. In MOEA/D, each individual in the population
represents the current best solution to one subproblem. Mating selection is
carried out in a uniform and static manner. Each individual/subproblem is
selected/solved once at each generation, and the mating pool of each
individual is determined and fixed based on the distance between weight
vectors on the objective space. We propose an adaptive mating selection
mechanism for MOEA/D. It classifies subproblems into solved ones and unsolved
ones and selects only individuals of unsolved subproblems. Besides, it
dynamically adjusts the mating pools of individuals according to their
distance on the decision space. The proposed algorithm, MOEA/D-AMS, is
compared with two versions of MOEA/D using nine continuous functions. The
experimental results confirm the benefits of the adaptive mating selection
mechanism.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Adam:2011:UCEfDotBBAaIFKBfC,
  title     = {Using Cellular Evolution for Diversification of the Balance Between Accurate and Interpretable Fuzzy Knowledge Bases for Classification},
  author    = {Ghandar Adam and Michalewicz Zbigniew},
  pages     = {1480--1487},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Evolutionary fuzzy systems, Classification, clustering, data analysis and data mining},
  abstract  = {
Recent work combining  population based heuristics and flexible models such as
fuzzy rules, neural networks, and others, has led to novel and powerful
approaches in many problem areas. This study tests an implementation of
cellular evolution for fuzzy rule learning problems and compares the results
with other related approaches. The paper also examines characteristics of the
cellular evolutionary approach in generating more diverse solutions in a
multiobjective specification of the learning task, and finds that solutions
seem to have useful properties that could enable anticipating out of sample
performance. We consider a bi-objective problem of  learning fuzzy classifiers
that balance accuracy and interpretability requirements.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chuan:2011:MDitDoCCS,
  title     = {Multi-objective Decisionmaking in the Detection of Comprehensive Community Structures},
  author    = {Shi Chuan and Yan Zhenyu and Pan Xin and Cai Yanan and Wu Bin},
  pages     = {1488--1494},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Multiobjective optimization, Classification, clustering, data analysis and data mining},
  abstract  = {
Community Detection in complex networks has attracted a lot of attention in
recent years. Compared to the traditional single-objective optimization for
community detection, the multi-objective optimization for community detection
with evolutionary computation is a promising solution. It is an important and
unsolved issue to make use of the optimal solution set returned by
evolutionary multiobjective algorithm for community detection. This paper
adapts a multi-objective community detection algorithm and further proposes
four model selection methods to aid the decision makers to select the
preferable community structures. The experiments with four synthetic and real
social networks illustrate that the proposed method can discover more
authentic and comprehensive community structures than traditional
single-objective approaches.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Session: Greedy Selection in Evolutionary Computation
@InProceedings{Ergezer:2011:OBOfCP,
  title     = {Oppositional Biogeography-Based Optimization for Combinatorial Problems},
  author    = {Mehmet Ergezer and Dan Simon},
  pages     = {1495--1502},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Discrete and combinatorial optimization., L. Graham, G. Parker), Heuristics, metaheuristics and hyper-heuristics},
  abstract  = {
In this paper, we propose a framework for employing opposition-based learning
to assist evolutionary algorithms in solving discrete and combinatorial
optimization problems. To our knowledge, this is the first attempt to apply
opposition to combinatorics. We introduce two different methods of opposition
to solve two different type of combinatorial optimization problems. The first
technique, open-path opposition, is suited for combinatorial problems where
the final node in the graph does not have be connected to the first node, such
as the graph-coloring problem. The latter technique, circular opposition, can
be employed for problems where the endpoints of a graph are linked, such as
the well-known traveling salesman problem (TSP). Both discrete opposition
methods have been hybridized with biogeography-based optimization (BBO).
Simulations on TSP benchmarks illustrate that incorporating opposition into 
BBO improves its performance.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Graham:2011:CoaGSOtTSaaHC,
  title     = {Comparison of a Greedy Selection Operator to Tournament Selection and a Hill Climber},
  author    = {Lee Graham and John Borbone and Gary Parker},
  pages     = {1503--1507},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms},
  abstract  = {
A new deterministic greedy genetic algorithm selection operator with very high
selection pressure, dubbed the "Jugate Adaptive Method" is examined. Its
performance and behavior are compared to those of a canonical genetic
algorithm with tournament selection, and a random-restarting next-ascent
stochastic hill- climber. All three algorithms are tuned using parameter
sweeps to optimize their success rates on five combinatorial optimization
problems, tuning each algorithm for each problem independently. Results were
negative in that the new method was outperformed in nearly all experiments.
Experimental data show the hill climber to be the clear winner in four of five
test problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Parker:2011:TEoUaGFiHGL,
  title     = {The Effects of Using a Greedy Factor in Hexapod Gait Learning},
  author    = {Gary Parker and William Tarimo},
  pages     = {1508--1513},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Robotics,},
  abstract  = {
Various selection schemes have been described for use in genetic algorithms.
This paper investigates the effects of adding greediness to the standard
roulette-wheel selection. The results of this study are tested on a Cyclic
Genetic Algorithm (CGA) used for learning gaits for a hexapod servo-robot. The
effectiveness of CGA in learning optimal gaits with selection based on
roulette-wheel selection with and without greediness is compared. The results
were analyzed based on fitness of the individual gaits, convergence time of
the evolution process, and the fitness of the entire population evolved.
Results demonstrate that selection with too much greediness tends to
prematurely converge with a sub-optimal solution, which results in poorer
performance compared to the standard roulette-wheel selection. On the other
hand, roulette-wheel selection with very low greediness evolves more diverse
and fitter populations with individuals that result in the desired optimal
gaits.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Session: Autonomous Agent Learning
@InProceedings{Handa:2011:DRoSaEIiM,
  title     = {Dimensionality Reduction of Scene and Enemy Information in Mario},
  author    = {Hisashi Handa},
  pages     = {1514--1519},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Games},
  abstract  = {
Mario AI is one of competitions on Computational Intelligence. In the case of
video games,  agents have to cope with a large number of input information in
order to decide their actions at every time step. We have proposed the use of
Isomap, a famous Manifold Learning, to reduce the dimensionality of inputs.
Especially, we have applied it into scene information. In this paper, we newly
extend to enemy information, where the number of enemies is not fixed. Hence,
we introduce the proximity metrics in terms of enemies. The generated
low-dimensional data is used for input values of Neural Networks. That is, at
every time step, transferred data by using a map from raw inputs into the
low-dimensional data are presented to Neural Networks. Experimental results on
Mario AI environment show the effectiveness of the proposed approach.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Allen:2011:RLwAKCfXGA,
  title     = {Reinforcement Learning with Adaptive Kanerva Coding for Xpilot Game AI},
  author    = {Martin Allen and Phil Fritzsche},
  pages     = {1520--1527},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Adaptive dynamic programming and reinforcement learning},
  abstract  = {
The Xpilot-AI video game platform allows the creation of artificially
intelligent and autonomous control agents. At the same time, the Xpilot
environment is highly complex, with very many state variables and action
choices. Basic reinforcement learning (RL) techniques are somewhat limited in
their application when dealing with such large state- and action- spaces,
since the repetition of exposure that is key to their value updates can
proceed very slowly. To solve this problem, state-abstractions are often
generated, allowing learning to move more quickly, but often requiring the
programmer to hand-craft state representations, reward functions, and action
choices in an ad hoc manner. We apply an automated technique for generating
useful abstractions for learning, adaptive Kanerva coding. This method employs
a small sub-set of the original states as a proxy for the full environment,
updating values over the abstract representative prototype states in a manner
analogous to Q-learning. Over time, the set of prototypes is adjusted to
provide more effective coverage and abstraction, again automatically. Our
results show that this technique allows a simple learning agent to double its
survival time when navigating the Xpilot environment, using only a small
fraction of the full state-space as a stand-in and greatly increasing the
potential for more rapid learning.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Parker:2011:QGLUCGA,
  title     = {Quadruped Gait Learning Using Cyclic Genetic Algorithms},
  author    = {Gary Parker and William Tarimo and Michael Cantor},
  pages     = {1528--1533},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary Robotics, Genetic algorithms},
  abstract  = {
Generating walking gaits for legged robots is a challenging task. Gait
generation with proper leg coordination involves a series of actions that are
continually repeated to create sustained movement. In this paper we present
the use of a Cyclic Genetic Algorithm (CGA) to learn gaits for a quadruped
servo-robot with three degrees of movement per leg. An actual robot was used
to generate a simulation model of the movement and states of the robot. The
CGA used the robot's unique features and capabilities to develop gaits
specific for that particular robot. Tests done in simulation show the success
of the CGA in evolving a reasonable control program and preliminary tests on
the robot show that the resultant control program produces a suitable gait.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Hancock:2011:MASFNACUFID,
  title     = {Multi Agent System For Network Attack Classification Using Flow-Based Intrusion Detection},
  author    = {David Hancock and Gary Lamont},
  pages     = {1534--1541},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Defense and cyber security, Multi-objective evolutionary algorithms},
  abstract  = {
Intrusion Detection (ID) is essential for protecting contemporary computer
networks from a range of threats.  Modern ID techniques must cope with
increasingly sophisticated attacks as well as rapidly rising network line
speeds.  Signature-based ID is forced to sample sparsely, increasing the
likelihood of malicious traffic entering the network without scrutiny.
Consequently, flow-based ID is gaining attention as an effective complement.
ID systems are furthermore often characterized as either network-based or
host- based.  The autonomous multi agent design paradigm is a scalable,
attractive alternative for its potential to leverage the strengths of both
architectures: the broad perspective and visibility into distributed malicious
activity provided by network-based ID, and the comprehensive view of the local
node provided by host-based ID.  This paper therefore develops an architecture
for a new multi agent, flow-based intrusion detection sysem.  The architecture
is designed in two iterations of increasing complexity.  These innovative ID
designs use a ``repuation'' system to permit agents to dynamically find nodes
that are most effective for classifying malicious network activity.
Furthermore, each system design includes the development of an innovative
classifier that uses multi objective evolutionary algorithms to aid in the
search for effective operational parameter values.  Evaluation using an
extensive agent simulation framework highlights the conditions under which the
reputation system provides a significant classification benefit.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Competition: Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems III
@InProceedings{Alshammari:2011:IMLltbtptsaVt,
  title     = {Is Machine Learning losing the battle to produce transportable signatures against VoIP traffic?},
  author    = {Riyad Alshammari and A. Nur Zincir-Heywood},
  pages     = {1542--1549},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Related Areas and Applications:Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems},
  abstract  = {
Traffic classification becomes more challenging since the traditional
techniques such as port numbers or deep packet inspection are ineffective
against voice over IP (VoIP) applications, which uses non-standard ports and
encryption. Statistical information based on network layer with the use of
machine learning (ML) can achieve high classification accuracy and produce
transportable signatures. However, the ability of ML to find transportable
signatures depends mainly on the training data sets. In this paper, we explore
the importance of sampling training data sets for the ML algorithms,
specifically Genetic Programming, C5.0, Naive Bayesian and AdaBoost, to find
transportable signatures. To this end, we employed two techniques for sampling
network training data sets, namely random sampling and consecutive sampling.
Results show that random sampling and 90-minute consecutive sampling have the
best performance in terms of accuracy using C5.0 and SBB, respectively. In
terms of complexity, the size of C5.0 solutions increases as the training size
increases, whereas SBB finds simpler solutions.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Reynoso-Meza:2011:HDAWACOFSRNOP,
  title     = {Hybrid DE Algorithm With Adaptive Crossover Operator For Solving Real-World Numerical Optimization Problems},
  author    = {Gilberto Reynoso-Meza and Javier Sanchis and Xavier Blasco and Juan M. Herrero},
  pages     = {1550--1555},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems},
  abstract  = {
In this paper, the results for the CEC 2011 Competition on testing
evolutionary algorithms on real world optimization problems using a hybrid
differential evolution algorithm are presented. The proposal uses a local
search routine to improve convergence and an adaptive crossover operator.
According to the obtained results, this algorithm shows to be able to find
competitive solutions with reported results.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Mallipeddi:2011:EDEAfCP,
  title     = {Ensemble Differential Evolution Algorithm for CEC2011 Problems},
  author    = {Rammohan Mallipeddi and Nagaratnam Suganthan Ponnuthurai},
  pages     = {1556--1563},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Differential evolution, Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems (Chair: P. Suganthan)},
  abstract  = {
Differential Evolution (DE) is a simple yet efficient stochastic algorithm for
solving real world problems. To achieve optimal performance with DE, time
consuming parameter tuning is essential as its performance is sensitive to the
choice of the mutation and crossover strategies and their associated control
parameters. During different stages of DE's evolution, different combinations
of mutation and crossover strategies with different parameter settings can be
appropriate. Based on this observation different adaptive and self-adaptive
techniques have been proposed. In this paper, we employ a DE with an ensemble
of mutation and crossover strategies and their associated control parameters
known as EPSDE. In EPSDE, a pool of distinct mutation and crossover strategies
along with a pool of values for each control parameter coexists throughout the
evolution process and competes to produce offspring. The performance of EPSDE
is evaluated on a set of real world problems taken from different fields of
engineering and presented in the technical report of Conference on
Evolutionary Computation (CEC) 2011.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ankush:2011:MDEwLSAfRWO,
  title     = {Modified Differential Evolution with Local Search Algorithm for Real World Optimization},
  author    = {Mandal Ankush and Aveek Kumar Das and Prithwijit Mukherjee and Swagatam Das and P. N. Suganthan},
  pages     = {1564--1571},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Differential evolution, Testing Evolutionary Algorithms on Real-world Numerical Optimization Problems},
  abstract  = {
Real world optimization problems are used to simulate the performance of any
Evolutionary Algorithm (EA) over real world applications. This is why the
performance of any EA over the real world optimization problems is very
important for judging its efficiency. In this work, we represent a
multi-population based memetic algorithm CDELS. It is hybridization of a
competitive variant of Differential Evolution (DE) and a Local Search method.
As the number of optima is large in this case, we have also incorporated a
distant search method to hop from one optima to other optima. However, it is
well known that DE has fast but less reliable convergence property. To
overcome this limitation, a hybrid mutation strategy is developed to balance
between exploration and thorough search. In addition, a proximity checking
method is applied to distribute the subpopulations over a larger portion of
the search space as this further enhances the searching ability of the
algorithm. The performance of CDELS algorithm is evaluated on the test suite
provided for the Competition on Testing Evolutionary Algorithms on Real-world
Numerical Optimization Problems in the 2011 IEEE Congress on Evolutionary
Computation and the simulation results are shown in this paper.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Workshop: Human-like Bots

% Special Session: Evolutionary Algorithms with Statistical & Machine Learning Techniques
@InProceedings{Echegoyen:2011:OtLoEiEoDA,
  title     = {On the Limits of Effectiveness in Estimation of Distribution Algorithms},
  author    = {Carlos Echegoyen and Qingfu Zhang and Alexander Mendiburu and Roberto Santana and Jose Antonio Lozano},
  pages     = {1572--1579},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Which problems a search algorithm can effectively solve is a fundamental issue
that plays a key role in understanding and developing algorithms. In order to
study the ability limit of estimation of distribution algorithms (EDAs), this
paper experimentally tests three different EDA implementations on a sequence
of additively decomposable functions (ADFs) with an increasing number of
interactions among binary variables. The results show that the ability of EDAs
to solve problems could be lost immediately when the degree of variable
interaction is larger than a threshold. We argue that this phase-transition
phenomenon is closely related with the computational restrictions imposed in
the learning step of this type of algorithms. Moreover, we demonstrate how the
use of unrestricted Bayesian networks rapidly becomes inefficient as the
number of sub-functions in an ADF increases. The study conducted in this paper
is useful in order to identify patterns of behavior in EDAs and, thus, improve
their performances.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Malago':2011:IlLRiMNbE,
  title     = {Introducing l1-regularized Logistic Regression in Markov Networks based EDAs},
  author    = {Luigi Malago' and Matteo Matteucci and Gabriele Valentini},
  pages     = {1580--1587},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Estimation of distribution algorithms, Discrete and combinatorial optimization.},
  abstract  = {
Estimation of Distribution Algorithms evolve populations of candidate
solutions to an optimization problem by introducing a statistical model, and
by replacing classical variation operators of Genetic Algorithms with
statistical operators, such as estimation and sampling. The choice of the
model plays a key role in the evolutionary process, indeed it strongly affects
the convergence to the global optimum. From this point of view, in a black-box
context, especially when the interactions among variables in the objective
function are sparse, it becomes fundamental for an EDA to choose the right
model, able to encode such correlations. In this paper we focus on EDAs based
on undirected graphical models, such as Markov Networks. To learn the topology
of the graph we apply a sparse method based on {$\backslash$}l1-regularized
logistic regression, which has been demonstrated to be efficient in the
high-dimensional case, i.e., when the number of observations is much smaller
than the sample space. We propose a new algorithm within the DEUM framework,
called {$\backslash$}deuml1, able to learn the interactions structure of the
problem without the need of prior knowledge, and we compare its performance
with other popular EDAs, over a set of well known benchmarks.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Valdes:2011:ECMfHLE,
  title     = {Evolutionary Computation Methods for Helicopter Loads Estimation},
  author    = {Julio J. Valdes and Catherine Cheung and Weichao Wang},
  pages     = {1588--1595},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Multiobjective optimization},
  abstract  = {
The accurate estimation of component loads in a helicopter is an important
goal for life cycle management and life extension efforts. This paper explores
the use of evolutionary computational methods to help estimate some of these
helicopter dynamic loads. Thirty standard time-dependent flight state and
control system parameters were used to construct a set of 180 input variables
to estimate the main rotor blade normal bending during forward level flight at
full speed. Evolutionary computation methods (single and multi-objective
genetic algorithms) optimizing residual variance, gradient, and number of
predictor variables were employed to find subsets of the input variables with
modeling potential. Clustering was used for composing a statistically
representative training set. Machine learning techniques were applied for
prediction of the main rotor blade normal bending involving neural networks,
model trees (black and white box techniques) and their ensemble models. The
results from this work demonstrate that reasonably accurate models for
predicting component loads can be obtained using smaller subsets of predictor
variables found by evolutionary computation based approaches.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Zhou:2011:AEoDAboNDE,
  title     = {An Estimation of Distribution Algorithm based on Nonparametric Density Estimation},
  author    = {Luhan Zhou and Aimin Zhou and Guixu Zhang and Chuan Shi},
  pages     = {1596--1603},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Estimation of distribution algorithms},
  abstract  = {
Probabilistic models play a key role in an estimation of distribution
algorithm(EDA). Generally, the form of a probabilistic model has to be chosen
before executing an EDA. In each generation, the probabilistic model
parameters will be estimated by training the model on a set of selected
individuals and new individuals are then sampled from the probabilistic model.
In this paper, we propose to use probabilistic models in a different way:
firstly generate a set of candidate points, then find some as offspring
solutions by a filter which is based on a nonparametric density estimation
method. Based on this idea, we propose a nonparametric estimation of
distribution algorithm (nEDA) for global optimization. The major differences
between nEDA and traditional EDAs are (1) nEDA uses a generating-filtering
strategy to create new solutions while traditional EDAs use a model
building-sampling strategy to generate solutions, and (2) nEDA utilizes a
nonparametric density model with traditional EDAs usually utilize parametric
density models.   nEDA is compared with a traditional  EDA which is based on
Gaussian model on a set of benchmark problems. The preliminary experimental
results show that nEDA is promising for dealing with global optimization
problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Real World Applications VI
@InProceedings{Lopez-Jaimes:2011:PItSMADP,
  title     = {Preference Incorporation to Solve Many-Objective Airfoil Design Problems},
  author    = {Antonio Lopez-Jaimes and Alfredo Arias-Montano and Carlos A. {Coello Coello}},
  pages     = {1604--1611},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Real-world applications, Large-scale problems.},
  abstract  = {
In this paper, we assess the convenience of applying a previously proposed
interactive method to solve three aerodynamic airfoil shape optimization
problems with 2, 3, and 6 objectives, respectively. The expensive simulations
required to evaluate the objective functions makes these problems an excellent
example in which the use interactive methods is very advantageous. First, the
search can be focused on the decision maker's region of interest, saving this
way, valuable function evaluations. Second, the preference relation used in
the interactive method helps to deal with a large number of objectives since
it is able to rank incomparable nondominated solutions. The experimental
evaluation reveals that in the three problems studied, the interactive method
achieved a better final solution than a traditional a posteriori method with
no preferences. Nevertheless, in the problem with 6 objectives, only 3 of them
were improved. A possible explanation for this is that local optima become
harder to overcome when the size of the region of interest is very small.
Additional experiments confirmed that the convergence is deteriorated if very
small regions of interest are used.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Walsh:2011:TUoaAMftEoFL,
  title     = {The Use of an Aesthetic Measure for the Evolution of Fractal Landscapes},
  author    = {Paul Walsh and Prasad Gade},
  pages     = {1612--1618},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Art and music, Real-world applications},
  abstract  = {
This paper explores the use of an aesthetic measure to aid the generation of
fractal landscapes. Virtual landscapes are important for applications ranging
from games to simulation. This paper extends work done on the auto generation
of virtual landscapes for climate change visualisation, by adding an aesthetic
measure based fitness function to the evolutionary algorithm, thus reducing
the reliance of the method on user based evaluation. A genetic algorithm that
uses an aesthetic measure of fitness based on information theory is defined.
This GA is used to explore a multi-dimensional parameter space that defines
how 3D virtual landscapes are created. The utility of this fitness measure is
assessed by evaluating the solutions generated by the system with real users.
Results indicate that genetic algorithms that use information theory based
fitness measures do indeed generate virtual artefacts that match user
preferences. Moreover the images generated are visually appealing enough to be
curated for public exhibition along side human artists in art galleries by
professional art critics.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Awad:2011:OoSSSUMGA,
  title     = {Optimization of Spectral Signature Selection Using Multi-Objective Genetic Algorithms},
  author    = {Mohamad Awad and Kenneth {De Jong}},
  pages     = {1619--1626},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Classification, clustering, data analysis and data mining, Real-world applications},
  abstract  = {
Segmentation of satellite images is an important step for the success of the
object detection and recognition in image processing. Segmentation is the
process of dividing the image into disjoint homogeneous regions. There are
many segmentation methods and approaches, the most popular are clustering
methods and approaches such as Fuzzy C-Means (FCM) and K-means. The success of
clustering methods depends strongly on the selection of the initial spectral
signatures. Normally, this is done either manually or randomly, in either case
the outcome is unpredictable. In this paper an unsupervised method based on
Multi-Objective Genetic Algorithm (MOGA) for the selection of spectral
signature from satellite images is described. The new method works by
maximizing the number of the selected pixels (minimize over-segmentation) and
by minimizing the difference between these pixels and their spectral signature
(maximize homogeneity). Experimental results are conducted using a high
resolution SPOT V satellite image, the collected spectral signatures, and the
K-means clustering algorithm. The verification of the segmentation results is
based on a very high resolution satellite image of type QuickBird. The
spectral signatures provided to K-means by MOGA increased the speed of
clustering to approximately 4 times the speed of the random based selection of
signatures. At the same time MOGA improved the accuracy of the results of
clustering using K-means to more than 10 \%.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Tomforde:2011:ROLiRS,
  title     = {Restricted On-line Learning in Real-world Systems},
  author    = {Sven Tomforde and Andreas Brameshuber and Joerg Haehner and Christian Mueller-Schloer},
  pages     = {1627--1634},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Learning classifier systems, Real-world applications, Evolutionary simulation-based optimization},
  abstract  = {
Systems capable of adapting to changing conditions have gained increasing
attention in the last decade. Typically, vast situation and configuration
spaces do not allow for using a predefined set of adaptation policies. Based
on the principles of Organic Computing, a 3-layered learning architecture has
been developed which is capable of coping with the problem by enabling
selfadaptation and self-improvement. A major focus has been set on developing
safety-based and efficient machine learning concepts founding on evolutionary
search heuristics and rule-based learning. The general design has been
successfully applied to safety-critical real-world applications like urban
traffic control and data communication protocols. This paper investigates the
question for which class of technical systems the design is applicable. Thus,
a generalised model based on mathematical functions is introduced and
evaluated. The evaluation demonstrates that the approach works well for
systems where the configuration spaces are steadily representable by functions
of the situation space. This statement holds even in the presence of noise.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Innovations in PSO Algorithms
@InProceedings{Wei:2011:AMPSOfCMOP,
  title     = {A Memetic Particle Swarm Optimization for Constrained Multi-objective Optimization Problems},
  author    = {Jingxuan Wei and Mengjie Zhang},
  pages     = {1635--1642},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Multiobjective optimization},
  abstract  = {
In this paper, a new memetic algorithm for constrained multi-objective
optimization problems is proposed, which combines the global search ability of
particle swarm optimization with an attraction based local search operator for
directed local fine-tuning. Firstly, a new particle updating strategy is
proposed based on the concept of uncertain personal-best to deal with the
problem of premature convergence. Secondly, an attraction based local search
operator is proposed to find good local search direction for the particles.
Finally, the convergence of the algorithm is proved. The proposed algorithm is
examined and compared with two well known existing algorithms on five
benchmark test functions.  The results suggest that the new algorithm can
evolve more good solutions, and the solutions are more widely spread  and
uniformly distributed along the Pareto front than the two existing methods.
The proposed two developments are effective individually, but the combined
effect is much better for these constrained multi-objective optimization
problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chu:2011:FPSOPwPCAeiibfohacp,
  title     = {Fortify Particle Swam Optimizer (PSO) with Principal Components Analysis--An example in improving bound-handling for optimizing high-dimensional and complex problems},
  author    = {Wei Chu and Xiaogang Gao and Soroosh Sorooshian},
  pages     = {1643--1647},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Numerical optimization., Constraint and uncertainty handling},
  abstract  = {
It is reported that the absorbing bound-handling approach may paralyze PSO
when it is applied to high-dimensional and complex problems. In this study, we
introduce principal components analysis (PCA) into PSO in order to remedy the
problem caused by the absorbing bound-handling approach. The experiments on
100- D composition functions demonstrate the effectiveness of PCA.
Furthermore, the strong influence of bound-handling on PSO is also evidently
revealed by the results. The fact that none of the studied bound-handling
methods excels on all of the benchmark functions highlights the necessity of
developing more sophisticated and robust bound-handling approaches that can
facilitate the application of PSO on high-dimensional problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Seren:2011:AHJPSOMfHDUDP,
  title     = {A Hybrid Jumping Particle Swarm Optimization Method for High Dimensional Unconstrained Discrete Problems},
  author    = {Cedric Seren},
  pages     = {1648--1655},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Discrete and combinatorial optimization., Large-scale problems.},
  abstract  = {
This article presents an original adaptation of particle swarm for solving
high dimensional optimization problems with discrete variables. The proposed
method combines an innovative jumping particle swarm optimization technique
which is well adapted to discrete variables with a variable neighborhood local
search heuristic and an efficient stretching technique. A dedicated
mathematical formalism used to handle real-coded discrete variables is defined
previously to the theoretical background section which ends with a full
description of the developed hybrid local/global optimization algorithm. This
section presents among others developed principles an adaptive boundary vector
notion which ensures an efficient convergence for jumping particle swarm
optimization. Proposed hJPSO-VNS algorithm performances are then evaluated for
solving both low and high combinatorial unconstrained optimization problems.
For low dimensions, our hJPSO-VNS method is compared with standard and
variable particle swarm optimization techniques developped by Clerc. For high
dimensional optimization problems, a dedicated benchmark composed of numerous
reference multimodal functions whose search domains have been
disadvantageously discretized is considered. Results are discussed by focusing
on four selected but representative objective functions. Our hJPSO-VNS
optimization technique shows excellent overall performances. Some comments and
perspectives dealing with the future works conclude this paper.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Monson:2011:SACfP,
  title     = {Simple Adaptive Cognition for PSO},
  author    = {Christopher Monson},
  pages     = {1656--1663},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Self-adaptation in evolutionary computation, Numerical optimization.},
  abstract  = {
A simple, effective, computationally cheap, and easily tuned method is
presented for improving PSO performance by automatically adapting acceleration
coefficients.  While this approach can be shown to be effective on its own as
a source of swarm diversity on difficult functions, it is also capable of
enhancing other adaptive strategies commonly employed with PSO. 
Significantly, and unlike many other PSO enhancements designed to improve
swarm diversity, this approach does not typically harm the performance of the
underlying method, allowing it to work well on easy and difficult functions
alike.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Novel Applications
@InProceedings{Hwang:2011:SEoDBNfTAD,
  title     = {Structure Evolution of Dynamic Bayesian Network for Traffic Accident Detection},
  author    = {Ju-Won Hwang and Young-Seol Lee and Sung-Bae Cho},
  pages     = {1664--1670},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Intelligent systems applications},
  abstract  = {
Recently, Bayesian network has been widely used to cope with the uncertainty
of real world in the field of artificial intelligence. Dynamic Bayesian
network, a kind of Bayesian network, can solve problems in dynamic
environments. However, as node and state values of node in Bayesian network
grow, it is very difficult to define structure and parameter of Bayesian
network. This paper proposes a method which generates and evolves structure of
dynamic Bayesian network to deal with uncertainty and dynamic properties in
real world using genetic algorithm. Effectiveness of the generated structure
of dynamic Bayesian network is evaluated in terms of evolution process and the
accuracy in a domain of the traffic accident detection.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Abramson:2011:Htoaeafsa,
  title     = {Hybrid tuning of an evolutionary algorithm for sensor allocation},
  author    = {Myriam Abramson and Ian Will and Ranjeev Mittu},
  pages     = {1671--1677},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary simulation-based optimization, Hybrid Systems of Computational Intelligence:, Particle swarm optimization},
  abstract  = {
The application of evolutionary algorithms to the optimization of sensor
allocation given different target configurations requires the tuning of
parameters affecting the robustness and run time of the algorithm. In this
context, parameter settings in evolutionary algorithms are usually set through
empirical testing or rules of thumb that do not always provide optimal results
within time constraints. Design of experiments (DOE) is a methodology that
provides some principled guidance on parameter settings in a constrained
experiment environment but relies itself on a final inductive step for
optimization. This paper describes a sensor allocation tool developed for
intelligence, surveillance and reconnaissance (ISR) in the maritime domain and
introduces a hybrid methodology based on DOE and machine learning techniques
that enables the tuning of an embedded particle swarm optimization (PSO)
algorithm for different scenarios.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chiang:2011:TTPSAftFLPwSC,
  title     = {Two-Stage Tabu - Particle Swarm Algorithms for the Facility Layout Problem with Size Constraints},
  author    = {Wen-Chyuan Chiang and Gangshu Cai and Xiaojing Xu and Ganesh Mudunuri and Weihang Zhu},
  pages     = {1678--1685},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Discrete and combinatorial optimization.},
  abstract  = {
The Facility Layout Problem (FLP) in this paper is an extension of the
traditional Quadratic Assignment Problems (QAP). While the objective is still
to minimize the summed cost of the (flow * distance), the facilities in the
FLP have different given sizes and their locations must be determined on a
continual planar site. Based on the visual facility layout design system
proposed by Chiang [13], this paper presents a study on using Tabu Search
(TS), Particle Swarm Optimization (PSO) and their combinations (TS+PSO and
PSO+TS) to tackle the FLP. The computation results show that the two-stage
algorithms are able to achieve better results in most cases than TS and PSO
individually on the FLP. The proposed two- stage algorithms and visual layout
design system provide an effective tool to solve the practical FLP.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Session: Evolutionary Computation in Medical Image Analysis
@InProceedings{LaTorre:2011:ADEAftDoSV,
  title     = {A Differential Evolution Algorithm for the Detection of Synaptic Vesicles},
  author    = {Antonio LaTorre and Santiago Muelas and Jose-Maria Pena and Roberto Santana and Angel Merchan-Perez},
  pages     = {1686--1693},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Algorithms:, Biometrics, bioinformatics and biomedical applications},
  abstract  = {
Neurotransmitters used by chemical synapses are stored in synaptic vesicles
that accumulate in axon terminals. The number and position of these vesicles
have been related to some important functional properties of the synapse. For
this reason, an accurate mechanism for semi-automatically counting this small
cellular structures will be of great help for neuroscientists. In this paper,
we present a Differential Evolution algorithm that quantifies the number of
synaptic vesicles in electron micrographs. The algorithm has been tested on
several images that have been obtained from the somatosensory cortex of the
rat and compared with some traditional approaches for detecting circular
structures. Finally, the results have been validated by two independent expert
anatomists.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lepagnot:2011:BCMSBoaMAfDCO,
  title     = {Brain Cine MRI Segmentation Based on a Multiagent Algorithm for Dynamic Continuous Optimization},
  author    = {Julien Lepagnot and Amir Nakib and Hamouche Oulhadj and Patrick Siarry},
  pages     = {1694--1701},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = { Dynamic and uncertain environments., Evolution strategies},
  abstract  = {
In this paper, we propose a multiagent based evolution strategy algorithm,
called CMADO, to evaluate the amplitudes of the deformations of the walls of
the third cerebral ventricle on a brain cine-MR imaging. CMADO based
segmentation technique is applied on a 2D+t dataset to detect the contours of
the region of interest (i.e. lamina terminalis). Then, the successive
segmented contours are matched using a procedure of global alignment. Finally,
local measurements of deformations are derived from the previously determined
matched contours. The validation step is realized by comparing our results to
the measurements achieved on the same patients through a manual segmentation
provided by an expert using Ethovision (c) software.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Multi-objective Optimization II
@InProceedings{Abello:2011:AAAfSDSwTNoTPI,
  title     = {An Adaptive Approach for Solving Dynamic Scheduling with Time-varying Number of Tasks - Part I},
  author    = {Manuel Abello and Lam Thu Bui and Zbigniew Michalewicz},
  pages     = {1702--1709},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms},
  abstract  = {
Changes in environment are common in daily activities and can introduce new
problems. To be adaptive to these changes, new solutions to the problems are
to be found every time change occur.

Our previous publication showed that centroid of non-dominated solutions found
through Multi-Objective Optimization with Evolutionary Algorithm (MOEA) from
previous changes enhances MOEA's search quality of solutions for the current
change. However, the number of tasks in the test environment employed was
fixed. In this two-part paper, we address the dynamic adaptation with time-
varying task number.

To cope with this variability, new components of the solution, corresponding
to the new tasks, are inserted appropriately to all solutions of the previous
changes. Then centroid of these modified solutions is recomputed. Further, to
avoid confusion in solution presentation, the insertion of new components
obliged the use of task ID number greater than the largest of the previous
IDs. The first part of this paper will show that the resulting task numbering
system will alter the centroid significantly which will degrade MOEA's search
quality. To circumvent, task IDs are mapped to new values in order to minimize
difference in IDs between adjacent solution components; an approach which
significantly upgraded MOEA's search performance despite changes in task
number as supported by the obtained results.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Abello:2011:AAAfSDSwTNoTPI,
  title     = {An Adaptive Approach for Solving Dynamic Scheduling with Time-varying Number of Tasks -- Part II},
  author    = {Manuel Abello and Lam Thu Bui and Zbigniew Michalewicz},
  pages     = {1710--1717},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms},
  abstract  = {
Changes in environment are common in daily activities and can introduce new
problems. To be adaptive to these changes, new solutions are to be found every
time change occur. This two-part paper employs a technique called Centroid-
Based Adaptation (CBA) which utilize centroid of non-dominated solutions found
through Multi-objective Optimization with Evolutionary Algorithm (MOEA) from
previous environmental change. This centroid will become part of MOEA's
initial population to find the solutions for the current change.

The first part of our paper deals mainly on the extension of CBA, called
Mapping Task IDs for CBA (McBA), to solve problems resulting from time-varying
number of tasks. This second part will show the versatility of McBA over a
portfolio of algorithms with respect to the degree of changes in environment.

This demonstration was accomplished by finding a model relating the degree of
changes to the performance of McBA using Nonlinear Principal Component
Analysis. From this model, the degree of change at which McBA's performance
becomes unacceptable can be found. Results showed that McBA, and its variant
called Random McBA, can withstand larger environmental changes than those of
other algorithms in the portfolio.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Rudolph:2011:OGFCtODHoSMEA,
  title     = {On Geometrically Fast Convergence to Optimal Dominated Hypervolume of Set-based Multiobjective Evolutionary Algorithms},
  author    = {Guenter Rudolph},
  pages     = {1718--1722},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Convergence, scalability and complexity analysis},
  abstract  = {
The Pareto front of a multiobjective optimization problem can be approximated
neatly by some versions of evolutionary algorithms. The quality of the
approximation can be measured by the hypervolume that is dominated by the
approximation. Open questions concern the existence of population-based
evolutionary algorithms whose population converge to an approximation of the
Pareto front with maximal dominated hypervolume for a given reference point
and, if applicable, the convergence velocity. Here, the existence of such an
algorithm is proven by providing a concrete example that converges to the
maximal dominated hypervolume geometrically fast.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{He:2011:AEMfPMiMEA,
  title     = {An Ensemble Method for Performance Metrics in Multiobjective Evolutionary Algorithms},
  author    = {Zhenan He and Gary Yen},
  pages     = {1723--1728},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Multiobjective optimization},
  abstract  = {
Evolutionary algorithms have been effectively exploited to solve
multiobjective optimization problems. In literature, a heuristic approach is
often taken. For a chosen benchmark problem, the performance of multiobjective
evolutionary algorithms (MOEAs) is evaluated via some heuristic chosen
performance metrics. The conclusion is then drawn based on statistical
findings given the preferable choices of performance metrics. The conclusion,
if any, is often indecisive and reveals no insight pertaining to specific
problem characteristics that the underlying MOEA could perform the best. In
this paper, we introduce an ensemble method to compare MOEAs by combining a
number of performance metrics using double elimination tournament selection.
Double elimination design allows characteristically poor performance of a
quality algorithm under the special environment to still be able to win it
all. Experimental results show that the proposed metrics ensemble can provide
a more comprehensive comparison among various MOEAs than what could be
obtained from single performance metric alone.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Shelokar:2011:SMiGDuMEP,
  title     = {Subgraph Mining in Graph-based Data using Multiobjective Evolutionary Programming},
  author    = {Prakash Shelokar and Quirin Arnaud and Cordon Oscar},
  pages     = {1729--1736},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Data mining, Evolutionary programming},
  abstract  = {
This work proposes multiobjective subgraph mining in graph-based data using
multiobjective evolutionary programming (MOEP). A mined subgraph is defined by
two objectives, support and size. These objectives are conflicting as a
subgraph with high support value is usually of small size and
{$\backslash$}emph\{vice-versa\}. MOEP applies NSGA-II's nondominated sorting
procedure to evolve the population during the subgraph generation process. An
experimental study on five synthetic and real-life graph-based datasets shows
that MOEP outperforms Subdue-based methods, a well-known heuristic search
approach for subgraph discovery in data mining community. The comparison is
done using hypervolume, \$C\$ and \$I\_{$\backslash$}epsilon\$ multiobjective
performance metrics.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Plenary Poster Session: Poster Session Tuesday
@InProceedings{Yen:2011:AMHPSOAfUC,
  title     = {A Modified Hybrid Particle Swarm Optimization Approach for Unit Commitment},
  author    = {Le Thanh Xuan Yen and Deepak Sharma and Dipti Srinivasan and Pnidoriya Naran Manji},
  pages     = {1737--1744},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Real-world applications, Particle swarm optimization},
  abstract  = {
This paper presents a new solution to thermal unit-commitment (UC) problem
based on a modified hybrid particle swarm optimization (MHPSO). Hybrid real
and binary PSO is coupled with the proposed heuristic based constraint
satisfaction strategy that makes the solutions/particles feasible for PSO. The
velocity equation of particle is also modified to prevent particle stagnation.
Unit commitment priority is used to enhance the performance of binary PSO. The
proposed algorithm is tested for 10, 20, 40 and 60 unit systems and the
results are reported for 10 different runs. Statistical results and their
comparison show a good performance of MHPSO over other existing optimization
methods.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Zhang:2011:AoAEPSOwIW,
  title     = {Assessment of An Evolutionary Particle Swarm Optimizer with Inertia Weight},
  author    = {Hong Zhang},
  pages     = {1745--1752},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Self-adaptation in evolutionary computation, Particle swarm optimization, Genetic algorithms},
  abstract  = {
This paper proposes a newly evolutionary particle swarm optimizer with inertia
weight (EPSOIW) for obtaining the PSOIW with high performance. Due to the use
of meta-optimization, it can systematically estimate appropriate values of
parameters in the PSOIW corresponding to a given optimization problem without
prior knowledge. Accordingly, the EPSOIW could be expected to not only obtain
an optimal PSOIW for efficiently solving a given optimization problem, but
also to quantitatively analyze the know-how on designing it. To demonstrate
the effectiveness of the proposed method, computer experiments on a suite of
multidimensional benchmark problems are carried out. We investigate the
intrinsic characteristics of the proposal, and compare the search ability and
efficiency with the other methods. The obtained experimental results indicate
that the search performance of the PSOIW optimized by the EPSOIW is superior
to those of the original PSOIW, OPSO and RGA/E. The EPSOIW is verified to be
relatively high in the processing capacity for solving multimodal problems in
comparison with the EPSO and ECPSO.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Zhang:2011:AAoMPSOwIWwDC,
  title     = {An Analysis of Multiple Particle Swarm Optimizers with Inertia Weight with Diversive Curiosity},
  author    = {Hong Zhang},
  pages     = {1753--1760},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Numerical optimization., Evolutionary computation theory},
  abstract  = {
In this paper we present a newly multiple particle swarm optimizers with
inertia weight with diversive curiosity (MPSOIW\${$\backslash$}alpha\$/DC) for
improving the search performance and intelligent processing of a plain MPSOIW.
It has the following outstanding features: (1) Decentralization in multi-swarm
exploration with hybrid search, (2) Concentration in evaluation and behavior
control with diversive curiosity, (3) Practical use of the results of
evolutionary PSOIW, and (4) Their effective combination. This achievement
expands the applied object of cooperative PSO, and develops the approach of
the curiosity-driven multi-swarm. To demonstrate the effectiveness of the
proposal, computer experiments on a suite of multidimensional benchmark
problems are carried out to analytical judgment. We examine its intrinsic
characteristics, and compare the search performance with other methods. The
obtained experimental results indicate that the search performance of the
MPSOIW\${$\backslash$}alpha\$/DC is superior to that by the PSOIW/DC, EPSOIW,
PSOIW, OPSO, RGA/E, and MPSO\${$\backslash$}alpha\$/DC for the given benchmark
problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Tjiong:2011:FSwPaKMfHC,
  title     = {Feature Selection with PSO and Kernel Methods for Hyperspectral Classification},
  author    = {Anthony Tjiong and Sildomar Monteiro},
  pages     = {1761--1768},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining, Real-world applications},
  abstract  = {
Hyperspectral image data has great potential to identify and classify the
chemical composition of materials remotely. Factors limiting the use of
hyperspectral sensors in practical land-based applications, such as robotics
and mining, are the complexity and cost of data acquisition, and the
processing time required for the subsequent analysis. This is mainly due to
the high dimensional and high volume nature of hyperspectral image data. In
this paper, we propose to combine a feature selection method, based on
particle swarm optimization (PSO), with a kernel method, support vector
machines (SVM), to reduce the dimensionality of hyperspectral data for
classification. We evaluate several different kernels, including some
optimized for hyperspectral analysis. In particular, a recent kernel called
observation angle dependent (OAD) kernel, originally designed for Gaussian
Process regression, was extended for SVM classification. The SVM with the
optimized kernel was then applied to induce the feature selection of a binary
version of PSO. We validate the method using hyperspectral data sets acquired
of rock samples from Western Australia. The empirical results demonstrate that
our method is able to efficiently reduce the number of features while keeping,
or even improving, the performance of the SVM classifier.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Huo:2011:TPSoMSPSOAtUPPP,
  title     = {The Preliminary Study on Multi-Swarm Sharing Particle Swarm Optimization: Applied to UAV Path Planning Problem},
  author    = {Chih-Li Huo and Tzu-Ying Lai and Tsung-Ying Sun},
  pages     = {1769--1775},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Intelligent systems applications, Robotics},
  abstract  = {
This paper presents a preliminary study on multi-swarm sharing scenario for
particle swarm optimization, MSSPSO, to deal with uncertain-dimension factor
space optimization problems. The proposed MSSPSO can provide more wide
capability for unknown solution space exploration. In this paper, the MSSPSO
is applied to UAV path planning problem. Based on characteristic number of
different paths, it has to use different number of control point to produce
varied flight paths. In order to explore suitable solution within suitable
characteristic number interval, MSSPSO is employed to explore better solution
and the variable-length crossover concept is used to share information among
different dimension swarms. The simulation is show that MSSPSO has the ability
to explore suitable solution and determine suitable characteristic for flight
path. On the other hand, swarm crossover helps swarm to avoid falling local
optimal position; swarm manager is applied to enhance computing efficiency and
prune the helpless swarms.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Li:2011:AHBAfMVCSP,
  title     = {A Hypervolume Based Approach for Minimal Visual Coverage Shortest Path},
  author    = {Jie Li and Changwen Zheng and Xiaohui Hu},
  pages     = {1776--1783},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms},
  abstract  = {
In this paper, the minimal visual coverage shortest path in raster terrain is
studied with the proposal of a hypervolume contribution based multiobjective
evolutionary approach. The main feature of the presented method is that all
individuals in the population are periodically replaced by the selected
non-dominated candidates in the archive based on hypervolume contribution,
besides the well designed evolutionary operators and some popular techniques
such as dominated relation and archive. Our algorithm may obtain well
distributed Pareto set approximation efficiently, which is superior to the
implementations based on the framework of NSGA-II and SMSEMOA with respect to
the hypervolume.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Hsieh:2011:AHCHMwDEfCMO,
  title     = {A Hybrid Constraint Handling Mechanism with Differential Evolution for Constrained Multiobjective Optimization},
  author    = {Min-Nan Hsieh and Tsung-Che Chiang and Li-Chen Fu},
  pages     = {1784--1791},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Constraint and uncertainty handling, Differential evolution, Multi-objective evolutionary algorithms},
  abstract  = {
In real-world applications, the optimization problems usually include some
conflicting objectives and subject to many constraints. Much research has been
done in the fields of multiobjective optimization and constrained
optimization, but little focused on both topics simultaneously. In this study
we present a hybrid constraint handling mechanism, which combines the
epsilon-comparison method and penalty method. Unlike original
epsilon-comparison method, we set an individual epsilon-value to each
constraint and control it by the amount of violation. The penalty method deals
with the region where constraint violation exceeds the epsilon-value and
guides the search toward the epsilon-feasible region. The proposed algorithm
is based on a well-known multiobjective evolutionary algorithm, NSGA-II, and
introduces the operators in differential evolution (DE). A modified DE
strategy, DE/better-to-best\_feasible/1, is applied. The better individual is
selected by tournament selection, and the best individual is selected from an
archive. Performance of the proposed algorithm is compared with NSGA-II and an
improved version with a self-adaptive fitness function. The proposed algorithm
shows competitive results on sixteen public constrained multiobjective
optimization problem instances.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Shirasaki:2011:EoGPfHCO,
  title     = {Effectiveness of Guidepost Pheromone for Honeybee Colony Optimization},
  author    = {Yudai Shirasaki and Sho Shimomura and Masaki Sugimoto and Yoko Uwate and Yoshifumi Nishio},
  pages     = {1792--1797},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Ant colony optimization},
  abstract  = {
Honeybee Colony Optimization (HCO) is an optimization algorithm based on a
particular intelligent behavior of honeybee swarms. In this study, we propose
a new HCO containing a characteristic of guidepost pheromone that has the
effect to attract other bees. Namely, many bees can move to the optimal place.
We investigate the performance of the proposed HCO by using four bench mark
problems. It discovered that the effect of guidepost pheromone works well for
the high dimension problems. We consider that the proposed HCO with pheromone
can leave from local minima more easily than the standard HCO.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ye:2011:SAoFRvIoACDaACT,
  title     = {Strengthen Accuracy of Feature Recognition via Integration of Ant Colony Detection and Adaptive Contour Tracking},
  author    = {Zhengmao Ye and Habib Mohamadian},
  pages     = {1798--1803},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Ant colony optimization, Evolution strategies, Self-adaptation in evolutionary computation},
  abstract  = {
Reliable feature recognition is necessary in broad fields of computer vision
and image processing. Edges often act as primary artifacts of visual data.
Edge detection is to mark sharp changes of the intensity or brightness of
digital images. Canny edge detection and ant colony optimization detection are
two essential edge detection approaches. The former is susceptible to noises
presented on source images. The information loss occurs when Gaussian
smoothing is used to improve connectivity of Canny edge detection. Edges can
be also detected via other approaches. To avoid edge suppression and feature
deformity, ACO has been proposed for edge and contour detection against false
detection, by which more intrinsic information will be extracted. The
evolutionary computation oriented ACO scheme is a promising approach for
feature capturing without the necessity of smoothing filters. It is among the
most effective approaches for edge detection. However, it may give rise to
broken pieces of numerous true edges occasionally. To further improve
accuracy, contour tracking schemes are needed to achieve stable feature
recognition. Some intelligent schemes are too complex to handle in real time,
so a simple adaptive contour tracking scheme has been proposed which is
combined with enhanced ACO schemes. This technology integration will result in
the sufficient true edge representation together with well connected linkage,
which can be easily extended to contour detection of binary, grayscale and
true color images. Using quantitative metrics, an objective study is made to
evaluate performance outcomes based on integration of the ACO schemes and
adaptive contour tracking.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lin:2011:TDwTStIoM,
  title     = {Taguchi-based Disturbance with Tournament Selection to Improve on MOPSO},
  author    = {Chi-nien Lin and Chih-Li Huo and Shu-Yan Lin and Yu-Hsiang Yu and Tsung-Ying Sun},
  pages     = {1804--1809},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Particle swarm optimization, Multiobjective optimization},
  abstract  = {
In this paper, a Taguchi-based disturbance mechanism is deployed in our
preliminary study on MOPSO. The proposed scenario includes tournament
selection for global best solutions, jump-improved operation to expand the
searching space, cluster operation to improve the diversity, and Taguchi-based
disturbance can enhance the searching ability and reduce the possibility of
falling into local optima of particles. Experiments are conducted on seven
two- objective benchmarks. The results show that the proposed method operates
better than other algorithms in three performance metrics.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Tsujimoto:2011:TNoCDP,
  title     = {The Neighborhood of Canonical Deterministic PSO},
  author    = {Takahiro Tsujimoto and Takuya Shindo and Kenya Jin'no},
  pages     = {1810--1816},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Numerical optimization.},
  abstract  = {
Particle swarm optimization (abbr. PSO) is one of the most effective
optimization algorithms. The PSO contains many control parameters. These
causes, the performance of the searching ability of the PSO is significantly
alternated. In order to analyze the dynamics of such PSO system rigorously, we
proposed a canonical deterministic PSO (abbr. CD-PSO) systems which does not
contain any stochastic factors, and its coordinate of the phase space is
normalized. \%The trajectory of the CD-PSO must converge to a fixed point. The
funded global best information influences the dynamics. This situation can be
regarded as the full-connection state. On the other hand, there is the case
where the best information in a limited population. Such information is called
as lbest. How to get the lbest information from any population is equivalent
to a network structure. Such network structure influences the performance of
searching ability. In order to clarify a relationship between network
structures of CD-PSO and its performance, we pay attention to the degree and
the average distance used in graph theory. First, we consider the case where
the CD-PSO has an extended cycle structure. Our numerical simulation results
indicates the searching performance is depended on the average distance of the
node, and the optimal average distance is existed. Next, we consider the case
where the CD-PSO has a Small World network structure. The extended cycle
structure has uniform symmetric property. On the contrary, a small world
network has nonuniform property. Even in the case where the CD-PSO has the
small world network structure, the searching performance is depended on the
average distance
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Huang:2011:GAwPRftMSPaDP,
  title     = {Genetic Algorithm with Path Relinking for the Multi-Vehicle Selective Pickup and Delivery Problem},
  author    = {Yu-Hsuan Huang and Chuan-Kang Ting},
  pages     = {1817--1824},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Memetic, multi-meme and hybrid algorithms, Discrete and combinatorial optimization., Real-world applications},
  abstract  = {
The multi-vehicle selective pickup and delivery problem (MVSPDP) is a class of
vehicle routing problem. The MVSPDP aims to minimize the total distance
traveled by a fleet of vehicles to collect and supply commodities, subject to
vehicle capacity and travel distance. This problem relaxes the constraint that
the vehicles have to visit all customers. In the MVSPDP, vehicles only need to
collect sufficient commodities from some selected pickup nodes for all
delivery nodes. To resolve the problem, this study develops a genetic
algorithm with path relinking (GAPR). A repair operator is presented for the
GAPR to handle the constraints. Experimental results on fourteen benchmarks
validate the effectiveness of the proposed GAPR for the MVSPDP.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Khairy:2011:PPSOwPLS,
  title     = {PSO2: Particle Swarm Optimization with PSO-Based Local Search},
  author    = {Mohamed Khairy and Magda B. Fayek and Elsayed E. Hemayed},
  pages     = {1825--1831},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Optimization:},
  abstract  = {
Several attempts have been made to enhance PSO performance by combining it
with a local search method. Following the same track we present PSO2. In PSO2
the local search is performed by smaller independent swarms of PSO located
around particles of the main PSO2. Different modifications are made to help
basic PSO2 escape from local optima.PSO2-RS and PSO2-SA are 2 modified
versions of PSO2 that target to increase the swarm diversity. The third and
best enhanced version, PSO2-SA-DYSS, is achieved by increasing the local
search swarms sizes as the search progresses. This last enhancement to PSO2
algorithm proved to make PSO2 behavior more exploitive. PSO2 versions have
been tested against the benchmark test functions using different velocity
update methods and topologies. Results have suggested the third and final
version PSO2-SA-DYSS. This version is examined against 4 functions of the
CEC-2005 benchmark suite and results are reported.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Hsieh:2011:SMGAfSMOP,
  title     = {Sharing Mutation Genetic Algorithm for Solving Multi-objective Optimization Problems},
  author    = {Sheng-Ta Hsieh and Shih-Yuan Chiu and Shi-Jim Yen},
  pages     = {1832--1838},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Genetic algorithms, Evolutionary computation theory},
  abstract  = {
Multi-objective optimization (MO) has been an active area of research in last
two decade. In multi-objective genetic algorithm (MOGA), quality of new
generated offspring of population will affect the performance of finding
Pareto optimum directly. In this paper, an improved MOGA is proposed named
SMGA to solving multi-objective optimization problem. For improving solution
searching efficiency, an effective mutation named sharing mutation is adopted
for generating potential offspring. Experiments were conducted on CEC-09 MOP
test problems. The results showed that the proposed method exhibits better
performance when solving these benchmark problems compared to related multi-
objective evolutionary algorithm (MOEA).
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Morshed:2011:RGNwCRoIaTI,
  title     = {Reconstructing Genetic Networks with Concurrent Representation of Instantaneous and Time-Delayed Interactions},
  author    = {Nizamul Morshed and Madhu Chetty},
  pages     = {1839--1846},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications, Genetic algorithms, Artificial ecology and artificial life},
  abstract  = {
Although living organisms can have some genetic interactions  occurring
instantaneously while others with time-delay, current modeling techniques for
genetic network reconstruction make  simplifications  and assume that the
interactions can be either of these but not both. In this paper, we propose a
gene regulatory network reconstruction algorithm that can model concurrent
occurrence of both, instantaneous as well as time-delayed interactions, thus
providing a better representation of the original biological processes. First
we introduce a novel framework using the Bayesian network (BN) formalism that
can model both types of interactions. A gene regulatory network reconstruction
algorithm using this proposed framework is then developed that employs an
evolutionary search strategy and a decomposable scoring metric based on
information theoretic quantities. Investigations of our approach are performed
using both, the synthetic data as well as Saccharomyces cerevisiae gene
expression data. Comparisons with recent reconstruction methods show the
superiority of the proposed method.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Mousavi:2011:ODoaASfaLBPiaEVwaGA,
  title     = {Optimal Design of an Air-Cooling System for a Li-Ion Battery Pack in an Electric Vehicle with a Genetic Algorithm},
  author    = {Mohsen Mousavi and Shaikh Hoque and Shahryar Rahnamayan and Ibrahim Dincer and Greg F. Naterer},
  pages     = {1847--1854},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Genetic algorithms},
  abstract  = {
This paper examines and optimizes parameters that affect the air cooling of a
Lithium-Ion (Li-Ion) Battery, used in Electric Vehicles (EVs). A battery pack
containing 150 cylindrical type Li-Ion battery cells in a PVC casing is
investigated. An equal number of tubes has been used in the pack as a medium
to cool the battery by using a fan when the vehicle is stationary or with
ambient air when in motion. The parameters affecting the air cooling of
battery have been studied and optimized by considering their practical
constraints. The objective function and Net Transfer Unit (NTU) have been
developed. Finally, a Genetic Algorithm has been employed to optimize the
decision variables. Analyzing the results shows that NTU can be maximized by
increasing the diameter of tubes on the battery and keeping the air velocity
in a certain range.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Benkhelifa:2011:EMDOoEHMTCoaP,
  title     = {Evolutionary Multi-objective Design Optimisation of Energy Harvesting MEMS: The Case of a Piezoelectric},
  author    = {Elhadj Benkhelifa and Ashutosh Tiwari and Alfonso G. {De Rueda} and Mansour Moniri},
  pages     = {1855--1862},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Real-world applications, Multiobjective optimization, Evolutionary simulation-based optimization},
  abstract  = {
The design and optimisation of Energy Harvesting (EH) Micro-Electromechanical-
Systems (MEMS) is of particular interest in this research. The application of
such devices is becoming an attractive alternative to the traditional use of
batteries in wireless and body sensor networks. An evolutionary
Multi-Objective Design Optimisation (DO) Framework is developed to experiment
with one class of EH-MEMS, namely, Piezoelectric, using a reconstructed
analytical model of the system. The application of such a Framework in this
application domain is unprecedented and has already shown very promising
results and in some cases it outperformed the human engineer. A thorough
analysis of the results has been undertaken, which reveals interesting
conclusions about the behaviour and physics of such devices. Besides, the main
features of the Framework are explored enabling the enhancement of the
MEMS-DO.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Zhang:2011:FLMbPSOwNT,
  title     = {Feedback Loop Mechanisms based Particle Swarm Optimization with Neighborhood Topology},
  author    = {Jingyu Zhang and Shiping Chen and David Levy and Yongzhong Lu},
  pages     = {1863--1870},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Self-adaptation in evolutionary computation, Multiobjective optimization},
  abstract  = {
Particle swarm optimization (PSO) is an optimization approach and has been
widely used for a verity of optimization problem in both research and
industrial domains. Due to the potential of PSO, several variants of the
original PSO algorithms have been developed to improve PSO's efficiency and
robustness. This paper proposes another variant of particle swarm optimization
algorithm, called N-PidSO. This N-PidSO algorithm is based on classical
feedback control theory and topological neighborhood, which offers better
search efficiency and convergence stability. As a result, our N-PidSO method
features faster searching from the proportional term without steady-state
error. And empirical results show that our N-PidSO algorithm is able to
achieve high performance for both unimodal and multimodal optimization
problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Mojica-Nava:2011:ARDWCTfaDC,
  title     = {A Replicator Dynamics Weighted Control Technique for a DC-DC Converter},
  author    = {Eduardo Mojica-Nava and Nicanor Quijano},
  pages     = {1871--1877},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary games and multi-agent systems, Engineering applications},
  abstract  = {
A power electronics benchmark problem involving several practical scenarios
for a fixed-frequency synchronous step-down DC-DC converter is investigated. A
new weighted control technique that uses the replicator dynamics concepts to
weight the operation of different controllers tuned to operate in different
modes, and with different control objectives is presented. Simulations for
four critical process conditions are shown to illustrate the performance of
this novel technique.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Shi:2011:AADEwUM,
  title     = {An Adaptive Differential Evolution with Unsymmetrical Mutation},
  author    = {Edwin Chao Shi and Frank H.F. Leung and Johnny C.Y. Lai},
  pages     = {1878--1885},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Differential evolution},
  abstract  = {
Differential Evolution (DE) is one of the evolutionary algorithms under active
research.  It has been successfully applied to many real world problems.  In
this paper, an improved DE with a novel mutation scheme is proposed.  The
improved DE assigns a distinct scale factor for each individual mutation based
on the fitness associated with each base vector involved in the mutation. 
With the adoption of different scale factors for mutation, DE is capable of
searching more locally around superior points and explore more broadly around
inferior points.  Consequently, a good balance between exploration and
exploitation can be achieved.  Also, an adaptive base vector selection scheme
is introduced to DE.  This scheme is capable of estimating the complexity of
objective functions based on the population variance.  When the problem is
simple, it will tend to select good vectors as base vector which will lead to
quick convergence.  When the objective function is complex, it will select
base vector randomly so that the population maintains a high exploration
capability and will not be trapped into local minima so easily.  A suite of 12
benchmark functions are used to evaluate the performance of the proposed
method.  The simulation result shows that the proposed method is promising in
terms of convergence speed, solution quality and stability.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chen:2011:POTPCfSCaLD,
  title     = {PSO-based On-line Tuning PID Controller for Setpoint Changes and Load Disturbance},
  author    = {Ping-Lin Chen and Ming-Chin Yang and Tsung-Ying Sun},
  pages     = {1886--1893},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Engineering applications, Real-world applications},
  abstract  = {
This paper proposes a Particle Swarm Optimization (PSO) approach for online
tuning Proportional Integral Derivative (PID) controller. There is a great
deal of general literature on PID controller with ignoring the disturbance
interference. However, in practical applications, the ability of interference
avoidance of PID controller should be considered in evaluating the performance
of system response. In this study, using PSO online tuning mechanism, PID
controller can track the input signal effectively even though the setpoint
changes and load disturbance influences. The simulation results describe that
the proposed method is able to obtain the good performance and stability.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Parracho:2011:TwOUPTuaGAK,
  title     = {Trading with Optimized Uptrend Pattern Template using a Genetic Algorithm Kernel},
  author    = {Paulo Parracho and Rui Neves and Nuno Horta},
  pages     = {1894--1900},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Finance and economics, Real-world applications, Genetic algorithms},
  abstract  = {
This paper describes a new computational finance approach. This approach
combines pattern recognition techniques with an evolutionary computation
kernel applied to financial markets time series in order to optimize trading
strategies. Moreover, for pattern matching a template-based approach is used
in order to describe the desired trading patterns. The parameters for the
pattern templates, as well as, for the decision making rules are optimized
using a genetic algorithm kernel. The approach was tested considering actual
data series and presents a robust profitable trading strategy which clearly
beats the market, SP 500 index, reducing the investment risk significantly.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lung:2011:ANEAtMP,
  title     = {A New Evolutionary Approach to Minimax Problems},
  author    = {Rodica Ioana Lung and Dumitru Dumitrescu},
  pages     = {1901--1904},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Numerical optimization., Differential evolution, Games},
  abstract  = {
Minimax or worst-case optimization is concerned with the minimization of the
maximum output in all scenarios of a given problem. The minimax problem can be
transformed in a two players zero-sum game considering the fact that the Nash
equilibria of this game would represent the solution of the original problem.
Using the Nash ascendancy relation the equilibria of the game can be directly
computed using a differential evolution algorithm. Results obtained by using
this approach are compared with best known results from literature on six
minimax benchmark problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Liu:2011:AiNaboss,
  title     = {A improved NSGA-II algorithm based on sub-regional search},
  author    = {Hai-lin Liu and Fangqing Gu},
  pages     = {1905--1910},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Multiobjective optimization, Evolutionary computation theory},
  abstract  = {
By dividing the objective space into several small regions, this paper
proposes an improved NSGA-II algorithm, which updates the population in each
sub-region by using non-dominated sorting and crowded distance selection
operator (NSGA-II). Since performing the evolutionary operator is independent
in each sub-region and the number of the individuals in a sub-region is far
less than the size of the population, the computational complexity at each
generation is lower than NSGA-II. The computational complexity of each
generation in the proposed algorithm is O(mN3/2 ), where m is the number of
the objective and N is its population size. For enhancing the capability of
proposed algorithm, The algorithm exchanges the information between
sub-regions through re-dividing their offsprings and the evolutionary
operators between individuals are operated in the same sub-region. Such
evolutionary operators can largely play a role of exploring the good
individuals in this area and improve the local search capabilities of the
algorithm. A specific selection in this paper surmounts the intrinsic
shortcoming of the subregion decomposition technique, which there may be no
Pareto optimal solutions in some sub-region. Numerical results show that the
proposed algorithm has a good performance.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Feitosa-Neto:2011:OTftSoMaAiES,
  title     = {Optimization Techniques for the Selection of Members and Attributes in Ensemble Systems},
  author    = {Antonino Feitosa Neto and Anne Canuto and Elizabeth Goldbarg and Marco Goldbarg},
  pages     = {1911--1918},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Classification, clustering, data analysis and data mining},
  abstract  = {
Although ensemble systems have been proved to be efficient for pattern
recognition tasks, its elaboration and design is not an easy task. Some
aspects such as the choice of its individual classifiers and the use of
feature selection methods are very difficult to define. In addition, these
aspects can have a strong effect in the accuracy of these systems, leading,
for instance, to cases where the produced ensembles have no performance
improvement. In order to avoid this situation, there is a great deal of
research to select individual classifiers or distribute attributes to the
individual classifiers of ensemble systems. In most of these works, however,
only one aspect is tackled (either member selection or feature selection). In
this paper, we present an analysis of two well-known optimization techniques
to choose the ensemble members and to select attributes for these individual
classifiers. In order to do this analysis, we use accuracy as well as two
recently proposed diversity measures as parameters, in a multi-objective
optimization problem.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Oliveira:2011:TRItSfBODCCA,
  title     = {Ternary Representation Improves the Search for Binary, One-dimensional Density Classifier Cellular Automata},
  author    = {Pedro Oliveira and Mateus Interciso},
  pages     = {1919--1925},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms},
  abstract  = {
Standard practice for searching binary, one-dimensional cellular automata rule
space, relies on representing the candidate rule numbers by their
corresponding binary sequence. Recently the use of ternary representation has
been tried, which is based upon the traditional notion of schemata in genetic
algorithms, though not with a focus on their effectiveness for the search.
Here, we specifically go about such an evaluation, in the context of the
classical benchmark task of density classification, in which the objective is
to find a binary, one-dimensional rule that indicates the prevailing bit in a
binary sequence, given to the rule as an initial configuration. The role of
ternary representation is probed by comparing their introduction into two
simple and traditional genetic algorithms of the literature, developed for the
task. The experiments show that the ternary representation can lead to an
increase in the number of high performance rules found for the task.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Scola:2011:MOMRO,
  title     = {Multi-objective Optimal Multiple Reservoir Operation},
  author    = {Luis Scola and Oriane Neto and Ricardo Takahashi and Sergio Cerqueira},
  pages     = {1926--1932},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Multiobjective optimization},
  abstract  = {
Hydropower plants produce most of the electrical power generated in Brazil.
Although the remaining potential is still large, most of it is located far
from the industrialized south-eastern states. In addition to that, the
increasing opposition to the construction of new large reservoirs, for
ecological and social reasons, highlights the need for the efficient operation
of the existing system. In this work, a formulation recently developed by the
authors, which has been shown to efficiently deal with the operational
constraints of a single plant, is expanded to the multi-reservoir case. A
multi-objective optimization of a system of five Brazilian hydropower plants
is performed, with the objectives of increasing the mean power generation
along a year and reducing the peak of demand of non-renewable energy sources.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Leguizamon:2011:AMDEAfCOP,
  title     = {A Multi-Region Differential Evolution Algorithm for Continuos Optimization Problems},
  author    = {Guillermo Leguizamon and Carlos A. {Coello Coello}},
  pages     = {1933--1939},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Differential evolution, Large-scale problems.},
  abstract  = {
This paper presents a Multi-Region Differential Evolution (MRDE) algorithm as
an extension of a classical version of differential evolution (DE) (i.e., as
an extension of DE/rand-to-best/1/exp). MRDE is designed to simultaneously
search on different and evenly distributed sub-regions on the whole search
space. The number and extent of the search regions change during the execution
of the algorithm, in such a way that, at the final stage of the evolutionary
process, only one region remains (i.e., the whole search space). Our proposed
MRDE is compared with respect to the classical DE algorithm on a set of
well-known benchmark problems. The results achieved show enough evidence of
the benefits of distributing the population of vectors when dealing with
large-scale optimization problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ghosh:2011:PPRRiOSUaADEA,
  title     = {Peak-to-Average Power Ratio Reduction in OFDM Systems Using an Adaptive Differential Evolution Algorithm},
  author    = {Saurav Ghosh and Subhrajit Roy and Das Swagatam and Abraham Ajith and Islam Minhazul},
  pages     = {1940--1948},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Intelligent systems applications, Differential evolution, Particle swarm optimization},
  abstract  = {
Orthogonal Frequency Division Multiplexing (OFDM) has emerged itself as very
popular wireless transmission technique in which digital data bits are
transmitted at a high speed in a radio environment. But the high
peak-to-average power ratio (PAPR) is the major setback for OFDM systems
demanding expensive linear amplifiers with wide dynamic range. In this article
we introduce a low-complexity partial transmit sequence (PTS) technique for
diminishing the PAPR of OFDM systems. But the computational complexity of the
exhaustive search technique for PTS increases exponentially with the number of
sub- blocks present in an OFDM system. So we propose a modified differential
evolution algorithm with novel mutation, crossover as well as parameter
adaptation strategies (MDE\_pBX) as a sub-optimum PTS for PAPR reduction of
OFDM systems. MDE\_pBX is utilized to search for the optimum phase weighting
factors and extensive simulation studies have been conducted to show that
MDE\_pBX can achieve lower PAPR as compared to other DE and PSO variants like
JADE, SaDE and CLPSO.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Islam:2011:AMDDEbTSSfMtOCiWSN,
  title     = {A Modified Discrete Differential Evolution based TDMA Scheduling Scheme for Many to One Communications in Wireless Sensor Networks},
  author    = {Minhazul Islam and Saurav Ghosh and Swagatam Das and Ajith Abraham and Subhrajit Roy},
  pages     = {1949--1956},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Differential evolution, Intelligent systems applications, Particle swarm optimization},
  abstract  = {
Time division multiple access (TDMA) plays an important role in MAC for
wireless sensor networks providing real-time guarantees and potentially
reducing the delay and also it saves power by eliminating collisions. In TDMA
based MAC, the sensor are not allowed tom radiate signals when they are not
engaged. On the other hand, if there are too many switching between active and
sleep modes it will also unnecessary waste energy. In this paper, we have
presented a multi-objective TDMA scheduling problem has been demonstrated to
prevent the wasting of energy discussed above and also further improve time
performance. A modified discrete Differential Evolution algorithm (MDDE) has
been proposed to enhance converging process in an proposed effective
optimization framework. Simulation results are given with different network
sizes. The results are compared with the Particle Swarm Optimization (PSO) and
genetic Algorithm (GA) and the original discrete DE (DDE). The proposed MDDE
algorithm has outperformed these two algorithms on the objective specified,
which is the total time or energy for data collection.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Plenary Talk: Analysis by Synthesis

% Session: Innovations in Evolutionary Programming
@InProceedings{Landassuri-Moreno:2011:BtEoMNN,
  title     = {Biasing the Evolution of Modular Neural Networks},
  author    = {Victor M. Landassuri-Moreno and John A. Bullinaria},
  pages     = {1957--1964},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolved neural networks, Evolutionary programming, Classification, clustering, data analysis and data mining},
  abstract  = {
Modularity is known to have benefits for neural systems and their evolution,
and this paper aims to improve the evolutionary neural network algorithm EPNet
to take advantage of those benefits. Neural networks exist with varying
degrees of modularity ranging from pure modular networks characterized by
disjoint partitions of hidden nodes with no communication between modules, to
pure homogeneous networks with significant connections throughout. In between
are apparently homogeneous networks that can be seen to have some degree of
modularity if the hidden nodes are reorganized appropriately. In this paper, a
modularity measure is presented and extended that can be applied to any neuron
at any level in the network to provide a fine analysis of node partitioning.
It also allows the rearrangement of nodes to create modules in homogeneous
networks, and that is used to improve the EPNet algorithm to evolve modular
neural networks. Experimental results on a simple classification task confirm
that the new modular EPNet algorithm does indeed lead to more modular networks
than the classical EPNet algorithm, without compromising the performance on
the given task.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Polushina:2011:CDiBSvGA,
  title     = {Change-Point Detection in Biological Sequences via Genetic Algorithm},
  author    = {Tatiana Polushina and Georgy Sofronov},
  pages     = {1965--1970},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Discrete and combinatorial optimization., Evolutionary programming},
  abstract  = {
Genome research is one of the most interesting and important areas of the
science nowadays. It is well-known that the genomes of complex organisms are
highly organized. Many studies show that DNA sequence can be divided into a
few segments, which have various properties of interest. Detection of this
segments is extremely significant  from the point of view of practical
applications, as well as for understanding evolutional processes. We model
genome sequences as a multiple change-point process, that is, a process in
which sequential data are divided into segments by an unknown number of
change-points, with each segment supposed to have been generated by a process
with different parameters. Multiple change-point models are important in many
biological applications and, specifically, in analysis of biomolecular
sequences. In this paper, we propose to use genetic algorithm to identify
change-points. Numerical experiments illustrate the effectiveness of our
approach to the problem. We obtain estimates for the positions of
change-points in artificially generated sequences and compare the accuracy of
these estimates to those obtained via Markov chain Monte Carlo and the
Cross-Entropy method. We also provide examples with real data sets to
illustrate the usefulness of our method.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Differential Evolution Approaches to Complex Problems
@InProceedings{Mallipeddi:2011:ESiCDE,
  title     = {Ensemble Strategies in Compact Differential Evolution},
  author    = {Rammohan Mallipeddi and Giovanni Iacca and Nagaratnam Suganthan Ponnuthurai and Ferrante Neri and Ernesto Mininno},
  pages     = {1971--1976},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Differential evolution, Numerical optimization.},
  abstract  = {
Differential Evolution is a population based stochastic algorithm with less
number of parameters to tune. However, the performance of DE is sensitive to
the mutation and crossover strategies and their associated parameters. To
obtain optimal performance, DE requires time consuming trial and error
parameter tuning. To overcome the computationally expensive parameter tuning
different adaptive/self-adaptive techniques have been proposed. Recently the
idea of ensemble strategies in DE has been proposed and favorably compared
with some of the state-of-the-art self-adaptive techniques. Compact
Differential Evolution (cDE) is modified version of DE algorithm which can be
effectively used to solve real world problems where sufficient computational
resources are not available. cDE can be implemented on devices such as micro
controllers or Graphics Processing Units (GPUs) which have limited memory. In
this paper we introduced the idea of ensemble into cDE to improve its
performance. The proposed algorithm is tested on the 30D version of 14
benchmark problems of Conference on Evolutionary Computation (CEC) 2005. The
employment of ensemble strategies for the cDE algorithms appears to be
beneficial and leads, for some problems, to competitive results with respect
to the-state-of-the-art DE based algorithms
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Hernandez:2011:ACotSoPSOaDEoMO,
  title     = {A Comparison on the Search of Particle Swarm Optimization and Differential Evolution on Multi-Objective Optimization},
  author    = {Jorge Hernandez and Gregorio Toscano-Pulido},
  pages     = {1977--1984},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Differential evolution, Particle swarm optimization},
  abstract  = {
Particle swarm optimization (PSO) and differential evolution (DE) are
meta-heuristics which have been found to be successful in a wide variety of
optimization tasks. The high speed of convergence and the relative simplicity
of PSO make it a highly viable candidate to be used in multi-objective
optimization problems (MOPs). Therefore, several PSO approaches capable to
handle MOPs (MOPSOs) have appeared in the past. There are some problems,
however, where PSO-based algorithms have shown a premature convergence. On the
other hand, multi-objective DEs (MODE) have shown lower speed of convergence
than MOPSOs but they have been successfully used in problems where MOPSO have
mistakenly converged. In this work, we have developed experiments to observe
the convergence behavior, the online convergence, and the diversity of
solutions of both meta-heuristics in order to have a better understanding
about how particles and solutions move in the search space. To this end, MOPSO
and MODE algorithms under (to our best effort) similar conditions were used.
Moreover, the ZDT test suite was used on all experiments since it allows to
observe Pareto fronts in two-dimensional scatter plots (more details on this
are presented on the experiments section). Based on the observations found,
modifications to two PSO-based algorithms from the state of the art were
proposed resulting in a rise on their performance. It is concluded that MOPSO
presents a poor distributed scheme that leads to a more aggressive search.
This aggressiveness showed to be detrimental for the selected problems. On the
other hand, MODE seemed to generate better distributed points on both decision
and objective space allowing it to produce better results.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lu:2011:CDEfCEP,
  title     = {Classification-Assisted Differential Evolution for Computationally Expensive Problems},
  author    = {Xiaofen Lu and Ke Tang and Xin Yao},
  pages     = {1985--1992},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Meta-modeling and surrogate models, Differential evolution, Numerical optimization.},
  abstract  = {
Like most Evolutionary Algorithms (EAs), Differential Evolution (DE) usually
requires a large number of fitness evaluations to obtain a sufficiently good
solution. This is an obstacle for applying DE to computationally expensive
problems. Many previous studies have been carried out to develop surrogate-
assisted approaches for EAs to reduce the number of real fitness evaluations.
Existing methods typically build surrogates with either regression or ranking
methods. However, due to the pairwise selection scheme of DE, it is more
appropriate to formulate the construction of surrogate as a classification
problem rather than a regression or ranking problem. Hence, we propose a
classification-assisted DE in this paper. Experimental studies showed that the
classification-assisted DE has great potential when compared to the DE that
uses regression or ranking techniques to build surrogates.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Prampero:2011:MPSOwEoD,
  title     = {Magnetic Particle Swarm Optimization with Estimation of Distribution},
  author    = {Paulo S. Prampero and Romis Attux},
  pages     = {1993--2000},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Estimation of distribution algorithms, Differential evolution},
  abstract  = {
The magnetic particle swarm (MPS) algorithm is an approach based on the
phenomenon dipole repulsion by a magnetic field. In this paper, a new version
of this algorithm, which employs an estimation of distribution step as an
additional search heuristic, is proposed and applied to seven well-known test
functions for 30-dimensional, 120-dimensional and 1000-dimensional search
spaces. The performance of the new approach is compared to that of benchmark
differential evolution and estimation of distribution methods, and the results
reveal its potential in terms of multimodal search in the context of complex
optimization tasks.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Evolutionary Games
@InProceedings{Shaban-Nejad:2011:AARMfEAoMI,
  title     = {An Abstract Representation Model for Evolutionary Analysis of Multi-Agent Interactions},
  author    = {Arash Shaban-Nejad and Volker Haarslev},
  pages     = {2001--2008},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Representation and operators, Intelligent systems applications, Evolutionary games and multi-agent systems},
  abstract  = {
Intelligent agents are able to assist human in managing highly dynamic and
complex systems in various knowledge intensive domains. The communication
between different agents interacting in an integrated multi-agents system can
be managed through a set of steering rules, which together form interaction
protocols. To support the negotiation, communication and interaction between
different intelligent agents, using an appropriate knowledge representation
formalism is crucial. This paper introduces the potential of category theory
as a formal representation vehicle to facilitate evolutionary analysis of
agent interaction and negotiation for managing evolving ontologies in the
domain of biomedicine. Utilizing categories supports agents' communication,
negotiation, state transitions, compositions and transformations in different
levels of abstractions.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Greenwood:2011:ANAotEISG,
  title     = {A Numerical Analysis of the Evolutionary Iterated Snowdrift Game},
  author    = {Garrison Greenwood and Shubham Chopra},
  pages     = {2009--2015},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Games},
  abstract  = {
The iterated prisoner's dilemma (IPD) game has been extensively investigated
to help researchers gain a better understanding of how cooperation develops in
populations. One criticism of IPD is it underestimates the level of
cooperation particularly in human populations. The iterated snowdrift (ISD)
game has emerged as a viable alternative model, in part because it predicts
higher cooperation levels. To date no numerical analysis of ISD has been done.
In this paper we report the results from a numerical analysis conducted on an
ISD with an N -player, well-mixed population. Our results show, with certain
cost-to-benefit ratios, evolved ISD strategies can maintain surprisingly high
quasi-stable levels of cooperation in the population.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Fernandez-Ares:2011:OPBIARSGUEA,
  title     = {Optimizing Player Behavior In A Real-Time Strategy Game Using Evolutionary Algorithms},
  author    = {Antonio Fernandez-Ares and Antonio M. Mora and Juan Julian Merelo and Pablo Garcia-Sanchez and Carlos Fernandes},
  pages     = {2016--2023},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Games, Genetic algorithms},
  abstract  = {
This paper describes an Evolutionary Algorithm for evolving the decision
engine of a bot designed to play the Planet Wars game. This game, which has
been chosen for the Google Artificial Intelligence Challenge in 2010, requires
that the artificial player is able to deal with multiple objectives, while
achieving a certain degree of adaptability in order to defeat different
opponents in different scenarios. The decision engine of the bot is based on a
set of rules that have been defined after an empirical study. Then, an
Evolutionary Algorithm is used for tuning the set of constants, weights and
probabilities that define the rules, and, therefore, the global behavior of
the bot. The paper describes the Evolutionary Algorithm and the results
attained by the decision engine when competing with other bots. The proposed
bot defeated a baseline bot in most of the playing environments and obtained a
ranking position in top-20\% of the Google Artificial Intelligence
competition.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ellefsen:2011:DRSUaGA,
  title     = {Dynamic Robot Scheduling Using a Genetic Algorithm},
  author    = {Kai Olav Ellefsen},
  pages     = {2024--2031},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary Robotics, Dynamic and uncertain environments., Games},
  abstract  = {
This paper describes a genetic algorithm that was developed for optimizing
plans in a robotic competition. The algorithm was used both as a static
planner, making plans before matches, and as a dynamic replanner during
matches, a task with much stricter demands of efficiency. The genetic
algorithm was hybridized with a local search technique, which experiments
proved essential to finding good solutions in this complex task. To enable
rapid response under environmental changes, a heuristic for immediate response
and a contingency planning module were also implemented. Experiments proved
that the algorithm was able to generate good plans, and continuously modify
them in light of a rapidly changing environment.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Session: Evolutionary Computation in Dynamic and Uncertain Environments
@InProceedings{Azevedo:2011:GISfDEMO,
  title     = {Generalized Immigration Schemes for Dynamic Evolutionary Multiobjective Optimization},
  author    = {Carlos Azevedo and Aluizio Araujo},
  pages     = {2032--2039},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
The insertion of atypical solutions (immigrants) in Evolutionary Algorithms
populations is a well studied and successful strategy to cope with the
difficulties of tracking optima in dynamic environments in single-objective
optimization. This paper studies a probabilistic model, suggesting that
centroid-based diversity measures can mislead the search towards optima, and
presents an extended taxonomy of immigration schemes, from which three
immigrants strategies are generalized and integrated into NSGA2 for Dynamic
Multiobjective Optimization (DMO). The correlation between two diversity
indicators and hypervolume is analyzed in order to assess the influence of the
diversity generated by the immigration schemes in the evolution of
non-dominated solutions sets on distinct continuous DMO problems under
different levels of severity and periodicity of change. Furthermore, the
proposed immigration schemes are ranked in terms of the observed offline
hypervolume indicator.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Helbig:2011:AMfDMOPuVEPSO,
  title     = {Archive Management for Dynamic Multi-objective Optimisation Problems using Vector Evaluated Particle Swarm Optimisation},
  author    = {Marde Helbig and Andries P. Engelbrecht},
  pages     = {2040--2047},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Many optimisation problems have more than one objective that are in conflict
with one another and that change over time, called dynamic multi-objective
problems. To solve these problems an algorithm must be able to track the
changing Pareto Optimal Front (POF) over time and find a diverse set of
solutions. This requires detecting that a change has occurred in the
environment and then responding to the change. Responding to the change also
requires to update the archive of non-dominated solutions that represents the
found POF. This paper discusses various ways to manage the archive solutions
when a change occurs in the environment. Furthermore, two new benchmark
functions are presented where the POF is discontinuous. The dynamic Vector
Evaluation Particle Swarm Optimisation (DVEPSO) algorithm is tested against a
variety of benchmark function types and its performance is compared against
three state-of-the-art DMOO algorithms.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Real World Applications VII
@InProceedings{Coulter:2011:BIOMiMAS,
  title     = {Biologically Inspired Obsolescence Management in Mobile Agent Systems},
  author    = {Duncan Coulter and Elizabeth Ehlers},
  pages     = {2048--2055},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Artificial immune systems, Evolutionary games and multi-agent systems, Real-world applications},
  abstract  = {
Ubiquitous computing heralds an era marked by the increasing pervasiveness of
computational hardware throughout a given environment. In order to capitalize
on the increased abundance of the underlying infrastructure multi-agent
systems will be required to reflect the characteristics of the ubiquitous
networks upon which they operate. Due to the potential for limited
communication capacity experienced by agents in the wild it will become
increasingly important for mobile agents to migrate to devices in greater
proximity to the problem upon which they are working or the resources they
require. A result of highly mobile agents operating in potentially constrained
computational and communication environments is that widely used command and
coordination structures are no longer able to scale efficiently. Engineers are
currently struggling with aspects of managing the physical devices which
comprise such networks, particularly the obsolescence management of their
constituent, highly dispersed, hardware. Analogously  the obsolescence
management of deployed agents is of increasing concern. The paper examines and
synthesizes several biological metaphors which may be employed in order to
mitigate the inherent complexity of managing deployed mobile agent systems and
presents this functionality in a service oriented manner.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Alford:2011:GMF,
  title     = {GEC-Based Multi-Biometric Fusion},
  author    = {Aniesha Alford and Caresse Hansen and Gerry Dozier and Kelvin Bryant and John Kelly and Tamirat Abegaz and Karl Ricanek and Damon Woodard},
  pages     = {2056--2059},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications, Genetic algorithms, Real-world applications},
  abstract  = {
In this paper, we use Genetic and Evolutionary Computation (GEC) to optimize
the weights assigned to the biometric modalities of a multi-biometric system
for score-level fusion.  Our results show that GEC-based multi-biometric
fusion provides a significant improvement in the recognition accuracy over
evenly fused biometric modalities, increasing the accuracy from 90.77\% to
95.24\%.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Dias:2011:SQDGPbQLGP,
  title     = {Self-Assembly Quantum Dots Growth Prediction by Quantum-Inspired Linear Genetic Programming},
  author    = {Douglas Dias and Anderson Singulani and Marco Aurelio Pacheco and Patricia Souza and Mauricio Pires and Omar Vilela Neto},
  pages     = {2060--2067},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Emergent technologies, Genetic programming, Real-world applications},
  abstract  = {
In this work we present the application of quantum inspired linear genetic
programming (QILGP) to the growth of self-assembled quantum dots. Quantum
inspired linear genetic programming is a novel model to evolve machine code
programs exploiting quantum mechanics principles. Quantum dots are
nanostructures that have been widely applied to optoelectronics devices. The
method proposed here relies on an existing database of growth parameters with
a resulting quantum dot characteristic to be able to later obtain the growth
parameters needed to reach a specific value for such a quantum dot
characteristic. The computational techniques were used to associate the growth
input parameters with the mean height of the deposited quantum dots. Trends of
the quantum dot mean height behavior as a function of growth parameters were
correctly predicted, improving on the results obtained by artificial neural
network and classical genetic programming.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Evolved Neural Networks and Numerical Optimization
@InProceedings{Roedland:2011:CGbCEaL,
  title     = {Classifying Glyphs by Combining Evolution and Learning},
  author    = {Tiril Anette Langfeldt Roedland},
  pages     = {2068--2075},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolved neural networks, Classification, clustering, data analysis and data mining, Real-world applications},
  abstract  = {
Artificial neural networks are used to classify the writing system of an
unseen glyph. The complexity of the problem necessitates a large network,
which hampers the training of the weights. Three hybrid algorithms ---
combining evolution and back-propagation learning --- are compared to the
standard back-propagation algorithm. The results indicated that pure
back-propagation is preferable to any of the hybrid algorithms.
Back-propagation had both the best classification results and the fastest
runtime, in addition to the least complex implementation.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Yu:2011:EANNBoCRO,
  title     = {Evolutionary Artificial Neural Network Based on Chemical Reaction Optimization},
  author    = {James J.Q. Yu and Albert Y.S. Lam and Victor O.K. Li},
  pages     = {2076--2083},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolved neural networks, Numerical optimization., Heuristics, metaheuristics and hyper-heuristics},
  abstract  = {
Evolutionary algorithms (EAs) are very popular tools to design and evolve
artificial neural networks (ANNs), especially to train them. These methods
have advantages over the conventional backpropagation (BP) method because of
their low computational requirement when searching in a large solution space.
In this paper, we employ Chemical Reaction Optimization (CRO), a newly
developed global optimization method, to replace BP in training neural
networks. CRO is a population-based metaheuristics mimicking the transition of
molecules and their interactions in a chemical reaction. Simulation results
show that CRO outperforms many EA strategies commonly used to train neural
networks.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Uemura:2011:ANFtaoMFfRGA,
  title     = {A New Framework taking account of Multi-funnel Functions for Real-coded Genetic Algorithms},
  author    = {Kento Uemura and Shun-ichi Kinoshita and Yuichi Nagata and Shigenobu Kobayashi and Isao Ono},
  pages     = {2084--2091},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Numerical optimization.},
  abstract  = {
In this paper, we propose a new framework taking account of multi-funnel
functions for Real-coded Genetic Algorithms (RCGAs). In the continuous
function optimization, Evolutionary Algorithms (EAs) are one of the most
effective optimization methods. However, most conventional EAs, such as RCGAs
and CMA-ES, work efficiently on functions with big-valley landscape and they
deteriorate on multi- funnel functions. Innately Split Model (ISM) has been
proposed as a framework of GAs for multi-funnel functions and outperforms
conventional GAs on this kind of functions. However, ISM is considered to have
two problems in terms of efficiency of the search and difficulty of parameter
settings. Our framework repeats a search by RCGAs as ISM does and has two
effective mechanisms to remedy the two problems of ISM. We conducted
experiments on benchmark functions with multi-funnel and big- valley
landscapes and our framework outperformed conventional EAs, Multi-start RCGA
(MS-RCGA), Multi-start CMA-ES (MS-CMA-ES) and ISM, on the multi-funnel
functions. Our framework achieved as good performance as MS-RCGA and MS-
CMA-ES on the big-valley function where ISM significantly deteriorates.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Multi-objective Optimization III
@InProceedings{Herbawi:2011:CoMEAfSTMRPiDMR,
  title     = {Comparison of Multiobjective Evolutionary Algorithms for Solving The Multiobjective Route Planning in Dynamic Multi-hop Ridesharing},
  author    = {Wesam Herbawi and Michael Weber},
  pages     = {2092--2099},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Multi-objective evolutionary algorithms},
  abstract  = {
Ridesharing is considered as one of the promising solutions for dropping the
consumption of fuel and reducing the congestion in urban cities, hence
reducing the environmental pollution. Route planning is a key component for
the success of ridesharing systems in which multiple objectives can be
optimized. The multiobjective route planning problem in multi-hop ridesharing
is categorized as NP--complete. Multiobjective evolutionary algorithms have
received a growing interest in solving the multiobjective optimization
problems. In this work, we compare the behaviour of different multiobjective
evolutionary algorithms for solving the multiobjective route planning in
dynamic multi-hop ridesharing.

Comparison results indicate that there is no single algorithm, as in
literature, that wins all the tournaments regarding all the quality
indicators. However, a subset of the algorithms is recommended with better
quality and runtime.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Davarynejad:2011:ACTtOPF,
  title     = {Accelerating Convergence Towards the Optimal Pareto Front},
  author    = {Mohsen Davarynejad and Jafar Rezaei and Jos Vrancken and Jan {van den Berg} and Carlos A. {Coello Coello}},
  pages     = {2100--2107},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Meta-modeling and surrogate models, Multi-objective evolutionary algorithms, Multiobjective optimization},
  abstract  = {
Evolutionary algorithms have been very popular optimization methods for a wide
variety of applications. However, in spite of their advantages, their
computational cost is still a prohibitive factor in certain real-world
applications involving expensive (computationally speaking) fitness function
evaluations. In this paper, we depart from the observation that nature's
survival of the fittest is not about exact measures of fitness; rather it is
about rankings among competing peers. Thus, by exploiting this natural
tolerance for imprecision, we propose here a new, fuzzy granules-based
approach for reducing the number of necessary function calls involving time
consuming real-world problems. Our proposed approach is compared with respect
to the standard NSGA-II, using the Set Coverage, Hypervolume and Generational
Distance performance measures. Our results indicate that our proposed approach
is a very promising alternative for dealing with multi-objective optimization
problems involving expensive fitness function evaluations.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Garza-Fabre:2011:ERSMO,
  title     = {Effective Ranking + Speciation = Many-Objective Optimization},
  author    = {Mario Garza-Fabre and Gregorio Toscano-Pulido and Carlos A. {Coello Coello} and Eduardo Rodriguez-Tello},
  pages     = {2108--2115},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Multi-objective evolutionary algorithms},
  abstract  = {
Multiobjective optimization problems have been widely addressed using
evolutionary computation techniques. However, when dealing with more than
three conflicting objectives (the so-called many-objective problems), the
performance of such approaches deteriorates. The problem lies in the inability
of Pareto dominance to provide an effective discrimination. Alternative
ranking methods have been successfully used to cope with this issue.
Nevertheless, the high selection pressure associated with these approaches
usually leads to diversity loss. In this study, we focus on parallel genetic
algorithms, where multiple partially isolated subpopulations are evolved
concurrently. As in nature, isolation leads to speciation, the process by
which new species arise. Thus, evolving multiple subpopulations can be seen as
a potential source of diversity and it is known to improve the search
performance of genetic algorithms. Our experimental results suggest that such
a behavior, integrated with an effective ranking, constitutes a suitable
approach for many-objective optimization.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Saha:2011:TPERMO,
  title     = {Towards Practical Evolutionary Robust Multi-Objective Optimization},
  author    = {Amit Saha and Tapabrata Ray and Warren Smith},
  pages     = {2116--2123},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Constraint and uncertainty handling, Multi-objective evolutionary algorithms},
  abstract  = {
Multi-objective optimization methods focus towards finding the high-performing
Pareto-optimal solutions,without considering their sensitivity to minor
deviations from their original values. It is a fair assumption that practical
realization of optimal solutions is often accompanied by minor differences
from the exact numerical results produced by an optimizer. Taking this factor
into account, Robust Optimization methods seek to find high-performing
solutions which are also less sensitive to such deviations. In this work, we
have proposed strategies to minimize the number of function evaluations (which
can be an expensive enterprise) to enhance one of the earliest proposed
methods for robust Multi-objective Optimization. Our focus is on constrained
Multi-objective optimization problems and hence we make use of the
Infeasibility Driven Evolutionary Algorithm (IDEA), as the Evolutionary
Multi-objective Optimizer. We take up three constrained Multi-objective
engineering design optimization problems from the literature as the test-bed
for our experiments and present results on the same.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Evolutionary Computation Theory
@InProceedings{McClymont:2011:BMOTPwME,
  title     = {Benchmark Multi-objective Optimisation Test Problems with Mixed Encodings},
  author    = {Kent McClymont and Ed Keedwell},
  pages     = {2124--2131},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary computation theory, Numerical optimization., Discrete and combinatorial optimization.},
  abstract  = {
The fields of multi-objective combinatorial and continuous optimisation have
both experienced a significant and rapid growth in publications and research
since the turn of the century. Despite this it is more often than not that
methods in both fields are applied only to problems of one type of encoding.
However, many real-world problems require parameters vectors that use multiple
encodings. This paper presents a suite of novel multi-objective optimisation
test problems (Exeter1 to 6) with mixed encodings (real and binary) and offer
variable correlation between the objectives at different stages of the search.
The problems are demonstrated using NSGA-II, SPEA2 and a (mu + lambda)
Evolution Strategy which were modified to operate on both encodings
simultaneously.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lockett:2011:MEA,
  title     = {Measure-Theoretic Evolutionary Annealing},
  author    = {Alan Lockett and Risto Miikkulainen},
  pages     = {2132--2139},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Evolutionary computation theory, Convergence, scalability and complexity analysis},
  abstract  = {
There is a deep connection between simulated annealing and genetic algorithms
with proportional selection. Evolutionary annealing is a novel evolutionary
algorithm that makes this connection explicit, resulting in an evolutionary
optimization method that can be viewed either as simulated annealing with
improved sampling or as a non-Markovian selection mechanism for genetic
algorithms with selection over all prior populations. A martingale-based
analysis shows that evolutionary annealing is asymptotically convergent and
this analysis leads to heuristics for setting learning parameters to optimize
the convergence rate. In this work and  in parallel work evolutionary
annealing is shown to converge faster than other evolutionary algorithms on
several benchmark problems,  establishing a promising foundation for future
theoretical and experimental research into algorithms based on evolutionary
annealing.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Emmerich:2011:HEIMPaEC,
  title     = {Hypervolume-based Expected Improvement: Monotonicity Properties and Exact Computation},
  author    = {Michael Emmerich and Andre Deutz and Jan Willem Klinkenberg},
  pages     = {2140--2147},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Meta-modeling and surrogate models, Multi-objective evolutionary algorithms},
  abstract  = {
The expected improvement (EI) is a well established criterion in Bayesian
global optimization (BGO) and metamodel-assisted evolutionary computation,
both applied in optimization with costly function evaluations. Recently, it
has been adopted in different ways to multiobjective optimization. A promising
approach to formulate the expected improvement in this context, is to base it
on the hypervolume indicator. Given the Bayesian model of the optimization
landscape, the EI in hypervolume computes the expected gain in attained
hypervolume for a given input point. Although a formulation of this expected
improvement is relatively straightforward, its computation and mathematical
properties are still to be investigated. This paper will outline and derive an
algorithm for the  exact computation of the proposed  hypervolume-based EI.
Moreover, this paper establishes monotonicity properties of the expected
improvement. In particular the effect of the predictive distribution's
variance on the hypervolume-based EI and elementary properties of the EI
landscape are studied. The monotonicity properties will reveal regions where
Pareto front approximations can be improved as well as underexplored regions
that are favored by the hypervolume-based expected improvement. A first
numerical example is included that illustrates the behavior of the
hypervolume-based EI in the multiobjective BGO framework.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Diaz-Manriquez:2011:OtSoSMiEOA,
  title     = {On the Selection of Surrogate Models in Evolutionary Optimization Algorithms},
  author    = {Alan Diaz-Manriquez and Gregorio Toscano-Pulido and Wilfrido Gomez-Flores},
  pages     = {2148--2155},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Meta-modeling and surrogate models},
  abstract  = {
Since many real-world problems are related to the satisfaction of at least one
goal,  several optimization techniques have been proposed in the past.
However, traditional optimization techniques are  computationally expensive
and are normally highly susceptible to some characteristics such as high
dimensionality, non-differentiability, non-linearity, highly expensive
function calculation, among others. Evolutionary algorithms are  bio-inspired
meta-heuristics that have shown flexibility, adaptability and good performance
when solving these sort of problems. In order to achieve acceptable results,
some problems usually require several evaluations of the optimization
function. However, when each of these evaluations represents a high
computational cost, these problems remain intractable even by these
meta-heuristics.

To reduce the computational cost in expensive optimization problems, some
researchers have replaced the real optimization function with a
computationally inexpensive surrogate model.  Despite there are  comparison
studies  among these techniques, these studies focused on revised the accuracy
of the meta-model for the problem at hand, but neither its suitability to be
used with evolutionary algorithms, nor its scalability in the variable design
space.

In this work, we compare four meta-modeling techniques, polynomial
approximation, kriging, radial basis functions and support vector regression,
in different aspects such as accuracy, robustness, efficiency, and scalability
with the aim to identify  advantages and disadvantages of each meta-modeling
technique in order to select the most suitable one to be combined with
evolutionary optimization algorithms.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Engineering  Applications I
@InProceedings{Spangenberg:2011:OoCPPfHADiSCAFS,
  title     = {Optimization of Casting Process Parameters for Homogeneous Aggregate Distribution in Self-Compacting Concrete: A Feasibility Study},
  author    = {Jon Spangenberg and Cem Celal Tutum and Jesper Henri Hattel and Nicolas Roussel and Mette Rica Geiker},
  pages     = {2156--2162},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Evolutionary simulation-based optimization, Real-world applications},
  abstract  = {
The use of self-compacting concrete (SCC) as a construction material has been
getting more attention from the industry. Its application area varies from
standard structural elements in bridges and skyscrapers to modern architecture
having geometrical challenges. However, heterogeneities induced during the
casting process may lead to variations of local mechanical properties and
hence to a potential decrease in load carrying capacity of the structure. This
paper presents a methodology for optimization of SCC casting aiming at having
a homogeneous aggregate distribution; a beam has been used as geometric
example. The aggregate distribution is predicted by a numerical flow model
coupled with a user defined volume fraction subroutine. The process parameters
in casting with SCC in general  are horizontal and vertical positions,
movement, as well as the size of the inlet, and the duration of the filling
etc., however since this work is the initial feasibility study in this field,
only three process parameters are considered. Despite the reduction in the
number of process parameters, the complexity involved in the considered
casting process results in a non trivial optimal design set.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Trivedi:2011:IMEAfDTGS,
  title     = {Improved Multi-objective Evolutionary Algorithm for Day-Ahead Thermal Generation Scheduling},
  author    = {Anupam Trivedi and Naran M.Pindoriya and Dipti Srinivasan and Deepak Sharma},
  pages     = {2163--2170},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Real-world applications},
  abstract  = {
This paper presents a multi-objective evolutionary algorithm to solve the
day-ahead thermal generation scheduling problem. The objective functions
considered to model the scheduling problem are: 1) minimizing the system
operation cost and 2) minimizing the emission cost. In the proposed algorithm,
the chromosome is formulated as a binary unit commitment matrix (UCM) which
stores the generator on/off states and a real power matrix (RPM) which stores
the corresponding power dispatch. Problem specific binary genetic operators
act on the binary UCM and real genetic operators act on the RPM to effectively
explore the large binary and real search spaces separately. Heuristics are
used in the initial population by seeding the random population with two
Priority list (PL) based solutions for faster convergence. Intelligent repair
operator based on PL is designed to repair the solutions for load demand
equality constraint violation. The ranking, selection and elitism methods are
borrowed from NSGA-II. The proposed algorithm is applied to a large scale 60
generating unit power system and the simulation results are presented and
compared with our earlier algorithm [26]. The presented algorithm is found to
outperform our earlier algorithm in terms of both convergence and spread in
the final Pareto-optimal front.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Madeiro:2011:SCPaRfLRiDNbaHGA,
  title     = {Simultaneous Capacitor Placement and Reconfiguration for Loss Reduction in Distribution Networks by a Hybrid Genetic Algorithm},
  author    = {Salomao Madeiro and Edson Galvao and Celso Cavellucci and Christiano Lyra and Fernando J. {Von Zuben}},
  pages     = {2171--2178},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Genetic algorithms},
  abstract  = {
There are two common strategies for technical loss reduction in electric power
distribution networks: (a) the installation of capacitor banks to compensate
the losses produced by reactive currents; and (b) the redefinition of the
topology of electric distribution networks by changing the state of some
sectionalizing switches to balance the load. Both strategies can be formulated
as combinatorial optimization problems. The optimization problems for the
first and the second strategies are usually known as Capacitor Placement
Problem (CPP) and Network Reconfiguration Problem (NRP), respectively. In this
paper, we propose a new approach based on Genetic Algorithm (GA) to solve both
CPP and NRP simultaneously. The new approach makes use of two previously
proposed and independent techniques for the CPP and the NRP. The performance
of the new approach is compared with the performance of the two previously
proposed techniques applied in a separate manner. The experiments show that
the new method is more efficient regarding the metrics of power loss reduction
and voltage profile enhancement.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Liu:2011:Sancsdwmga,
  title     = {Space active noise control system design with multi-objective genetic algorithms},
  author    = {Huideng Liu and Arui Qiu},
  pages     = {2179--2185},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Real-world applications},
  abstract  = {
The model for the space active noise control system is investigated in this
paper and is converted to a multi-objective optimization problem with
constraints, of which the positions of secondary speakers and error sensors
are the decision variables, the summation of the squared pressure at all
points within the noise quiet zone and the total source strength for the
secondary speakers are the multi-objective functions. The multi-objective
genetic algorithms and simple genetic algorithm are implemented to solve the
optimization problem so as to determine the appropriate positions of the
secondary speakers and error sensors. The large sound pressure reduction
within the noise quiet zone to control the single tone primary noise and motor
operating noise shows that the optimal schemes obtained by the genetic
algorithms are efficient.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Complex Networks and Evolutionary Computation I
@InProceedings{Amiri:2011:AEMEAfCDiSN,
  title     = {An Efficient Multiobjective Evolutionary Algorithm for Community Detection in Social Networks},
  author    = {Babak Amiri and Liaquat Hossain and  John W Crawford},
  pages     = {2186--2192},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Community detection in complex networks has been has been addressed in
different ways recently. To identify communities in social networks we can
formulate it with two different objectives, maximization of internal links and
minimization of external links. Because these two objects are correlated, the
relationship between these two objectives is a trade-off. This study employed
harmony search algorithm, which was conceptualized using the musical process
of finding a perfect state of harmony to perform this bi- objective trade-off.
In the proposed algorithm an external repository considered to save
non-dominated solutions found during the search process and a fuzzy clustering
technique is used to control the size of repository.  The harmony search
algorithm was applied on well-known real life networks, and good Pareto
solutions were obtained when compared with other algorithms, such as the
MOGA-Net and Newman algorithms.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chira:2011:FEfOCDiCN,
  title     = {Fitness Evaluation for Overlapping Community Detection in Complex Networks},
  author    = {Camelia Chira and Anca Gog},
  pages     = {2193--2199},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
The discovery of community structures in complex networks is a challenging
problem intensively studied in recent years. This paper investigates the
performance of evolutionary algorithms for the task of detecting overlapping
communities. This task is of great importance as the membership of a node to
more than one group is naturally occuring in many real-world networks from
fields such as sociology, biology and computer science. One of the major
challenges in designing evolutionary algorithms for overlapping community
detection is the efficient assessment of the quality of any particular
division of nodes into groups. We test four different fitness functions in an
evolutionary approach to the problem using the same chromosome representation
and search scheme. The performance of the resulting algorithms is tested in a
set of computational experiments for some real-world networks. We show that
none of the fitness functions used are able to guide the search process
towards good partitions based on a measure of the normalized mutual
information.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Naruchitparames:2011:FRiSNuGAaNT,
  title     = {Friend Recommendations in Social Networks using Genetic Algorithms and Network Topology},
  author    = {Jeffrey Naruchitparames and Mehmet Gunes and Sushil Louis},
  pages     = {2200--2207},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Social networking sites employ recommendation systems in contribution to
providing better user experiences. The complexity in developing recommendation
systems is largely due to the heterogeneous nature of social networks. This
paper presents an approach to friend recommendation systems by using complex
network theory, cognitive theory and a Pareto-optimal genetic algorithm in a
two-step approach to provide quality, friend recommendations while
simultaneously determining an individual's perception of friendship. Our
research emphasizes that by combining network topology and genetic algorithms,
better recommendations can be achieved compared to each individual
counterpart. We test our approach on 1,200 Facebook users in which we observe
the combined method to outperform purely social or purely network-based
approaches. Our preliminary results represent strong potential for developing
link recommendation systems using this combined approach of personal interests
and the underlying network.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Differential Evolution II
@InProceedings{Takahama:2011:ENObDEwaRLSO,
  title     = {Efficient Nonlinear Optimization by Differential Evolution with a Rotation-Invariant Local Sampling Operation},
  author    = {Tetsuyuki Takahama and Setsuko Sakai},
  pages     = {2208--2215},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Differential evolution},
  abstract  = {
Differential Evolution (DE) is a newly proposed evolutionary algorithm. DE has
been successfully applied to optimization problems including non-linear,
non-differentiable, non-convex and multimodal functions. However, the
performance of DE degrades in problems having strong dependence among
variables, where variables are strongly related to each other. One of the
desirable properties of optimization algorithms for solving the problems with
the strong dependence is rotation-invariant property. In DE, the mutation
operation is rotation-invariant, but the crossover operation is not
rotation-invariant usually. In this study, we propose a new operation, called
local sampling operation that is rotation-invariant. In the operation,
independent points are selected from the population, difference vectors from a
parent to the points span a local area centered at the parent, and a new point
is generated around the area. Also, the operation is used for judging whether
intensive search or extensive search is desirable in each generation. The
effect of the proposed method is shown by solving some benchmark problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chakraborty:2011:CiMAHNwDE,
  title     = {Clustering in Mobile Ad Hoc Networks with Differential Evolution},
  author    = {Uday Chakraborty and Sajal Das and Travis Abbott},
  pages     = {2216--2221},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Differential evolution, Real-world applications},
  abstract  = {
This paper presents a new, differential-evolution-based method for solving the
problem of optimal selection of cluster-heads and cluster-members in mobile ad
hoc networks. A novel encoding scheme is used to represent nodes in the
network graph, and randomly-generated networks of different sizes are solved.
The present method handles problems of much larger sizes than do the
best-known methods in the literature. Empirical results show the superiority
of this method over state-of-the-art approaches on two counts: quality of the
solution and time to find the solution.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Noman:2011:AADEA,
  title     = {An Adaptive Differential Evolution Algorithm},
  author    = {Nasimul Noman and Danushka Bollegala and Hitoshi Iba},
  pages     = {2222--2229},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Self-adaptation in evolutionary computation, Differential evolution},
  abstract  = {
The performance of Differential Evolution (DE) algorithm is significantly
affected by its parameter setting. But the choice of parameters is heavily
dependent on the problem characteristics. Therefore, recently a couple of
adaptation schemes that automatically adjust DE parameters have been proposed.
The current work presents another adaptation scheme for DE parameters namely
amplification factor and crossover rate. We systematically analyze the
effectiveness of the proposed adaptation scheme for DE parameters using a
standard benchmark suite consisting of ten functions. The undertaken empirical
study shows that the proposed adaptive DE (aDE) algorithm exhibits an overall
better performance compared to other prominent adaptive DE algorithms as well
as canonical DE.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Evolutionary Games and Multi-agent Systems I
@InProceedings{Adra:2011:AMOAFTDIaROAMS,
  title     = {A Multiobjective Optimisation Approach For The Dynamic Inference and Refinement Of Agent-Based Model Specifications},
  author    = {Salem Adra and Mariam Kiran and Phil McMinn and Neil Walkinshaw},
  pages     = {2230--2237},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary games and multi-agent systems, Multiobjective optimization, Evolutionary simulation-based optimization},
  abstract  = {
Despite their increasing popularity, agent-based models are hard to test, and
so far no established testing technique has been devised for this kind of
software applications. Reverse engineering an agent-based model specification
from model simulations can help establish a confidence level about the
implemented model and in some cases reveal discrepancies between observed and
normal or expected behaviour. In this study, a multiobjective optimisation
technique based on a simple random search algorithm is deployed to dynamically
infer and refine the specification of three agent-based models from their
simulations. The multiobjective optimisation technique also incorporates a
dynamic invariant detection technique which serves to guide the search towards
uncovering new model behaviour that better captures the model specification.
The Non-Dominated Sorting Genetic Algorithm (NSGA-II) [1] was also deployed to
replace the random search algorithm, and the results from both approaches were
compared. While both algorithms revealed good potential in capturing the model
specifications, the pure exploratory nature of random search was found more
suitable for the application at hand, compared to the balanced
exploitation/exploration nature of genetic algorithms in general.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Sarraf-Shirazi:2011:HSLiAMotMSP,
  title     = {Hierarchical Self-Organized Learning in Agent-Based Modeling of the MAPK Signaling Pathway},
  author    = {Abbas Sarraf Shirazi and Sebastian {von Mammen} and Christian Jacob},
  pages     = {2238--2244},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary games and multi-agent systems},
  abstract  = {
In this paper, we present a self-organized approach to automatically identify
and create hierarchies of cooperative agents. Once a group of cooperative
agents is found, a higher-order agent is created which in turn learns the
group behaviour. This way, the number of agents and thus the complexity of the
multiagent system will be reduced, as one agent emulates the behaviour of
several agents. Our proposed method of creating hierarchies captures the
dynamics of a multiagent system by adaptively creating and breaking down
hierarchies of agents as the simulation proceeds. Experimental results on two
MAPK signaling pathways suggest that the proposed approach is suitable in
stable systems while periodic systems still need further investigations.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Al-Khateeb:2011:TIoLDiEC,
  title     = {The Importance of Look-Ahead Depth in Evolutionary Checkers},
  author    = {Belal Al-Khateeb and Graham Kendall},
  pages     = {2245--2251},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary games and multi-agent systems, Games},
  abstract  = {
Intuitively it would seem to be the case that any learning algorithm would
perform better if it was allowed to search deeper in the game tree. However,
there has been some discussion as to whether the evaluation function or the
depth of the search is the main contributory factor in the performance of the
player. There has been some evidence suggesting that look-ahead (i.e. depth of
search) is particularly important. In this work we provide a rigorous set of
experiments, which support this view. We believe this is the first time such
an intensive study has been carried out for evolutionary checkers. Our
experiments show that increasing the depth of a look-ahead has significant
improvements to the performance of the checkers program and has a significant
effect on its learning abilities.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Wang:2011:GNPwURA,
  title     = {Genetic Network Programming with Updating Rule Accumulation},
  author    = {Lutao Wang and Shingo Mabu and Kotaro Hirasawa},
  pages     = {2252--2259},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary computation theory, Evolutionary simulation-based optimization, Evolutionary games and multi-agent systems},
  abstract  = {
Conventional evolutionary computation methods aim to find elite individuals as
the optimal solutions. The rule accumulation method tries to find good
experiences from individuals throughout the generations and store them as
decision rules, which is regarded as solutions. Genetic Network Programming
(GNP) is competent for dynamic environments because of its directed graph
structure, reusability of nodes and partially observable processes. A GNP
based rule accumulation method has been studied and applied to the stock
trading problem. However, with the changing of dynamic environments, the old
rules in the rule pool are incompetent for guiding new agent's actions, thus
updating these rules becomes necessary. This paper proposes a new method to
update the accumulated rules in accordance with the environment changes.
Sarsa- learning which is a good on-line learning policy is combined with
off-line evolution to generate better individuals and update the rules in the
rule pool. Tileworld problem which is an excellent benchmark for multi-agent
systems is used as the simulation environment. Simulation results demonstrate
the efficiency and effectiveness of the proposed method in dealing with the
changing environments.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Session: Evolutionary Computation in Network Optimization
@InProceedings{Goulart:2011:BRGAfFIiONO,
  title     = {Biased Random-key Genetic Algorithm for Fiber Installation in Optical Network Optimization},
  author    = {Nata Goulart and Luiz Dias and Sergio Souza and Thiago Noronha},
  pages     = {2260--2264},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Real-world applications},
  abstract  = {
The problem of Fiber Installation in Optical Network Optimization consists in
routing a set of lightpaths (all-optical connections), such that the cost of
the optical components necessary to operate the network is minimized. We
propose a genetic algorithm with random keys that extends the best heuristic
in the literature by embedding it into an evolutionary framework.
Computational results showed that the new heuristic improves the best
heuristic in the literature.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Rocha:2011:MEAfIRO,
  title     = {Multiobjective Evolutionary Algorithms for Intradomain Routing Optimization},
  author    = {Miguel Rocha and Tiago Sa and Pedro Sousa and Paulo Cortez and Miguel Rio},
  pages     = {2265--2272},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Evolutionary Algorithms (EAs) have been used to develop methods for Traffic
Engineering (TE) over IP-based networks in the last few years, being used to
reach the best set of link weights in the configuration of intra-domain
routing protocols, such as OSPF. In this work, the multiobjective nature of a
class of optimization problems provided by TE with Quality of Service
constraints is identified. Multiobjective EAs (MOEAs) are developed to tackle
these tasks and their results are compared to previous approaches using single
objective EAs. The effect of distinct genetic representations within the MOEAs
is also explored. The results show that the MOEAs provide more flexible
solutions for network management, but are in some cases unable to reach the
level of quality obtained by single objective EAs. Furthermore, a freely
available software application is described that allows the use of the
mentioned optimization algorithms by network administrators, in an
user-friendly way by providing adequate user interfaces for the main TE tasks.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Zhong:2011:ELWSiWSN,
  title     = {Energy-Efficient Local Wake-up Scheduling in Wireless Sensor Networks},
  author    = {Jing-hui Zhong and Jun Zhang},
  pages     = {2273--2277},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Ant colony optimization},
  abstract  = {
scheduling sensor activities is an effective way to prolong the lifetime of
wireless sensor networks (WSNs). In this paper, we explore the problem of
wake- up scheduling in WSNs where sensors have different lifetime. A novel
local wake- up scheduling (LWS) strategy is proposed to prolong the network
lifetime with full coverage constraint. In the LWS strategy, sensors are
divided into a first layer set and a successor set. The first layer set which
satisfies the coverage constraint is activated at the beginning. Once an
active sensor runs out of energy, some sensors in the successor set will be
activated to satisfy the coverage constraint. Based on the LWS strategy, this
paper presents an ant colony optimization based method, namely mc-ACO, to
maximize the network lifetime. The mc-ACO is validated by performing
simulations on WSNs with different characteristics. A recently published
genetic algorithm based wake-up scheduling method and a greedy based method
are used for comparison. Simulation results reveal that mc-ACO yields better
performance than the two algorithms.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Schroeder:2011:ITRfSoCGbMEO,
  title     = {Inferring Transcriptional Regulators for Sets of Co-expressed Genes by Multi-objective Evolutionary Optimization},
  author    = {Adrian Schroeder and Clemens Wrzodek and Johannes Wollnik and Andreas Draeger and Dierk Wanke and Kenneth W. Berendzen and Andreas Zell},
  pages     = {2278--2285},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Higher organisms are able to respond to continuously changing external
conditions by transducing cellular signals into specific regulatory programs,
which control gene expression states of thousands of different genes. One of
the central problems in understanding gene regulation is to decipher how
combinations of transcription factors control sets of co-expressed genes under
specific experimental conditions. Existing methods in this field mainly focus
on sequence aspects and pattern recognition, e.g., by detecting cis-regulatory
modules (CRMs) based on gene expression profiling data. We propose a novel
approach by combining experimental data with a priori knowledge of respective
experimental conditions. These various sources of evidence are likewise
considered using multi-objective evolutionary optimization. In this work, we
present three objective functions that are especially designed for
stimulus-response experiments and can be used to integrate a priori knowledge
into the detection of gene regulatory modules. This method was tested and
evaluated on whole-genome microarray measurements of drug-response in human
hepatocytes.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Biometrics, Bioinformatics and Biomedical Applications I
@InProceedings{Miller:2011:IRoQCSvGA,
  title     = {Improved Reconstruction of Quantized CT Scans via Genetic Algorithms},
  author    = {Chris Miller and Frank Moore and Brendan Babb and Michael Peterson},
  pages     = {2286--2292},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Real-world applications, Genetic algorithms, Biometrics, bioinformatics and biomedical applications},
  abstract  = {
Cost-effective storage and timely transmission of medical images are very
difficult technical challenges. Compression and reconstruction techniques must
guarantee no significant loss of clinical information. This paper presents a
convenient technique for improving the quality of reconstructed computed
tomography (CT) images previously subjected to specified levels of lossy
compression. Our genetic algorithm (GA) evolves novel transforms that
consistently outperform state-of-the-art wavelet-based schemes supported by
the Digital Imaging and Communication in Medicine (DICOM) standard.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chira:2011:AHEAtPSPwLM,
  title     = {A Hybrid Evolutionary Approach to Protein Structure Prediction with Lattice Models},
  author    = {Camelia Chira},
  pages     = {2293--2299},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications, Genetic algorithms},
  abstract  = {
The prediction of minimum-energy protein structures starting from a sequence
of amino acids is a computationally challenging problem even in simplified
lattice protein models. A hybrid evolutionary model is designed and tested in
the current paper to address this well-known NP-hard problem. Hill-climbing
strategies are integrated in the search operators and a meaningful
diversification of genetic material occurs during the population evolution.
The main features of the proposed algorithm refer to a weak hill-climbing
application of uniform crossover and pullmove transformations and the
randomization of genetic material based on the fingerprint of the protein
conformations. Numerical experiments are performed for several difficult
bidimensional instances from lattice models (the hydrophobic-polar model and
functional model proteins). The results are competitive with those obtained by
related population-based optimization algorithms.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Garza-Fabre:2011:CAEFftHMoPSP,
  title     = {Comparing Alternative Energy Functions for the HP Model of Protein Structure Prediction},
  author    = {Mario Garza-Fabre and Eduardo Rodriguez-Tello and Gregorio Toscano-Pulido},
  pages     = {2300--2307},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications, Discrete and combinatorial optimization.},
  abstract  = {
Protein structure prediction is the problem of finding the functional
conformation of a protein given only its amino acid sequence. The HP lattice
model is an abstract formulation of this problem, which captures the fact that
hydrophobicity is one of the major driving forces in the protein folding
process. This model represents a hard combinatorial optimization problem and
has been widely addressed through metaheuristics such as evolutionary
algorithms. However, the conventional energy (evaluation) function of the HP
model does not provide an adequate discrimination among potential solutions,
which is an essential requirement for metaheuristics in order to perform an
effective search. Therefore, alternative energy functions have been proposed
in the literature to cope with this issue. In this study, we inquire into the
effectiveness of several of such alternative approaches. We analyzed the
degree of discrimination provided by each of the studied functions as well as
their impact on the behavior of a basic memetic algorithm. The obtained
results support the relevance of following this research direction. To our
knowledge, this is the first work reported in this regard.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Kessentini:2011:Psoaemfpba,
  title     = {Particle swarm optimization and evolutionary methods for plasmonic biomedical applications},
  author    = {Sameh Kessentini and Dominique Barchiesi and Thomas Grosges and Marc Lamy {de la Chapelle}},
  pages     = {2308--2313},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications, Particle swarm optimization, Evolutionary programming},
  abstract  = {
In this paper the Evolutionary Method (EM) and the Particle Swarm Optimization
(PSO), which are based on competitiveness and collaborative algorithms
respectively, are investigated for plasmonic design. Actually, plasmonics
represents a rapidly expanding interdisciplinary field with numerous devices
for physical, biological and medicine applications. In this study, four EM and
PSO algorithms are tested in two different plasmonic applications: design of
surface plasmon resonance (SPR) based biosensors and optimization of hollow
nanospheres used in curative purposes (cancer photothermal therapy). Specific
problems--in addition of being multimodal and having different topologies--
are related to plasmonic design; therefore the most efficient optimization
method should be determined through a comparative study. Results of
simulations enable also to characterize the optimization methods and depict in
which case they are more efficient.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Heuristics and Hyper Heuristics
@InProceedings{Pasti:2011:HtARSoPMCO,
  title     = {Heuristics to Avoid Redundant Solutions on Population-Based Multimodal Continuous Optimization},
  author    = {Rodrigo Pasti and Renato Dourado Maia and Fernando J. {Von Zuben} and Leandro Nunes {de Castro}},
  pages     = {2314--2321},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Heuristics, metaheuristics and hyper-heuristics, Self-adaptation in evolutionary computation},
  abstract  = {
In population-based meta-heuristics, the generation and maintenance of
diversity seem to be crucial to deal with multimodal continuous optimization.
However, usually this crucial aspect is not an inherent feature of generally
adopted meta-heuristics. In this paper, we propose to associate diversity
maintenance with the detection and elimination of redundant candidate
solutions in the search space, more specifically candidate solutions located
at the same attraction basin of a local optimum. Two low computational cost
heuristics are proposed to detect redundancy, in a pairwise comparison of
candidate solutions and by extracting local features of the fitness landscape
at runtime. Those heuristics are not tied to a specific class of algorithms,
and are thus able to be incorporated into a broad range of population-based
meta-heuristics, and even into multiple executions of non-population-based
algorithms. In a set of experimental results, the two heuristics were
implemented as an attached module of an already existing multipopulation
meta-heuristics, and the results indicate that they operate properly, no
matter the number and conformation of the attraction basins  in multimodal
optimization problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Bui:2011:AGHfTPP,
  title     = {A Grid-Based Heuristic for Two-Dimensional Packing Problems},
  author    = {Lam Thu Bui and Hussein Abbass and Stephen Baker and Michael Barlow and Axel Bender},
  pages     = {2322--2329},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Heuristics, metaheuristics and hyper-heuristics, Genetic algorithms},
  abstract  = {
To solve two-dimensional (2D) rectangular packing problems, we introduce a new
spatial method based on the discretization of the container into a grid of
cells with predefined resolution. Before an item is added, grid cells are
checked whether they can accommodate the item. If an appropriate empty cell
cluster is found, the item is added and moved towards the bottom-left corner
of the container. This placement and sliding method is supplemented by a
heuristic that orders the items according to descending size. Order and
rotation of items can be improved by hybridizing the heuristic with a genetic
algorithm (GA) in which a population of order-rotation chromosomes is evolved.
The method is tested on 47 benchmark problems and compared to other methods in
the literature. This shows that it is fast and performs very well in finding
close to optimal problem solutions. Particularly for large problem sizes, it
outperforms some of the currently leading methods, such as heuristic recursive
(HR). The hybridization with the GA metaheuristic results in further
performance improvements.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Grobler:2011:ItIoAESSoMGO,
  title     = {Investigating the Impact of Alternative Evolutionary Selection Strategies on Multi-method Global Optimization},
  author    = {Jacomine Grobler and Andries P. Engelbrecht and Graham Kendall and V.S.S. Yadavalli},
  pages     = {2330--2337},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Heuristics, metaheuristics and hyper-heuristics},
  abstract  = {
Algorithm selection is an important consideration in multi-method global
optimization. This paper investigates the use of various algorithm selection
strategies derived from well known evolutionary selection mechanisms.
Selection strategy performance is evaluated on a diverse set of floating point
benchmark problems and meaningful conclusions are drawn with regard to the
impact of selective pressure on algorithm selection in a multi-method
environment.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Alimadad:2011:MHStSCUaCA,
  title     = {Modeling HIV Spread through Sexual Contact Using a Cellular Automaton},
  author    = {Azadeh Alimadad and Vahid Dabbaghian and Singh Singh and Herbert H. Tsang},
  pages     = {2338--2343},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Heuristics, metaheuristics and hyper-heuristics},
  abstract  = {
Having a risky sexual behaviour increases the likeliness of infection by the
Human Immunodeficiency Virus (HIV), which causes the Acquired Immunodeficiency
Syndrom (AIDS). This has been a long lasting problem in high-risk populations
such as sex workers: individuals in this population may face drug addiction
and share infected needles, or have unprotected sex, and both issues can
result in an HIV infection that may then be transmitted to other parts of the
population. To study the dynamics of the HIV epidemic in such a highrisk
community, we propose a model in which the population is represented as a
cellular automaton. At the macro-level, our model accounts for the fact that
the sexual behaviour of an individual is influenced by the social norms of his
acquaintances(social network) as well as by his awareness of HIV status. At
the micro-level, randomized neighborhoods provide an explicit representation
of personal interactions standing for the large number of non-repeated
encounters in populations at risk. Our simulations study the dynamics of the
disease for different social norms as well as the probability that a
seropositive individual get tested.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Multi-objective Optimization IV
@InProceedings{Legriel:2011:OUSSfMOUWS,
  title     = {On Universal Search Strategies for Multi-Criteria Optimization Using Weighted Sums},
  author    = {Julien Legriel and Scott Cotton and Oded Maler},
  pages     = {2344--2351},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization},
  abstract  = {
We develop a stochastic local search algorithm for finding Pareto points for
multicriteria optimization problems. The algorithm alternates between
different single-criterium optimization problems characterized by weight
vectors. The policy for switching between different weights is an adaptation
of the universal restart strategy defined by [LSZ93] in the context of Las
Vegas algorithms. We demonstrate the effectiveness of our algorithm on
multicriteria quadratic assignment problem benchmarks and prove some of its
theoretical properties.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Batista:2011:ACoDCiMOP,
  title     = {A Comparison of Dominance Criteria in Many-Objective Optimization Problems},
  author    = {Lucas Batista and Felipe Campelo and Frederico Guimaraes and Jaime Ramirez},
  pages     = {2352--2359},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization},
  abstract  = {
In this paper, we analyze four dominance criteria in terms of their ability to
adequately order sets of points in multi- and many-objective optimization
problems. The use of relaxed and alternative dominance relationships has been
an important tool for improving the performance of multiobjective evolutionary
optimization algorithms, and their ordering ability is among the most
important characteristics responsible for such improvement. Three relaxed
formulations of dominance are investigated, along with the traditional Pareto
ordering, in order to provide a comparison baseline. The results obtained show
that all three relaxed dominance approaches presented greater robustness to
the increase in the number of objectives, and are therefore more appropriate
for use in many-objective optimization algorithms.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Zapotecas-Martinez:2011:ANSSAfMO,
  title     = {A Nonlinear Simplex Search Approach for Multi-Objective Optimization},
  author    = {Saul Zapotecas Martinez and Alfredo Arias-Montano and Carlos A. {Coello Coello}},
  pages     = {2360--2367},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization},
  abstract  = {
This paper proposes an algorithm for dealing with nonlinear and unconstrained
multi-objective optimization problems (MOPs). The proposed algorithm adopts a
nonlinear simplex search scheme in order to obtain multiple approximations of
the Pareto optimal set. The search is directed by a well-distributed set of
weighted vectors. Each weighted vector defines a scalarization problem which
is solved by deforming a simplex according to the movements described by
Nelder and Mead's method. The simplex is constructed with a set of solutions
which minimize different scalarization problems defined by a set of neighbor
weighted vectors. The solutions found in the search are used to update a set
of solutions considered to be the minima for each separate problem. In this
way, the proposed algorithm collectively obtains multiple trade-offs among the
different conflicting objectives, while maintaining a well distributed set of
solutions along the Pareto front. The main aim of this work is to show that a
well-designed strategy using just mathematical programming techniques can be
competitive with respect to a state-of-the-art multi-objective evolutionary
algorithm.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Hamada:2011:AWA2MSAfMFO,
  title     = {Adaptive Weighted Aggregation 2: More Scalable AWA for Multiobjective Function Optimization},
  author    = {Naoki Hamada and Yuichi Nagata and Shigenobu Kobayashi and Isao Ono},
  pages     = {2368--2375},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Convergence, scalability and complexity analysis},
  abstract  = {
Adaptive Weighted Aggregation (AWA) is a framework of multi-starting
optimization methods based on scalarization for solving multiobjective
function optimization problems. It progressively generates new solutions to
refine the approximation of the Pareto set or the Pareto front by the
subdivision, and iteratively estimates the appropriate weight vector for
scalarization in each search by the weight adaptation. Our recent study shows
that AWA's solution set combinatorially increases for the number of
objectives. In this paper, we propose a new subdivision and weight adaptation
scheme of AWA to improve its scalability. Numerical experiments show that the
effectiveness of the proposed method.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Coevolutionary Systems
@InProceedings{Zeng:2011:SoPMCCD,
  title     = {Studies of Pareto-based Multi-objective Competitive Coevolutionary Dynamics},
  author    = {Fanchao Zeng and Decraene James and Malcolm Yoke Hean Low and Wentong Cai and Philip Hingston},
  pages     = {2376--2383},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Coevolutionary systems, Multiobjective optimization},
  abstract  = {
Competitive coevolutionary algorithms are stochastic population-based search
algorithms. To date, most of the competitive coevolution research has been
done in the domain of single-objective optimization. We propose a novel
competitive coevolutionary framework to explore Pareto-based multi-objective
competitive coevolution. This framework utilizes the hypervolume indicator and
fitness sharing mechanism to address disengagement and over-specification
issues. A diversity- driven evolutionary selection scheme is utilized to deal
with the loss of fitness gradient problem. Several series of experiments are
conducted using multi- objective two-sided competitive games. The results
suggest that Pareto-optimal solution sets can effectively be found using our
proposed coevolutionary framework.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Rothman:2011:DMTHUM,
  title     = {Do Multiple Trials Help Univariate Methods?},
  author    = {Daniel Rothman and Sean Luke and Keith Sullivan},
  pages     = {2384--2391},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Coevolutionary systems, Estimation of distribution algorithms},
  abstract  = {
Cooperative Coevolutionary Algorithms (CCEAs) and Univariate Estimation of
Distribution Algorithms (Univariate EDAs) are closely related algorithms in
that both update marginal distributions/populations, and test samples of those
distributions/populations by grouping them with collaborators drawn from
elsewhere to form a complete solution.  Thus the quality of these samples is
context-sensitive and the algorithms assume low linkage among their variables.
This results in well-known difficulties with these methods.  While EDAs have
commonly overcome these difficulties by examining multivariate linkage, CCEAs
have instead examined basing the fitness of each marginal sample on the
maximum of several trials.  In this study we examine whether multiple-trial
CCEA approach is really effective for difficult problems and large numbers of
subpopulations; and whether this approach can be used to improve Univariate
EDAs as well.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ly:2011:TSSfCRP,
  title     = {Trainer Selection Strategies for Coevolving Rank Predictors},
  author    = {Daniel Ly and Hod Lipson},
  pages     = {2392--2399},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Coevolutionary systems, Evolution strategies, Coevolution and collective behavior},
  abstract  = {
Despite the range of applications and successes of evolutionary algorithms,
expensive fitness computations often form a critical performance bottleneck. A
preferred method of reducing the computational overhead is to coevolve rank
predictors, providing a coarse and lightweight fitness approximation that has
proven to drastically increase performance. However, the majority of previous
work on rank predictor coevolution focused solely on improving the predictor
heuristics while strategies to select the equally important trainer population
is often an afterthought. Four different strategies are presented and
benchmarked on a symbolic regression problem using hundreds of test problems
with varying complexities. Of the four strategies, updating the trainer
population with the solution of the highest rank variance is found to be
significantly superior, resulting in a four to ten fold reduction in
computational effort for similar convergence rates over the remaining
strategies.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ibrahimov:2011:CoDEAfGSCOaPA,
  title     = {Comparison of Different Evolutionary Algorithms for Global Supply Chain Optimisation and Parameter Analysis},
  author    = {Maksud Ibrahimov and Arvind Mohais and Sven Schellenberg and Zbigniew Michalewicz},
  pages     = {2400--2407},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Coevolutionary systems, Genetic algorithms, Heuristics, metaheuristics and hyper-heuristics},
  abstract  = {
This paper discusses global optimisation from a business perspective in the
context of the supply chain operations. A two-silo supply chain was built for
experimentation and three approaches were used for global optimisation: a
classical evolutionary approach, a cooperative coevolutionary approach and a
coevolutionary approach with on the fly partner generation where the solution
from the second component of the supply chain is generated deterministically
based on the first one. The second approach produced higher quality solutions
due to its use of communication between silos. Additional experiment was
conducted to choose optimal species sizes.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Wen:2011:ACCPLCSEwMFS,
  title     = {A Cooperative Coevolution-Based Pittsburgh Learning Classifier System Embedded with Memetic Feature Selection},
  author    = {Yun Wen and Hua Xu},
  pages     = {2408--2415},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Learning classifier systems, Coevolutionary systems, Memetic, multi-meme and hybrid algorithms},
  abstract  = {
Given that real-world classification tasks always have irrelevant or noisy
features which degrade both prediction accuracy and computational efficiency,
feature selection is an effective data reduction technique showing promising
performance. This paper presents a cooperative coevolution framework to make
the feature selection process embedded into the classification model
construction within the genetic-based machine learning paradigm. The proposed
approach utilizes the divide-and-conquer strategy to manage two populations in
parallel, corresponding to the selected feature subsets and the rule sets of
classifier respectively, in which a memetic feature selection algorithm is
adopted to evolve the feature subset population while a Pittsburgh-style
learning classifier system is used to carry out the classifier evolution.
These two coevolving populations cooperate with each other regarding the
fitness evaluation and the final solution is obtained via collaborations
between the best individuals from each population. Empirical results on
several benchmark data sets chosen from the UCI repository, together with a
non-parametric statistical test, validate that the proposed approach is able
to deliver classifiers of better prediction accuracy and higher stability with
fewer selected features, compared with the original learning classifier
system. In addition, the incorporated feature selection process is shown to
help improve the computational efficiency as well.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Engineering  Applications II
@InProceedings{Dumas:2011:AEAFBDOBIWNI,
  title     = {An Evolutionary Approach For Blind Deconvolution Of Barcode Images With Nonuniform Illumination},
  author    = {Laurent Dumas and Mohammed El Rhabi and Gilles Rochefort},
  pages     = {2416--2421},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Numerical optimization., Genetic algorithms},
  abstract  = {
This paper deals with a joint  nonuniform illumination estimation and blind
deconvolution for barcode signals by using evolutionary algorithms. Indeed,
such optimization problems are highly non convex and a robust method is 
needed in case of noisy and/or blurred signals and nonuniform illumination.
Here, we present the construction of a genetic algorithm combining discrete
and continuous optimization which is successfully applied to decode real
images with very strong noise and blur.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Salmani-Jelodar:2011:MDfLPoGAuPGA,
  title     = {Model Development for Lattice Properties of Gallium Arsenide using Parallel Genetic Algorithm},
  author    = {Mehdi Salmani-Jelodar and Sebastian Steiger and Abhijeet Paul and Gerhard Klimeck},
  pages     = {2422--2428},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Real-world applications, Multiobjective optimization},
  abstract  = {
In the last few years, evolutionary computing (EC) approaches have been
successfully used for many real world optimization applications in scientific
and engineering areas. One of these areas is computational nanoscience.
Semi-empirical models with physics-based symmetries and properties can be
developed by using EC to reproduce theoretically the experimental data. One of
these semi-empirical models is the Valence Force Field (VFF) method for
lattice properties. An accurate understanding of lattice properties provides a
stepping stone for the investigation of thermal phenomena and has large impact
in thermoelectricity and nano-scale electronic device design. The VFF method
allows for the calculation of static properties like the elastic constants as
well as dynamic properties like the sound velocity and the phonon dispersion.
In this paper a parallel genetic algorithm (PGA) is employed to develop the
optimal VFF model parameters for gallium arsenide (GaAs). This methodology can
also be used for other semiconductors. The achieved results agree
qualitatively and quantitatively with the experimental data.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Raeesi-N.:2011:AMOLBMAfJSS,
  title     = {A Machine Operation Lists Based Memetic Algorithm for Job Shop Scheduling},
  author    = {Mohammad R. Raeesi N. and Ziad Kobti},
  pages     = {2429--2436},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Memetic, multi-meme and hybrid algorithms, Engineering applications},
  abstract  = {
In this article, a new Memetic Algorithm (MA) has been proposed to solve Job
Shop Scheduling Problems. The proposed MA is based on Machine Operation Lists
(MOL), which is the exact sequence of operations for each machine. Machine
Operation Lists representation is a modification of Preference List-Based
representation. Linear Order Crossover (LOX) and Random operations are first
considered as crossover and mutation operators for the proposed MA. Local
Search heuristic (LS) of the proposed MA reconsiders all the operations of a
job. It chooses a job and removes all of its operations and finally reassigns
them again one by one in their sequencing order to improve the fitness value
of the schedule. The proposed algorithm has been applied on the well-known
benchmark of classical Job Shop Scheduling Problems (JSSP). Comparing it with
the existing methods shows that the proposed MA and the proposed Genetic
Algorithm (GA) without LS are effective in JSSP. Moreover, comparing the
results of MA and GA shows that using LS not only improves the final results
but also helps GA to converge to the final solution.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Braun:2011:SaPIoNSwaES,
  title     = {Structure and Parameter Identification of Nonlinear Systems with an Evolution Strategy},
  author    = {Jan Braun and Johannes Krettek and Frank Hoffmann and Torsten Bertram},
  pages     = {2437--2444},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Engineering applications, Representation and operators},
  abstract  = {
Modeling and identification of dynamic systems often is a prerequisite for the
engineering of technical solutions, for example control system design. This
paper presents an multi-objective evolutionary approach for identification of
dynamic systems of variable structure. The evolutionary algorithm employs
domain specific operators in order to evolve the block oriented structure of
the model and simultaneously optimize its parameters. Based on the observed
inputs and outputs the multi-objective method identifies an entire set of
optimal compromise models which contrast model accuracy against complexity.
The models are constructed from a set of basic blocks that capture phenomenons
such as linear transfer functions, nonlinear gains and hysteresis that
typically occur in mechanical, hydraulic and electrical systems. This
representation enables the incorporation of domain knowledge in terms of
building blocks and the interpretation of the identified model for further
analysis and design. The feasibility of the proposed method is validated in
the identification of an artificial dynamic system as well as a hydraulic
proportional valve.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Plenary Poster Session: Poster Session Wednesday
@InProceedings{Wang:2011:EDEwEELSiMF,
  title     = {Enhancing Differential Evolution with Effective Evolutionary Local Search in Memetic Framework},
  author    = {Yu Wang and Li Bin and He Zhen and Zhang Kaibo},
  pages     = {2445--2452},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Memetic, multi-meme and hybrid algorithms, Numerical optimization.},
  abstract  = {
Memetic algorithms (MAs) are widely recognized to have better convergence
capability than their conventional counterparts. Due to its good robustness
and universality, differential evolution (DE) has been frequently used as the
global search method in MAs. However, on account of the limited performance of
the conventional local search operators, the performance of previous
DE-related MAs still needs further improvement. In this paper, we implement
more efficient evolutionary algorithms (EAs) as the local search techniques in
an adaptive MA framework to form two MA(DE-LS) variants, and investigate their
impacts. In order to comprehensively show the effectiveness and efficiency of
MA(DE-LS), we experimentally compare it with state-of-the-art EAs, DE-based
MAs and other MAs.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Sajjadi-Kia:2011:AnFaCARAfRN,
  title     = {A new Fault-tolerant and Congestion-aware Adaptive Routing Algorithm for Regular Networks-on-Chip},
  author    = {Hamed Sajjadi Kia and Ababei Cristinel},
  pages     = {2453--2460},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolvable hardware and software, Engineering applications},
  abstract  = {
In this paper, we propose a new fault-tolerant and congestion-aware adaptive
routing algorithm for Networks-on-Chip (NoCs). The proposed algorithm is based
on the ball-and-string model and employs a distributed approach based on
partitioning of the regular NoC architecture into regions controlled by local
monitoring units. Each local monitoring unit runs a shortest path computation
procedure to identify the best routing path so that highly congested routers
and faulty links are avoided while latency is improved. To dynamically react
to continuously changing traffic conditions, the shortest path computation
procedure is invoked periodically. Because this procedure is based on the
ball-and-string model, the hardware overhead and computational times are
minimal. Experimental results based on an actual Verilog implementation
demonstrate that the proposed adaptive routing algorithm improves
significantly the network throughput compared to traditional XY routing and
DyXY adaptive routing algorithms.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Xing:2011:PGRfSMAbGNPwRA,
  title     = {Pruning Generalized Rules for Stock Markets Accumulated by Genetic Network Programming with Rule Accumulation},
  author    = {Yafei Xing and Shingo Mabu and Kotaro Hirasawa},
  pages     = {2461--2467},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic programming, Finance and economics},
  abstract  = {
A new strategy on pruning rules accumulated by Genetic Network Programming
with Rule Accumulation (GNP-RA) has been proposed in this paper. The
generalized rules extracted by training GNP are pruned by GA in the validation
phase. Each rule has two variables: U and N. Variable U determines if the rule
is used or not, while variable N shows that the information on N days is used.
By mutating variables U and N of each rule, the portfolio of U and N is
changed, as a result, the rules are pruned. The performance of the pruned
rules is tested in the testing phase, meanwhile, the best mutation rates for
variable U and variable N are also studied. The simulation results show that
the pruned rules work better than the rules without pruning.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chuang:2011:ASoRGAfPOURSDCaDM,
  title     = {A Study on Real-Coded Genetic Algorithm for Process Optimization Using Ranking Selection, Direction-Based Crossover and Dynamic Mutation},
  author    = {Yao-Chen Chuang and Chyi-Tsong Chen},
  pages     = {2468--2475},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Evolution strategies, Numerical optimization.},
  abstract  = {
This paper develops a novel and efficient real-coded genetic algorithm (RCGA)
for process optimization. The proposed RCGA is equipped with Ranking Selection
(RS), Direction-Based Crossover (DBX) and Dynamic Random Mutation (DRM)
operators. The RS operator is used to eliminate the bad solutions and
reproduce good solutions, making the whole population to achieve a better
average fitness. The DBX operator uses relative fitness information to direct
the crossover toward a direction that significantly improves the objective
fitness. The DRM operator prevents the premature convergence of RCGA and at
the same time increases the precision of the searched solution. The
effectiveness and application of the proposed RCGA are demonstrated through a
variety of single- objective optimization benchmark problems. For comparative
study, other existing RCGAs with different evolution operators are also
performed to the same problem set. Extensive experiment results reveal that
the proposed RCGA provides a significantly faster convergence speed and much
better search performance than comparative methods.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Li:2011:ARCGAfSNBPwNOF,
  title     = {A  Real-Binary Coded Genetic Algorithm for Solving Nonlinear Bilevel Programming with Nonconvex Objective Functions},
  author    = {Hecheng Li and Yuping Wang},
  pages     = {2476--2480},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
This work deals with a class of nonlinear bilevel programming problems with
nonconvex objective functions, in which the follower objective is a function
of linear expression of all variables and the follower constraints are linear.
For the leader functions, there are no any restrictions on the convexity as
well as the differentiability. The distinguished feature of the problem is the
nonconvexity of the follower objective function, which breaks through the
barrier that the follower must be convex or concave in literature.  First, for
any fixed leader variable \$x\$, two linear programming are got from the
follower and used to obtain the follower optimal solution \$y\$. In addition,
in order to avoid solving directly the follower problem for each \$x\$, a
real-binary encoding scheme is given which consists of \$x\$ and the bases of
two linear programming. Finally, a new crossover operator is designed based on
the characteristics of the mixed encoding, and a novel genetic algorithm is
proposed. The numerical results on 15 examples illustrate that the proposed
algorithm is effective and stable.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Shindo:2011:PsofspPi,
  title     = {Particle swarm optimization for sigle phase PWM inverters},
  author    = {Takuya Shindo and Takuya Kurihara and Hiroyuki Taguchi and Kenya Jin'no},
  pages     = {2481--2485},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Multiobjective optimization, Real-world applications},
  abstract  = {
This article discusses a design procedure of DC-AC inverter. The DC-AC
inverter is to produce a sinusoidal ac voltage with adjustable amplitude and
frequency. Pulse-width modulation (abbr. PWM) is one of the most used
techniques in static inverters. For the PWM, the switching angle is most
important, and the switching angle controls the efficiency of DC-AC inversion.
For this reason, the design of the optimal switching angle vector is very
important. In this article. we obtain such switching angle vector by particle
swarm optimization system (abbr. PSO). Our simulation results indicate that
the proposed design procedure gives high efficiency inversion.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ki-Baek:2011:MPSOwPS,
  title     = {Multi-Objective Particle Swarm Optimization with Preference-based Sorting},
  author    = {Lee Ki-Baek and Kim Jong-Hwan},
  pages     = {2486--2493},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Particle swarm optimization, Multiobjective optimization},
  abstract  = {
Multi-objective particle swarm optimization (MOPSO) provides a set of
nondominated solutions and the number of nondominated solutions increases
exponentially when the number of objectives increases. To select a desired
solution out of them, preference-based solution selection algorithm (PSSA) was
proposed by incorporating user's preference into multi-objective evolutionary
algorithms. In this paper, multi-objective particle swarm optimization with
preference-based sorting (MOPSO-PS) is proposed, where a global best position
is randomly selected from the archive of nondominated solutions sorted by
global evaluation considering user's preferences for multiple objectives. The
user's preference is represented as a degree of consideration for the
objectives by the fuzzy measures. The global evaluation of the solutions is
carried out by the fuzzy integral of partial evaluation with respect to the
fuzzy measures, where the partial evaluation of each solution is obtained as a
normalized objective function value. To demonstrate the effectiveness of the
proposed MOPSO-PS, empirical comparisons to NSGA-II, MQEA, and MOPSO are
carried out for the DTLZ functions. Experimental results show that the user's
preference is properly reflected in the selected solutions without any loss of
overall quality and diversity.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Zhong:2011:EDoCSGoSNuWSAPS,
  title     = {Evolutionary Dynamics of Continuous Strategy Games on Social Networks under Weak Selection: A Preliminary Study},
  author    = {Weicai Zhong and Yang Zhang and Jing Liu},
  pages     = {2494--2498},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Cooperation is a fundamental principle of all biological systems. Most
previous studies presumed that the interactions between individuals are
discrete, namely, each individual offers either cooperation or defection. This
discrete strategy seems unrealistic in real systems and cooperative behavior
in nature should be viewed as a continuous trait. Existing research work on
games with a continuous strategy mainly focuses on infinite well-mixed
populations. Additionally, our previous work showed that there is a
considerable difference in terms of equilibria between continuous and discrete
strategy games on graphs under strong selection. This paper studies the game
dynamics in finite structured populations under weak selection using the
stochastic dynamics based on respectively the mutant fixation probability
(\${$\backslash$}rho\_\{Y\}\$) and the fixation probability ratio of mutant to
resident (\${$\backslash$}rho\_\{Y\}/{$\backslash$}rho\_\{X\}\$). For three
update rules, called `birth-death' (BD), `death-birth' (DB) and `imitation'
(IM), we derive exact conditions for natural selection favoring one strategy
over another. Comparing discrete strategy games, we find that for continuous
ones (i) the rule, \$b/c$>$k\$, is also valid; (ii) the same selection
conditions are also derived using
\${$\backslash$}rho\_\{Y\}/{$\backslash$}rho\_\{X\}\$; however, (iii) the
selection conditions obtained using \${$\backslash$}rho\_\{Y\}\$ and
\${$\backslash$}rho\_\{Y\}/{$\backslash$}rho\_\{X\}\$ are the same instead of
different; and (iv) interestingly, the `1/3' rule is not observed for DB and
IM updating.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Srinivasan:2011:CBSfBiEPM,
  title     = {Co-evolutionary Bidding Strategies for Buyers in Electricity Power Markets},
  author    = {Dipti Srinivasan and Trong Trung Ly},
  pages     = {2499--2506},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Engineering applications, Coevolutionary systems},
  abstract  = {
The deregulation of the electrical power industries has opened many
opportunities to power buyers, once price takers of a monopolistic economy, to
look forward to a free market economy with market forces determining the
market clearing prices and quantities. However, the strong influence of
technical and physical constraints of the network may result in economic
decisions that adversely affect the interests of the consumers. Compared to
the monopolistic economy of yesteryears, power buyers may actually be able to
influence the market by cooperating with other power buyers in the network. 
This paper presents a co-evolutionary algorithm for evolving individual and
cooperative strategies of electricity buyers in a power market. The algorithm
focuses on how the buyers choose their bidding strategies through learning to
maximize the profits in different scenarios of playing individually or
cooperatively. The results show that it is of great benefit to cooperate but
the free rider problem may arise when an individual buyer gains more profit
due to the cooperative effort of the others.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Sharma:2011:MAfPBUC,
  title     = {Multi-Agent Approach for Profit Based Unit Commitment},
  author    = {Deepak Sharma and Dipti Srinivasan and Anupam Trivedi},
  pages     = {2507--2513},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary games and multi-agent systems, Intelligent systems applications, Engineering applications},
  abstract  = {
Deregulation in the electricity market offers freedom to the generator
companies (GENCOs) to schedule their generators in order to maximize their
profit without actually satisfying the load and the reserve requirements.
Various techniques have been developed for solving the profit based unit
commitment (PBUC) problem. Among them, the multi-agent approach is different
where each generator unit is referred to as an intelligent agent. In this
paper, we develop a new multi-agent approach for PBUC problem in which the
rule based intelligence is provided to the independent system operator (ISO)
agent. Intelligence of generator agents (GenAgents) is limited to maximize
their profit for the given demand and reserve using real-parametric genetic
algorithm (GA) and share the results with ISO agent. In this approach, ISO
agent commits the maximum profit generating GenAgents for every hour while
satisfying the up/down time constraints. ISO agent also asks other GenAgents
to calculate their profit for the remaining demand and reserve. The simulation
results of 10 units problem for two payment methods are shown and compared
with other techniques.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Namura:2011:KRRSMfHNF,
  title     = {Kriging/RBF-Hybrid Response Surface Method  for Highly Nonlinear Functions},
  author    = {Nobuo Namura and Koji Shimoyama and Shinkyu Jeong and Shigeru Obayashi},
  pages     = {2514--2521},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Meta-modeling and surrogate models, Numerical optimization., Genetic algorithms},
  abstract  = {
In order to construct a response surface of an unknown function robustly, a
hybrid method between the Kriging model and the radial basis function (RBF)
networks is proposed in this paper. In the hybrid method, RBF approximates the
macro trend of the function and the Kriging model estimates the micro trend.
Then, hybrid methods using two types of model selection criteria (MSC):
leave-one-out cross-validation and generalized cross-validation for RBF and
the ordinary Kriging (OK) model for comparison are applied to three types of
one-dimensional test problems, in which the accuracy of each response surface
is compared by shapes and root mean square errors. As a result, the hybrid
models are more accurate than the OK model for highly nonlinear functions
because the hybrid models can capture the macro trend of the function properly
by RBF, but the OK model cannot. However, because the accuracy of the hybrid
method turns down significantly when RBF causes overfitting, stable MSC is
required. In addition, the hybrid models can find out the global optimum with
a few sample points by using the Kriging model's approximation errors
effectively.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ji:2011:Sopwiahiuea,
  title     = {Solving optimization problems with intervals and hybrid indices using evolutionary algorithms},
  author    = {Xin-fang Ji and Dun-wei Gong and Xiao-ping Ma},
  pages     = {2522--2529},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Multiobjective optimization, Constraint and uncertainty handling},
  abstract  = {
Optimization problems with intervals and hybrid indices are common in real-
world applications. Previous theories and methods suitable for them, however,
are few. We present a large population evolutionary algorithm with a user's
interval preferences to effectively solve the problems above in this study. In
this algorithm, a large population is adopted to improve the performance of
the algorithm in exploration. A similarity-based strategy is employed to
estimate the implicit indices of the individuals that the user has not
evaluated to alleviate the user's fatigue. When Pareto domination is utilized
to compare different individuals, the user's preferences to the individuals
with the same rank are calculated to further distinguish their performance. In
addition, the user's preferences to different indices, expressed with
intervals, are quantified by solving another optimization problem. We apply
the proposed algorithm to the interior layout problem, a typical optimization
one with both interval parameters in the explicit index and interval value of
the implicit index, and compare it with other three optimization algorithms.
The experimental results validate its superiority.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Masuda:2011:AESotSDoDE,
  title     = {An Empirical Study on the Search Directions of Differential Evolution},
  author    = {Kazuaki Masuda and Hirofumi Yokota and Kenzo Kurihara},
  pages     = {2530--2537},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Differential evolution, Heuristics, metaheuristics and hyper-heuristics, Convergence, scalability and complexity analysis},
  abstract  = {
Among various evolutionary computation methods, differential evolution (DE) is
recognized as one of the most promising methods for solving continuous global
optimization problems. Although DE has been used by many researchers, the
reasons how and why it can generally solve such problems so well are not fully
explained. To find the reasons, we study the common behavior of individuals in
DE through various numerical experiments. Regarding DE as a multi-point
directional search model, we investigate convergence and practicality of the
search directions used by its individuals. Specifically, we focus on the
characteristics of two difference vectors for each individual: (a) a vector
from the target vector, i.e., the individual itself, to the corresponding
mutant vector, and (b) another vector from it to the corresponding trial
vector. The experimental results, in which famous benchmark problems are
solved by DE/rand/1/bin, exhibit the phenomenon that both of the vectors (a)
and (b) automatically decrease their length exponentially, and show the
possibility that the mutant vectors improve the corresponding individuals more
frequently than the trial vectors.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Kudo:2011:ASoAoDViPSfCDOPoHRE,
  title     = {A Study on Analysis of Design Variables in Pareto Solutions for Conceptual Design Optimization Problem of Hybrid Rocket Engine},
  author    = {Fumiya Kudo and Yoshikawa Tomohiro and Furuhashi Takeshi},
  pages     = {2538--2542},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Genetic algorithms, Engineering applications},
  abstract  = {
Genetic Algorithm (GA) is one of the most effective methods in the application
to optimization problems. Recently, Multi-objective Genetic Algorithm (MOGA)
is focused on in the engineering design field. In this field, the analysis of
design variables in the acquired Pareto solutions, which gives the designers
useful knowledge in the applied problem, is important as well as the
acquisition of advanced solutions. This paper proposes a new visualization
method using Isomap which visualizes the geometric distances of solutions in
the design variable space considering their distances in the objective space.
The proposed method enables a user to analyze the design variables of the
acquired solutions considering their relationship in the objective space. This
paper applies the proposed method to the conceptual design optimization
problem of hybrid rocket engine and studies the effectiveness of the proposed
method. It shows that the visualized result gives some knowledges on the
features between design variables and fitness values in the acquired Pareto
solutions.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Zhan:2011:OLPSOfPECOwFSR,
  title     = {Orthogonal Learning Particle Swarm Optimization for Power Electronic Circuit Optimization with Free Search Range},
  author    = {Zhihui Zhan and Jun Zhang},
  pages     = {2543--2550},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization},
  abstract  = {
Power electronic circuit (PEC) always consists of a number of components such
as resistors, capacitors, and inductors which have to be optimized in order to
obtain good circuit performance. In current studies, the search ranges of
these components are always pre-defined carefully by expert designers, making
it difficult for practical applications. In this paper, the search space is
freely set to the commonly used ranges and an efficient orthogonal learning
particle swarm optimization (OLPSO) is applied to optimally design the PEC
with such search space. OLPSO uses an orthogonal learning (OL) strategy for
PSO to discover useful information that lies in the personal historical best
experience and the neighborhood's best experience via orthogonal experimental
design. Therefore, OLPSO can construct a more promising and efficient exemplar
to guide particle to fly better towards the global optimal region. OLPSO is
implemented to optimize the design of a buck regulator in PEC. The optimized
results are compared with those obtained by using a genetic algorithm (GA)
approach and those obtained by using PSO with traditional learning strategy.
Results show that the OLPSO algorithm is more promising in the design and
optimization of the PEC with large search space. Moreover, the simulations
results demonstrate the advantages of OLPSO by showing that the circuit
optimized by OLPSO exhibits better startup and large-signal disturbance
performance when compared with the one optimized by GA.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Fernandez-de-Vega:2011:MGCbmoFRBSApa,
  title     = {Musical Genre Classification by means of Fuzzy Rules Based Systems: A preliminary approach},
  author    = {Francisco {Fernandez de Vega} and Francisco {Chavez de la O} and Rafael Alcala Fernandez and Francisco Herrera Triguero},
  pages     = {2551--2557},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Evolutionary fuzzy systems, Art and music},
  abstract  = {
Musical Genre is part of the basic information required for classifying
musical audio, and fundamental for music information retrieval systems. The
problem of automatic musical genre detection has attracted large attention in
the last decade, due to the emergence of digital music databases and Internet.
Although a number of techniques has been applied to the problem, no general
solution still exists, due to the imprecise features that properly define
musical genre. This paper presents a preliminary attempt to apply Fuzzy Rules
Based System (FRBS) in cooperation with Evolutionary Algorithms to musical
genre classification. The novelty of the approach -which allows us to use
fuzzy information extracted from audio files- is aligned with the fuzzy nature
of the problem at hand, where no clear-cut rules are available for the
classification. Preliminary results presented allows to foresee the potential
of the technique.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Kameya:2011:PPoBBiGA,
  title     = {Pattern-based Preservation of Building Blocks in Genetic Algorithms},
  author    = {Yoshitaka Kameya and Chativit Prayoonsri},
  pages     = {2558--2565},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms},
  abstract  = {
As stated in the building block hypothesis, we expect genetic algorithms (GAs)
to create building blocks (BBs) and combine them appropriately in the
evolutionary process.  However, such BBs are often destroyed by unwanted
crossovers, soon after they are created. Also, we may suffer from a "loose"
encoding of chromosomes since BBs are in general unknown.  In this paper, we
propose a framework named GAP (GA with patterns), in which key patterns are
extracted from significantly "good" chromosomes and protect such key patterns
against unwanted crossover. GAP is applicable to optimization problems with
fixed-point encoding and permutation encoding in a uniform fashion, and unlike
perturbation-based linkage learning methods, GAP does not require extra
fitness evaluations.  Experimental results with the royal road problems and
traveling salesman problems show the performance improvement of GAP over
standard GAs.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Ahmadi-Javid:2011:ASOAHM,
  title     = {Anarchic Society Optimization: A Human-Inspired Method},
  author    = {Amir Ahmadi-Javid},
  pages     = {2566--2572},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Heuristics, metaheuristics and hyper-heuristics, Particle swarm optimization},
  abstract  = {
This paper introduces Anarchic Society Optimization (ASO), which is inspired
by a social grouping in which members behave anarchically to improve their
situations. The basis of ASO is a group of individuals who are fickle,
adventurous, dislike stability, and frequently behave irrationally, moving
toward inferior positions they have visited during the exploration phase. The
level of anarchic behavior among members intensifies as the level of
difference among members' situations increases. Using these anarchic members,
ASO explores the solution space perfectly and avoids falling into local
optimum traps. First we present a unified framework for ASO, which can easily
be used for both continuous and discrete problems. Then, we show that Particle
Swarm Optimization (PSO), for which a general introduction was initially
implemented for continuous optimization problems, is a special case of this
framework. To evaluate the performance of ASO for discrete optimization, we
develop an ASO algorithm for a challenging scheduling problem. The numerical
results show that the proposed ASO algorithm significantly outperforms other
effective algorithms in the literature. Our study indicates that developing an
ASO algorithm is basically straightforward for any problem to which a PSO or
Genetic algorithm has been applied. Finally, it is shown that under mild
conditions an ASO algorithm converges to a global optimum with probability
one.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Seridi:2011:MEAfBiMD,
  title     = {Multi-objective Evolutionary Algorithm for Biclustering in Microarrays Data},
  author    = {Khedidja Seridi and Laetitia Jourdan and El-Ghazali Talbi},
  pages     = {2573--2579},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications},
  abstract  = {
Microarrays is a powerful tool in studying genes expressions under several
conditions. The obtained data need to be analyzed using data mining methods.
Biclustering is a data mining method which consists in simultaneous clustering
of rows and columns in a data matrix. Using biclustering, we can extract genes
that have similar behavior (co-express) under specific conditions. These genes
may share identical biological functions. The aim in analyzing gene expression
data is the extraction of maximal number of genes and conditions that present
similar behavior. The two objectives to be optimized (size and similarity) are
conflicting. Therefore, multi objective optimization is suitable for
biclustering. In our work, we combined a well-known multi objective genetic
algorithm (NSGA-II) with a heuristic to solve the biclutering problem. We used
a string of integers as a solution representation, the integers represent the
indexes of the rows and the columns. Experimental results on real data set
show that our approach can find significant biclusters of high quality.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Chen:2011:QIQCiSAfOP,
  title     = {QISA: Incorporating Quantum Computation into Simulated Annealing for Optimization Problems},
  author    = {Zhanghui Chen and Ping Luo},
  pages     = {2580--2587},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Molecular and quantum computing, Optimization:, Heuristics, metaheuristics and hyper-heuristics},
  abstract  = {
This paper proposes a novel model of QISA (Quantum-Inspired Simulated
Annealing) which embeds quantum computation into the Simulated Annealing (SA)
process for optimization problems. Compared with previous SA studies, QISA
adopts Quantum Bits (Qubits) rather than the conventional binary bits as the
coding scheme, and update the entries in the Qubits sequence with different
probabilities by the proposed methods of heat observation and quantum rotation
gate. By flexibly controlling the heating function and rotation angle, QISA
does not have to either accept or reject, but can partially accept a new
solution. The careful experiments on a number of numerical optimization and
combinatorial optimization problems validate its better convergent performance
and lower sensitivity to parameters.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lima:2011:FPAtNNWaA,
  title     = {Frankenstein PSO Applied to Neural Network Weights and Architectures},
  author    = {Natalia Lima and Teresa Ludermir},
  pages     = {2588--2592},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Evolved neural networks, Classification, clustering, data analysis and data mining},
  abstract  = {
In this paper we present the FPSO-FPSO, a variation of the particle swarm
optimization algorithm (PSO), called Frankstein PSO or just FPSO, which is
used to adjust the weights and architectures of a feed-forward neural network.
To evaluate the algorithm we used benchmark classification problems in medical
care area. The results were compared with other algorithms which use the same
methodology to find out the weights and architectures.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Complex Networks and Evolutionary Computation II
@InProceedings{Celebi:2011:MPsDGPODH,
  title     = {Mobile Prisoner's Dilemma Game Played On Diverse Habitats},
  author    = {Remzi Celebi and Hurevren Kilic},
  pages     = {2593--2597},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Promotion of cooperative behavior in Prisoner's Dilemma (PD) game while
players that are allowed to move between different gaming environments (i.e.
habitats) is investigated. The stochastic mobile model under study is realized
over connected habitats that are situated on two dimensional grid environment.
The players appearing in the same habitat are allowed to interact with their
immediate neighbors. Mobility of a player is defined as movement from its
habitat to another based on both obtained payoff and randomly assigned habitat
diversity values. By the end extensive experimentation, it is concluded that
player mobility is an effective factor that contributes to promotion of
cooperation in spatial evolutionary games. Also, even for higher values of
temptation of PD game, habitat diversity supports and triggers a collective
resistance for the emergence and promotion of cooperative system behavior.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Li:2011:TMiFENN,
  title     = {The Modularity in Freeform Evolving Neural Networks},
  author    = {Shuguang Li and Jianping Yuan},
  pages     = {2598--2603},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
In this paper, we validate whether the network modularity can emerge, and the
evolution performance can be improved by varying the environment or evolution
process under a more freeform artificial evolution. Previous studies have
demonstrated that the modular structure naturally arisen as a response of the
variations on environment and selection process, however, since the models
they used were relatively simple and with some biasing constraints, the
results may lack of generality. In contrast, we evolve more freeform neural
networks to address this issue, and an artificial tracer method was employed
to quantify the modularity. A series of varying scenarios have been
experimented, the results show that the evolution performance have been
improved in most cases, however, the modularity never appeared among those
scenarios. A further experiment shows that our method has the potentials to
produce modular networks but the more advanced methods are still needed to
encourage the emergence of modularity on the complex questions.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Kim:2011:MIEoHfBDA,
  title     = {Mutual Information-Based Evolution of Hypernetworks for Brain Data Analysis},
  author    = {Eun-Sol Kim and Jung-Woo Ha and Wi Hoon Jung and Joon Hwan Jang and Jun Soo Kwon and Zhang Byoung-Tak},
  pages     = {2604--2610},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications, Classification, clustering, data analysis and data mining, Real-world applications},
  abstract  = {
Cortical analysis becomes increasingly important for brain research and
clinical diagnosis. This problem involves a combinatorial search to find the
essential modules among a large number of brain regions. Despite statistical
approaches, cortical analysis remains a formidable challenge due to high-
dimensionality and data sparsity. Here we describe an evolutionary method for
finding significant modules from cortical data. The method uses a hypernetwork
which is encoded as a population of hyperedges, where hyperedges represent
building blocks or potential modules. We develop an efficient method for
evolving the hypernetwork using mutual information to generate essential
hyperedges. We evaluate the method on predicting IQ levels and finding
potential significant modules on IQ from brain MRI data consisting of 62
healthy adults with over 80,000 measured points. The experimental results
shows that our information-theoretic evolutionary hypernetworks improve the
classification accuracy by about 10 percents. Moreover, it extracts
significant cortical modules that distinguish high IQ from low IQ groups.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Special Track: Differential Evolution III
@InProceedings{Elsayed:2011:ISDEAwaLSfCO,
  title     = {Integrated Strategies Differential Evolution Algorithm with a Local Search for Constrained Optimization},
  author    = {Saber Elsayed and Ruhul Sarker and Daryl Essam},
  pages     = {2611--2618},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
Due to the variability of the characteristics of different Constrained
Optimization Problems, no single Differential Evolution strategy, with no
single constraint handling technique, performs consistently over a range of
problems. In this paper, for a better coverage of the problem characteristics,
we introduce a DE algorithm that uses multiple search operators and constraint
handling techniques. In the proposed algorithm, initially each individual is
assigned a random combination of operators. After a certain number of
generations, the improvement made by each combination is recorded, and the
best combination is then assigned to more and more individuals, while each of
the other individuals are assigned a random combination. To accelerate the
convergence of the proposed algorithm, a local search procedure is also
applied to selected individuals. The algorithm has been tested by solving 18
test problems, with 10D and 30D. The results showed that the proposed
algorithm is superior to state of the art algorithms
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Wang:2011:ADEwVPSfSHP,
  title     = {Adaptive Differential Evolution with Variable Population Size for Solving High-Dimensional Problems},
  author    = {Hui Wang and Shahryar Rahnamayan and Zhijian Wu},
  pages     = {2619--2625},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
In this paper, we present a novel Differential Evolution (DE) algorithm to
solve high-dimensional global optimization problems effectively. The proposed
approach, called DEVP, employs a variable population size mechanism, which
adjusts population size adaptively. Experiments are conducted to verify the
performance of DEVP on 19 high-dimensional global optimization problems with
dimensions 50, 100, 200, 500 and 1000. The simulation results show that DEVP
outperforms classical DE, CHC (Crossgenerational elitist selection,
Heterogeneous recombination, and Cataclysmic mutation), G-CMA-ES (Restart
Covariant Matrix Evolutionary Strategy) and GODE (Generalized Opposition-Based
DE) on the majority of test problems.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Noman:2011:SDEDPuCDE,
  title     = {Solving Dynamic Economic Dispatch Problems using Cellular Differential Evolution},
  author    = {Nasimul Noman and Hitoshi Iba},
  pages     = {2626--2633},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Dynamic and uncertain environments., Real-world applications},
  abstract  = {
This paper proposes cellular differential evolution (cDE) algorithm for
solving dynamic economic dispatch (DED) problems with valve-point effects.
DEDs are high dimensional optimization problems with many equality and
inequality constraints. The problem of premature convergence in solving high
dimensional optimization problems using evolutionary algorithms (EAs) could be
fought using population structuring. This work investigates the suitability  a
structured DE algorithm, called cDE, in solving these large dimensional
optimization tasks. The suitability and effectiveness of the proposed
algorithm is validated using two test systems consisting of 10 and 13 thermal
units respectively. Numerical results clearly show that the proposed method
outperforms existing methods in terms of solution quality and robustness.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Esmailzadeh:2011:EDEUCS,
  title     = {Enhanced Differential Evolution Using Center-Based Sampling},
  author    = {Ali Esmailzadeh and Shahryar Rahnamayan},
  pages     = {2634--2641},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
The classical Differential Evolution (DE) has showed to perform efficiently in
solving both benchmark functions and real-world problems. However, DE, similar
to other evolutionary algorithms deteriorate in performance during solving
high-dimensional problems. Opposition-based Differential Evolution (ODE) was
introduced and, in general, has shown better performance comparing to
classical DE for solving largescale problems. In this paper, we propose an
enhancement to ODE in order to improve its ability to solve large-scale
problems more effectively. The proposed modified version of ODE is called
Center-Based Differential Evolution (CDE) which utilizes the exact algorithm
of ODE except replacing of opposite points with center-based individuals. This
paper compares DE and ODE with the proposed algorithm, CDE. Furthermore, CDE
with dynamic range (CDE\_d) will be compared to CDE with fixed range (CDE\_f
). Experimental verifications are conducted on seven well-known shifted
large-scale benchmark functions for dimensions of 100 and 500, including
detailed parameter analysis for CDE. The shifted version of the functions
ensures there is no bias towards the center of search space, in favor of CDE
algorithm. The results clearly show that the CDE outperforms DE and ODE during
solving large-scale problems, and also clarifies the superiority of CDE\_d to
CDE\_f .
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Evolutionary Games and Multi-agent Systems II
@InProceedings{Nagy:2011:FEfGIn2P,
  title     = {Fuzzy Equilibria for Games Involving n$>$2 Players},
  author    = {Reka Nagy and Dumitru Dumitrescu and Rodica Ioana Lung},
  pages     = {2642--2648},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Games, Multi-objective evolutionary algorithms},
  abstract  = {
Generative relations represent a powerful algebraic tool for characterizing
and detecting game equilibria. Generative relations are particularly useful
for defining new classes of equilibria, for example joint equilibria.

In order to avoid difficulties for games involving many players (n$>$2) a new
generative relation for fuzzy Nash-Pareto equilibrium is introduced. An
evolutionary procedure relying on this generative relation is used for
detecting several types of fuzzy equilibria. Experimental results indicate the
effectiveness and robustness of the proposed approach.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Sanchez:2011:GEEStaCE,
  title     = {Group Evolution: Emerging Synergy through a Coordinated Effort},
  author    = {Ernesto Sanchez and Giovanni Squillero and Alberto Tonda},
  pages     = {2649--2655},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Coevolution and collective behavior, Coevolutionary systems, Evolutionary games and multi-agent systems},
  abstract  = {
A huge number of optimization problems, in the CAD area as well as in many
other fields, require a solution composed by a set of structurally homogeneous
elements. Each element tackles a subset of the original task, and they
cumulatively solve the whole problem. Sub-tasks, however, have exactly the
same structure, and the splitting is completely arbitrary. Even the number of
sub-tasks is not known and cannot be determined a-priori. Individual elements
are structurally homogeneous, and their contribution to the main solution can
be evaluated separately. We propose an evolutionary algorithm able to optimize
groups of individuals for solving this class of problems. An individual of the
best solution may be sub-optimal when considered alone, but the set of
individuals cumulatively represent the optimal group able to completely solve
the whole problem. Results of preliminary experiments show that our algorithm
performs better than other techniques commonly applied in the CAD field.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Merelo:2011:OwsiesttMp,
  title     = {Optimizing worst-case scenario in evolutionary solutions to the MasterMind puzzle},
  author    = {Juan Julian Merelo and Antonio M. Mora and Carlos Cotta},
  pages     = {2656--2663},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Games, Representation and operators},
  abstract  = {
The MasterMind puzzle is an interesting problem to be approached via
 evolutionary algorithms, since it is at the same time a constrained and a
 dynamic problem, and has eventually a single solution. In previous
 papers we have presented and evaluated different evolutionary algorithms to
this game
 and shown how their behavior scales with size, looking mainly at the
 game-playing performance. In this paper we fine-tune the parameters of the
 evolutionary algorithms so that the worst-case number of evaluations,
 and thus the average and median, are improved, resulting in a better
 solution in a more reliably predictable time.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Knittel:2011:FaAoFHUR,
  title     = {Formation and Activation of Feature Hierarchies Under Reinforcement},
  author    = {Anthony Knittel and Terry Bossomaier},
  pages     = {2664--2671},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Autonomous mental development, Learning classifier systems, Evolutionary games and multi-agent systems},
  abstract  = {
Representation of knowledge through a hierarchy of re-used elements, and the
discovery of intermediate terms for learning, is an area of increasing
interest in artificial learning.  Such a hierarchy is a recognised aspect of
human visual processing and has an important role in recognition of objects. 
A hierarchy allows efficiency of representation, and a manner of preserving
links between related concepts.  The use of such an approach in an artificial
system requires addressing processes for discovery of features, and for
activation of features according to an observation.  Learning Classifier
Systems provide a means of developing a population of rules relevant to a task
according to reinforcement, capturing features of the problem in a population
of rules.  Implementation of a hierarchical representation to define rules is
examined using the Activation-Reinforcement Classifier System, acting in a
game environment.  Two methods of activation of fragments are examined, one
using a parallel activation method allowing multiple interpretations to be
active in tandem, the other based on attention to a single higher level
concept at once, using a limited working memory.  Attention to a high level
rule provides a bias on the low level features to be activated.  Trials show
the system operates successfully on  the game of Dots and Boxes with a large
game size, and is able to extract relevant features of the game using a body
of 4000 autonomously produced features.  The attention-based activation method
operates with a reduced memory requirement and faster processing time than the
parallel method.  The network of features produced shows a scale-free
connectivity distribution, a common property of many human semantic networks.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Artificial Ecology and Artificial Life
@InProceedings{Ashlock:2011:TTAGCiaEA,
  title     = {Translation Tables: A Genetic Code in an Evolutionary Algorithm},
  author    = {Daniel Ashlock and Justin Schonfeld and Paul McNicholas},
  pages     = {2672--2679},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Artificial ecology and artificial life, Coevolution and collective behavior, Representation and operators},
  abstract  = {
The genetic code that maps triples of DNA onto amino acids, is a central part
of the biochemistry of life.  In this study we incorporate an analogous code,
called a translation table, into the self-avoiding walk test problem.  Use of
a translation table permits evolution of both the distribution of commands and
the behavior of the mutation operator. It thus can evolve to encode two types
of domain knowledge about the test problem. The translation tables are shown
to specialize to specific cases of the test problem but yield no significant
improvement in performance.  The emergence of encoded problem-specific
knowledge in the translation tables is demonstrated. A translation table
constructed from extrapolation of the evolutionary trend yields a performance
improvement, suggesting that the current algorithm would require more time to
locate translation tables that would enhance performance.  A tentative
technique for overcoming this limitation is outlined.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lehman:2011:IEtNSaS,
  title     = {Improving Evolvability through Novelty Search and Self-Adaptation},
  author    = {Joel Lehman and Kenneth Stanley},
  pages     = {2680--2687},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Artificial ecology and artificial life, Evolved neural networks},
  abstract  = {
A challenge for current evolutionary algorithms is to yield highly evolvable
representations like those in nature. Such evolvability in natural evolution
is encouraged through selection: Lineages better at molding to new niches are
less susceptible to extinction. Similar selection pressure is not generally
present in evolutionary algorithms; however, the first hypothesis in this
paper is that novelty search, a recent evolutionary technique, also selects
for evolvability because it rewards lineages able to continually radiate new
behaviors. Results in experiments in a maze-navigation domain in this paper
support that novelty search finds more evolvable representations than regular
fitness-based search. However, though novelty search outperforms fitness-based
search in a second biped locomotion experiment, it proves no more
evolvablethan fitness-based search because delicately balanced behaviors are
more fragile in that domain. The second hypothesis is that such fragility can
be mitigated through self- adaption, whereby genomes influence their own
reproduction. Further experiments in fragile domains with novelty search and
self-adaption indeed demonstrate increased evolvability,while, interestingly,
adding self-adaptation to fitness- based search decreases evolvability. Thus,
selecting for novelty may often facilitate evolvability when representations
are not overly fragile; furthermore, achieving the potential of
self-adaptation may often critically depend upon the reward scheme driving
evolution.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{de-Bruyn:2011:EAaPSOfALE,
  title     = {Evolutionary Algorithms and Particle Swarm Optimization for Artificial Language Evolution},
  author    = {Kobus {de Bruyn} and Geoff Nitschke and Willem {van Heerden}},
  pages     = {2688--2695},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Artificial ecology and artificial life, Particle swarm optimization, Genetic algorithms},
  abstract  = {
This paper reports upon two adaptive approaches for deriving words in an
artificial language simulation. The efficacy of a Particle Swarm Optimization
(PSO) method versus an Artificial Evolution (AE) method was examined for the
purpose of adapting communication between agents. The objective of the study
was for agents to derive a common (shared) lexicon for talking about food
resources in the simulation environment. In the simulation, communication was
essential for agent survival and as such facilitated lexicon adaptation.
Results indicated that PSO was effective at adapting agents to quickly
converge to a common lexicon, where, on average, one word for each food type
was derived. AE required more method iterations to converge to a common
lexicon that contained, on average, multiple words for each food type.
However, there was greater word diversity in the lexicon converged upon by AE
evolved agents, compared to that converged upon by PSO adapted agents.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Biometrics, Bioinformatics and Biomedical Applications II
@InProceedings{Dorn:2011:AHGAft3PSPPuaPS,
  title     = {A Hybrid Genetic Algorithm for the 3-D Protein Structure Prediction Problem using a Path-Relinking Strategy},
  author    = {Marcio Dorn and Luciana S. Buriol and Luis C. Lamb},
  pages     = {2696--2703},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications, Genetic algorithms, Heuristics, metaheuristics and hyper-heuristics},
  abstract  = {
One of the main research problems in Structural Bioinformatics is related to
the prediction of three-dimensional structures (3-D) of polypeptides or
proteins. The rate at which amino acid sequences are identified is increasing
faster than the 3-D protein structure determination by experimental methods.
Computational prediction methods have been developed during the last years,
but the problem still remains challenging because of the complexity and high
dimensionality of a protein conformational search space. In this article we
present a hybrid genetic algorithm for the Protein Structure Prediction (PSP)
Problem. A genetic algorithm is combined with a structured population, and it
is hybridized with a path-relinking procedure that helps the algorithm to
scape from local minima. We perform a set of experiments and show that the
proposed hybrid genetic algorithm is effective in finding good quality
solutions for the PSP Problem.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Oh:2011:SCE,
  title     = {Simulating Chemical Evolution},
  author    = {In Soo Oh and Yun-Geun Lee and Robert Ian McKay},
  pages     = {2704--2711},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications},
  abstract  = {
Chemical methods such as directed evolution and some forms of the SELEX
procedure implement evolutionary algorithms directly in vitro. They have a wide
range of applications in detecting and targeting diseases and potential
applications in other areas as well [1].
 However it is relatively difficult and expensive to carry out these processes
(by comparison with evolutionary computation), so that the underlying theory
has seen limited development. For more complex problems, where multiple and
dynamic objectives are involved, there is potential for substantial improvement
in the search protocols. Simulation through the methods of evolutionary
computation is one potential way to gain the necessary insights.
 The complex fitness functions and huge populations involved in combinatorial
chemistry render detailed simulation infeasible. However detailed simulation is
not needed, so long as simulations are sufficiently similar to yield
qualitative insights. In this paper, we investigate whether one class of
problems - those involving short-chain evolution, where stereochemical effects
do not dominate - are likely to have sufficiently similar fitness landscapes to
a simple problem, string matching, for useful inferences to be made. In the
outcome, it appears that the differences between more detailed simulations and
string matching are not sufficient to significantly alter the behaviour of
evolutionary algorithms, so that string matching could be used as a realistic
surrogate. This is valuable, because string matching can be implemented in
GPUs, offering speed-ups to the level where populations of 10\^{}7, or even 10\^{}8,
might be feasible, thus reducing the population gap between chemical and
computer evolution.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Alford:2011:ACoGFSaWfMBR,
  title     = {A Comparison of GEC-Based Feature Selection and Weighting for Multimodal Biometric Recognition},
  author    = {Aniesha Alford and Khary Popplewell and Gerry Dozier and Kelvin Bryant and John Kelly and Joshua Adams and Tamirat Abegaz and Joseph Shelton and Karl Ricanek and Damon Woodard},
  pages     = {2712--2715},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Biometrics, bioinformatics and biomedical applications, Genetic algorithms},
  abstract  = {
In this paper, we compare the performance of a Steady-State Genetic Algorithm
(SSGA) and an Estimation of Distribution Algorithm (EDA) for multi-biometric
feature selection and weighting.    Our results show that when fusing face and
periocular modalities, SSGA-based feature weighting produces higher average
recognition accuracies, while EDA-based feature selection performs better at
reducing the number of features needed for recognition.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Emerging Areas
@InProceedings{Kumar:2011:NAtOtEoQPoGO,
  title     = {Nearest-Neighbor Architecture to Overcome the Effects of Qubit Precessions on Gate Operations},
  author    = {Preethika Kumar and Steven Skinner and Daraeizadeh Sahar},
  pages     = {2716--2721},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Emerging areas, Molecular and quantum computing},
  abstract  = {
We design a nearest-neighbor architectural layout that uses fixed positive and
negative couplings between qubits, to overcome the effects of relative phases
due to qubit precessions, both during idle times and gate operations. The
scheme uses decoherence-free subspaces, and we show how to realize gate
operations on these encoded qubits. The main advantage of our scheme is that
most gate operations are realized by only varying a single control parameter,
which greatly reduces the circuit complexity. Moreover, the scheme is robust
against phase errors occurring as a result of finite rise and fall times due
to non-ideal pulses.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Lee:2011:AMEAfLHoSDC,
  title     = {A Molecular Evolutionary Algorithm for Learning Hypernetworks on Simulated DNA Computers},
  author    = {Ji-Hoon Lee and Bado Lee and Joon Shik Kim and Russell Deaton and Byoung-Tak Zhang},
  pages     = {2722--2729},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Molecular and quantum computing},
  abstract  = {
We describe a "molecular" evolutionary algorithm that can be implemented in
DNA computing in vitro to learn the recently-proposed hypernetwork model of
cognitive memory. The molecular learning process is designed to make it
possible to perform wet-lab experiments using DNA molecules and bio-lab tools.
We present the bio-experimental protocols for selection, amplification and
mutation operators for evolving hypernetworks. We analyze the convergence
properties of the molecular evolutionary algorithms on simulated DNA
computers. The performance of the algorithms is demonstrated on the task of
simulating the cognitive process of learning a language model from a drama
corpus to identify the style of an unknown drama. We also discuss other
applications of the molecular evolutionary algorithms. In addition to their
feasibility in DNA computing, which opens a new horizon of in vitro
evolutionary computing, the molecular evolutionary algorithm provides unique
properties that are distinguished from conventional evolutionary algorithms
and makes a new addition to the arsenal of tools in evolutionary computation.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{:2011:Pnitd,
  title     = {Paper not in the database},
  author    = {},

  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {},
  abstract  = {
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Multi-objective Optimization V
@InProceedings{Azevedo:2011:CBDaHiEMO,
  title     = {Correlation Between Diversity and Hypervolume in  Evolutionary Multiobjective Optimization},
  author    = {Carlos Azevedo and Aluizio Araujo},
  pages     = {2730--2737},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multi-objective evolutionary algorithms, Multiobjective optimization, Numerical optimization.},
  abstract  = {
This paper reports a study of the influence of diversity in the convergence
dynamics of Multiobjective Evolutionary Algorithms (MOEAs) towards the Pareto
Front (PF). By varying mutation and crossover parameters, several scenarios of
exploration and exploitation are considered, in which each of them is analysed
in order to assess the role of diversity levels on the evolution of high
quality sets of non-dominated solutions, in terms of the Hypervolume
indicator. For this task, the application of the NSGA2 algorithm for
approximating the PF in five ZDT benchmark problems is considered. The results
not only indicate that there are significant statistical correlations between
several diversity metrics and the observed maximum Hypervolume levels on the
evolved populations, but also suggest that there are predictable temporal
patterns of correlation when the evolutionary process is portrayed generation
wise.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Eppe:2011:AESoPMIiMOH,
  title     = {An Experimental Study of Preference Model Integration into Multi-Objective Optimization Heuristics},
  author    = {Stefan Eppe and Manuel Lopez-Ibanez and Thomas Stuetzle and Yves {De Smet}},
  pages     = {2738--2745},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Discrete and combinatorial optimization., Multi-objective evolutionary algorithms},
  abstract  = {
The usage of preference models in algorithms for multi-objective optimization
has recently received an increasing attention by the research community.
Motivated by this trend, we experimentally study the impact that the
integration of preference models into evolutionary multi-objective search
algorithms has on performance. In this article, we consider three preference
models, ranging from rather simple to more complex ones; these are (i)
reference point, (ii) guided dominance, and (iii) P ROMETHEE II. As a
benchmark problem we consider multi-objective traveling salesman problem
instances of various sizes and with a varying number of objectives.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Tantar:2011:Odmocapm,
  title     = {On dynamic multi-objective optimization, classification and performance measures},
  author    = {Emilia Tantar and Alexandru-Adrian Tantar and Bouvry Pascal},
  pages     = {2746--2753},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Dynamic and uncertain environments.},
  abstract  = {
In this work we focus on defining how dynamism can be modeled in the context
of multi-objective optimization. Based on this, we construct a component
oriented classification for dynamic multi-objective optimization problems. For
each category we provide synthetic examples that depict in a more explicit way
the afferent defined model. We do this either by positioning existing
synthetic benchmarks with respect to the proposed classification or through
new problem formulations. In addition, an online dynamic MNK-landscape
formulation is introduced together with a new comparative metric for the
online dynamic multi-objective context.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Xiong:2011:AEMSAfSRIPS,
  title     = {An Evolutionary Multi-objective Scenario-Based Approach for Stochastic Resource Investment Project Scheduling},
  author    = {Jian Xiong and Jing Liu and Yingwu Chen and Hussein Abbass},
  pages     = {2754--2761},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Multiobjective optimization, Discrete and combinatorial optimization., Multi-objective evolutionary algorithms},
  abstract  = {
Many planning problems, such as mission capability planning, can be modelled
as project scheduling problems. Unlike conventional deterministic project
scheduling problems, such problems involve uncertainty and the execution of
the plan will definitely be perturbed by many factors. In other words, the
circumstances under which the plan will be executed are changing and
stochastic. In this paper, we first use scenarios to represent the stochastic
elements in the problem; these are: perturbation strength and perturbation
occurrence time. We define and explain the Stochastic Resource Investment
Project Scheduling (SRIPS) problem. A multi-objective optimization model of
SRIPS is proposed where three optimization objectives are considered
simultaneously: makespan, cost, and robustness. A multi-objective genetic
algorithm is employed to solve the problem. Finally, we generate two test
problems with 30 and 60 non-dummy activities to validate the performance of
the proposed approach and analyze the sensitivity of the results to different
parameter settings.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


% Session: Engineering  Applications III
@InProceedings{Munoz:2011:OSPwPCAtFMS,
  title     = {Opposition-based Shuffled PSO with Passive Congregation Applied to FM Matching Synthesis},
  author    = {Daniel Munoz and Carlos Llanos and Leandro Coelho and Mauricio Ayala},
  pages     = {2762--2768},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Particle swarm optimization, Engineering applications},
  abstract  = {
Synthesis of musical instruments or human voice is a time consuming process
which requires theoretical and experimental knowledge about the synthesis
engine. Commonly, performers need to deal with synthesizer interfaces and a
process of trial and error for creating musical sounds similar to a target
sound. This drawback can be overcome by adjusting automatically the
synthesizer parameters using optimization algorithms. In this paper a hybrid
particle swarm optimization (PSO) algorithm is proposed to solve the frequency
modulation (FM) matching synthesis problem. The proposed algorithm takes
advantage of a shuffle process for exchanging information between particles
and applies the selective passive congregation and the opposition-based
learning approaches to preserve swarm diversity. Both approaches for injecting
diversity are based on simple operators, preserving the easy implementation
philosophy of the particle swarm optimization. The proposed hybrid particle
swarm optimization algorithm was validated for a three-nested FM synthesizer,
which represents a 6-dimensional multimodal optimization problem with strong
epistasis. Simulation results revealed that the proposed algorithm presented
promising results in terms of quality of solutions.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Bandaru:2011:HIACSfFSWPO,
  title     = {Higher-level Innovization: A Case Study from Friction Stir Welding Process Optimization},
  author    = {Sunith Bandaru and Cem Celal Tutum and Kalyanmoy Deb and Jesper Henri Hattel},
  pages     = {2769--2776},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Classification, clustering, data analysis and data mining, Engineering applications, Genetic algorithms},
  abstract  = {
The task of finding crucial design interdependencies in the form of
mathematical relationships (empirical or otherwise) in an engineering design
problem using the Pareto-optimal front is referred to as innovization. Past
studies on the subject have limited themselves to a single front. In this
paper we introduce the higher- level innovization task through an application
of a manufacturing process simulation for the Friction Stir Welding (FSW)
process where commonalities among two different Pareto-optimal fronts are
analyzed. Multiple design rules are simultaneously deciphered from each front
separately and compared. Important design aspects of the FSW problem are
revealed in the process. The overall study aims at showing how some design
principles can considerably ease the task of optimizing future enhancements to
the design.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}

@InProceedings{Sakurai:2011:ASOMboBaGfDS,
  title     = {A Simple Optimization Method based on Backtrack and GA for Delivery Schedule},
  author    = {Yoshitaka Sakurai and Kouhei Takada and Natsuki Tsukamoto and Takashi Onoyama and Rainer Knauf and Setsuo Tsuruta},
  pages     = {2777--2784},
  booktitle = {Proceedings of the 2011 IEEE Congress on Evolutionary Computation},
  year      = {2011},
  editor = "Alice E. Smith",
  month     = {5-8 June},
  address   = {New Orleans, USA},
  organization ="IEEE Computational Intelligence Society",
  publisher = "IEEE Press",
  ISBN      = {0-7803-8515-2},
  keywords  = {Genetic algorithms, Engineering applications, Intelligent systems applications},
  abstract  = {
A delivery route optimization system greatly improves the real time delivery
efficiency. To realize such an optimization, its distribution network requires
solving several tens to hundreds (max. 1500-2000) cities Traveling Salesman
Problems (TSP) within interactive response time (around 3 seconds) with
expert-level accuracy (below 3\% level of error rate). Moreover, as for the
algorithms, understandability and flexibility are necessary because field
experts and field engineers can understand and adjust it to satisfy the field
conditions. To meet these requirements, a Backtrack and Restart Genetic
Algorithm (Br-GA) is proposed. This method combines Backtracking and GA having
simple heuristics such as 2-opt and NI (Nearest Insertion) so that, in case of
stagflation, GA can restarts with the state of populations going back to the
state in the generation before stagflation. Including these heuristics, field
experts and field engineers can easily understand the way and use it. Using
the tool applying their method, they can easily create/modify the solutions or
conditions interactively depending on their field needs. Experimental results
proved that the method meets the above-mentioned delivery scheduling
requirements more than other methods from the viewpoint of optimality as well
as simplicity.
},
  notes =	{CEC2011 sponsored by the IEEE Computational Intelligence Society, and previously sponsored by the EPS and the IET. },
}


